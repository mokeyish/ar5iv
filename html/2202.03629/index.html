<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Survey of Hallucination in Natural Language Generation</title>
<!--Generated on Tue Jul 25 02:23:58 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/dginev/ar5iv-css@0.7.6/css/ar5iv.min.css" type="text/css">
<meta name="keywords" lang="en" content="Hallucination,  Intrinsic Hallucination,  Extrinsic Hallucination,  Faithfulness in NLG,  Factuality in NLG,  Consistency in NLG">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno"><span id="id1" class="ltx_ERROR undefined">\useunder</span>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_ulem_uline"></span><span id="p1.1.2" class="ltx_ERROR undefined">\ul</span>













</p>
</div>
<h1 class="ltx_title ltx_title_document">Survey of Hallucination in Natural Language Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ziwei Ji
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:zjiad@connect.ust.hk">zjiad@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nayeon Lee
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:nyleeaa@connect.ust.hk">nyleeaa@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rita Frieske
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:rita.frieske@ust.hk">rita.frieske@ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tiezheng Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:tyuah@connect.ust.hk">tyuah@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dan Su
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dsu@connect.ust.hk">dsu@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yan Xu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yxucb@connect.ust.hk">yxucb@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Etsuko Ishii
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:eishii@connect.ust.hk">eishii@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yejin Bang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yjbang@connect.ust.hk">yjbang@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenliang Dai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:wdaiai@connect.ust.hk">wdaiai@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrea Madotto
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:amadotto@connect.ust.hk">amadotto@connect.ust.hk</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pascale Fung
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:pascale@ece.ust.hk">pascale@ece.ust.hk</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Center for Artificial Intelligence Research (CAiRE), Hong Kong University of Science and Technology</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Clear Water Bay</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Hong Kong</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id4.id1" class="ltx_p">Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios.
To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.</p>
<p id="id5.id2" class="ltx_p">In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions; and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, machine translation, and visual-language generation.
This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.
</p>
</div>
<div class="ltx_keywords">Hallucination, Intrinsic Hallucination, Extrinsic Hallucination, Faithfulness in NLG, Factuality in NLG, Consistency in NLG
</div>
<span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2022</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>CSUR</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_publicationmonth"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">publicationmonth: </span>2</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language generation</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Neural networks</span></span></span>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S1" title="1. Introduction ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S2" title="2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Definitions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS1" title="2.1. Categorization ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Categorization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS2" title="2.2. Task Comparison ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Task Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS3" title="2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Terminology Clarification</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S3" title="3. Contributors to Hallucination in NLG ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Contributors to Hallucination in NLG</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS1" title="3.1. Hallucination from Data ‣ 3. Contributors to Hallucination in NLG ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Hallucination from Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS2" title="3.2. Hallucination from Training and Inference ‣ 3. Contributors to Hallucination in NLG ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Hallucination from Training and Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S4" title="4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Metrics Measuring Hallucination</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS1" title="4.1. Statistical Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Statistical Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S4.SS2" title="4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Model-based Metric</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS1" title="4.2.1. Information Extraction (IE)-based ‣ 4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Information Extraction (IE)-based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS2" title="4.2.2. QA-based ‣ 4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>QA-based</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS3" title="4.2.3. Natural Language Inference (NLI) Metrics ‣ 4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Natural Language Inference (NLI) Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS4" title="4.2.4. Faithfulness Classification Metrics ‣ 4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Faithfulness Classification Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S4.SS2.SSS5" title="4.2.5. LM-based Metrics ‣ 4.2. Model-based Metric ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.5 </span>LM-based Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS3" title="4.3. Human Evaluation ‣ 4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Human Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S5" title="5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Hallucination Mitigation Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S5.SS1" title="5.1. Data-Related Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Data-Related Methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS1" title="5.1.1. Building a Faithful Dataset ‣ 5.1. Data-Related Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Building a Faithful Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS2" title="5.1.2. Cleaning Data Automatically ‣ 5.1. Data-Related Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Cleaning Data Automatically</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS3" title="5.1.3. Information Augmentation ‣ 5.1. Data-Related Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Information Augmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S5.SS2" title="5.2. Modeling and Inference Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Modeling and Inference Methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS2.SSS1" title="5.2.1. Architecture ‣ 5.2. Modeling and Inference Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS2.SSS2" title="5.2.2. Training ‣ 5.2. Modeling and Inference Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS2.SSS3" title="5.2.3. Post-Processing ‣ 5.2. Modeling and Inference Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.3 </span>Post-Processing</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S6" title="6. Future Directions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Future Directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS1" title="6.1. Future Directions in Metrics Design ‣ 6. Future Directions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Future Directions in Metrics Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS2" title="6.2. Future Directions in Mitigation Methods ‣ 6. Future Directions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Future Directions in Mitigation Methods</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S7" title="7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Hallucination in Abstractive Summarization</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S7.SS1" title="7.1. Hallucination Definition in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Hallucination Definition in Abstractive Summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S7.SS2" title="7.2. Hallucination Metrics in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Hallucination Metrics in Abstractive Summarization</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S7.SS2.SSS1" title="7.2.1. Unsupervised Metrics ‣ 7.2. Hallucination Metrics in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.1 </span>Unsupervised Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S7.SS2.SSS2" title="7.2.2. Semi-Supervised Metrics ‣ 7.2. Hallucination Metrics in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.2 </span>Semi-Supervised Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S7.SS3" title="7.3. Hallucination Mitigation in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Hallucination Mitigation in Abstractive Summarization</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S7.SS3.SSS1" title="7.3.1. Architecture Method. ‣ 7.3. Hallucination Mitigation in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.1 </span>Architecture Method.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S7.SS3.SSS2" title="7.3.2. Training Method ‣ 7.3. Hallucination Mitigation in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.2 </span>Training Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S7.SS3.SSS3" title="7.3.3. Post-Processing Method ‣ 7.3. Hallucination Mitigation in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.3 </span>Post-Processing Method</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S7.SS4" title="7.4. Future Directions in Abstractive Summarization ‣ 7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Future Directions in Abstractive Summarization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S8" title="8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Hallucination in Dialogue Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS1" title="8.1. Hallucination Definition in Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Hallucination Definition in Dialogue Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S8.SS2" title="8.2. Open-domain Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Open-domain Dialogue Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS2.SSS1" title="8.2.1. Self-Consistency ‣ 8.2. Open-domain Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.1 </span>Self-Consistency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS2.SSS2" title="8.2.2. External Consistency ‣ 8.2. Open-domain Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.2 </span>External Consistency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS2.SSS3" title="8.2.3. Hallucination Metrics ‣ 8.2. Open-domain Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.3 </span>Hallucination Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS2.SSS4" title="8.2.4. Mitigation Methods ‣ 8.2. Open-domain Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.4 </span>Mitigation Methods</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S8.SS3" title="8.3. Task-oriented Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Task-oriented Dialogue Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS3.SSS1" title="8.3.1. Hallucination Metrics ‣ 8.3. Task-oriented Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3.1 </span>Hallucination Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S8.SS3.SSS2" title="8.3.2. Mitigation Methods ‣ 8.3. Task-oriented Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3.2 </span>Mitigation Methods</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S8.SS4" title="8.4. Future Directions in Dialogue Generation ‣ 8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.4 </span>Future Directions in Dialogue Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S9" title="9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Hallucination in Generative Question Answering</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS1" title="9.1. Hallucination Definition in GQA ‣ 9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.1 </span>Hallucination Definition in GQA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS2" title="9.2. Hallucination-related Metrics in GQA ‣ 9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.2 </span>Hallucination-related Metrics in GQA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS3" title="9.3. Hallucination Mitigation in GQA ‣ 9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.3 </span>Hallucination Mitigation in GQA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S9.SS4" title="9.4. Future Directions in GQA ‣ 9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.4 </span>Future Directions in GQA</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S10" title="10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Hallucination in Data-to-Text Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S10.SS1" title="10.1. Hallucination Definition in Data-to-Text Generation ‣ 10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1 </span>Hallucination Definition in Data-to-Text Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S10.SS2" title="10.2. Hallucination Metrics in Data-to-Text Generation ‣ 10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.2 </span>Hallucination Metrics in Data-to-Text Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S10.SS3" title="10.3. Hallucination Mitigation in Data-to-Text Generation ‣ 10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.3 </span>Hallucination Mitigation in Data-to-Text Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S10.SS4" title="10.4. Future Directions in Data-to-Text Generation ‣ 10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.4 </span>Future Directions in Data-to-Text Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S11" title="11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>Hallucinations in Neural Machine Translation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S11.SS1" title="11.1. Hallucinations Definition and Categories in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.1 </span>Hallucinations Definition and Categories in NMT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S11.SS2" title="11.2. Hallucination Metrics in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.2 </span>Hallucination Metrics in NMT</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S11.SS2.SSS1" title="11.2.1. Statistical Metrics ‣ 11.2. Hallucination Metrics in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.2.1 </span>Statistical Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S11.SS2.SSS2" title="11.2.2. Model-Based Metrics ‣ 11.2. Hallucination Metrics in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.2.2 </span>Model-Based Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S11.SS3" title="11.3. Hallucination Mitigation Methods in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.3 </span>Hallucination Mitigation Methods in NMT</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S11.SS3.SSS1" title="11.3.1. Data-Related ‣ 11.3. Hallucination Mitigation Methods in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.3.1 </span>Data-Related</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S11.SS3.SSS2" title="11.3.2. Modeling and Inference ‣ 11.3. Hallucination Mitigation Methods in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.3.2 </span>Modeling and Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S11.SS4" title="11.4. Future Directions in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.4 </span>Future Directions in NMT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S12" title="12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12 </span>Hallucination in Vision-Language Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S12.SS1" title="12.1. Object Hallucination in Image Captioning ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12.1 </span>Object Hallucination in Image Captioning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S12.SS2" title="12.2. Hallucination in Other VL Tasks ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12.2 </span>Hallucination in Other VL Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S12.SS3" title="12.3. Future Directions in VL ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">12.3 </span>Future Directions in VL</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S13" title="13. Conclusion ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">13 </span>Conclusion</span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Natural Language Generation (NLG) is one of the crucial yet challenging sub-fields of Natural Language Processing (NLP). NLG techniques are used in many downstream tasks such as summarization, dialogue generation, generative question answering (GQA), data-to-text generation, and machine translation. Recently, the rapid development of NLG has captured the imagination of many thanks to the advances in deep learning technologies, especially Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2017</a>)</cite>-based models like BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin
et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>, BART <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2020</a>)</cite>, GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib150" title="" class="ltx_ref">2019</a>)</cite>, and GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(Brown
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. The conspicuous development of NLG tasks attracted the attention of many researchers, leading to an increased effort in the field.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Alongside the advancement of NLG models, attention towards their limitations and potential risks has also increased.
Some early works <cite class="ltx_cite ltx_citemacro_citep">(Welleck et al<span class="ltx_text">.</span>, <a href="#bib.bib202" title="" class="ltx_ref">2019a</a>; Holtzman
et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite> focus on the potential pitfalls of utilizing the standard likelihood maximization-based objective in training and decoding of NLG models. They discovered that such likelihood maximization approaches could result in <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">degeneration</span>, which refers generated output that is bland, incoherent, or gets stuck in repetitive loops.
Concurrently, it is discovered that NLG models often generate text that is nonsensical, or unfaithful to the provided source input <cite class="ltx_cite ltx_citemacro_citep">(Vinyals and Le, <a href="#bib.bib191" title="" class="ltx_ref">2015</a>; Koehn and Knowles, <a href="#bib.bib86" title="" class="ltx_ref">2017a</a>; Rohrbach et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2018</a>; Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite>. Researchers started referring to such undesirable generation as <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">hallucination</span> <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite> <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The term “hallucination” first appeared in Computer Vision (CV) in <cite class="ltx_cite ltx_citemacro_citet">Baker and Kanade (<a href="#bib.bib6" title="" class="ltx_ref">2000</a>)</cite> and carried more positive meanings, such as superresolution <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2007</a>; Baker and Kanade, <a href="#bib.bib6" title="" class="ltx_ref">2000</a>)</cite>, image inpainting <cite class="ltx_cite ltx_citemacro_citep">(Fawzi
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2016</a>)</cite>, and image synthesizing <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib227" title="" class="ltx_ref">2019b</a>)</cite>. Such hallucination is something we take advantage of rather than avoid in CV.
Nevertheless, recent works have started to refer to a specific type of error as ”hallucination” in image captioning <cite class="ltx_cite ltx_citemacro_citep">(Biten
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Rohrbach et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2018</a>)</cite> and object detection <cite class="ltx_cite ltx_citemacro_citep">(Kayhan
et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2021</a>; Bai
et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2009</a>)</cite>, which denotes non-existing objects detected or localized incorrectly at their expected position. The latter conception is similar to “hallucination” in NLG.</span></span></span>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Hallucination in NLG is concerning because it hinders performance and raises safety concerns for real-world applications.
For instance, in medical applications, a hallucinatory summary generated from a patient information form could pose a risk to the patient.
It may provoke a life-threatening incident for a patient if the instructions of a medicine generated by machine translation are hallucinatory.
Hallucination can also lead to potential privacy violations. <cite class="ltx_cite ltx_citemacro_citet">Carlini
et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> demonstrate that language models can be prompted to recover and generate sensitive personal information from the training corpus (e.g., email address, phone/fax number, and physical address). Such memorization and recovery of the training corpus is considered a form of hallucination because the model is generating text that is not “faithful” to the source input content (i.e., such private information does not exist in the source input).</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Currently there are many active efforts to address hallucination for various NLG tasks. Analyzing hallucinatory content in different NLG tasks and investigating their relationship would strengthen our understanding of this phenomenon and encourage the unification of efforts from different NLG fields.
However, to date, little has been done to understand hallucinations from a broader perspective that encompasses all major NLG tasks. To the best of our knowledge, existing surveys have only focused specific tasks like abstractive summarization <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>; Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite> and translation <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>.
Thus, in this paper, we present a survey of the research progress and challenges in the hallucination problem in NLG. And offer a comprehensive analysis of existing research on the phenomenon of hallucination in different NLG tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, machine translation.
We mainly discussed hallucination of the unimodal NLG tasks that have textual input sources upon which the generated text can be assessed. We also briefly summarize hallucinations in multi-modal settings such as visual-language tasks <cite class="ltx_cite ltx_citemacro_citep">(Biten
et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Alayrac
et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>.
This survey can provide researchers a high-level insight derived from the similarities and differences of different approaches. Furthermore, given the various stages of development in studying hallucination from different tasks, the survey can assist researchers in drawing inspiration on concepts, metrics, and mitigation methods.</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Organization of this Survey</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">The remainder of this survey is organized as follows. Section <a href="#S2" title="2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> <math id="S1.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.SS0.SSS0.Px1.p1.1.m1.1a"><mo id="S1.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.SS0.SSS0.Px1.p1.1.m1.1b"><csymbol cd="latexml" id="S1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S1.SS0.SSS0.Px1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.SS0.SSS0.Px1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S1.SS0.SSS0.Px1.p1.1.m1.1d">∼</annotation></semantics></math> Section <a href="#S6" title="6. Future Directions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> provide an overview of the hallucination problem in NLG by discussing the definition and categorization, contributors, metrics, and mitigation methods of hallucinations, respectively.
The second part of our survey discusses the hallucination problem associated with specific NLG tasks: abstractive summarization in Section <a href="#S7" title="7. Hallucination in Abstractive Summarization ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, dialogue generation in Section <a href="#S8" title="8. Hallucination in Dialogue Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, GQA in Section <a href="#S9" title="9. Hallucination in Generative Question Answering ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, data-to-text generation in Section <a href="#S10" title="10. Hallucination in Data-to-Text Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, machine translation in Section <a href="#S11" title="11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, and VL generation in Section <a href="#S12" title="12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.
Finally, we conclude the whole survey in Section <a href="#S13" title="13. Conclusion ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Definitions</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In the general context outside of NLP, hallucination is a psychological term referring to a particular type of perception <cite class="ltx_cite ltx_citemacro_citep">(Fish
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2009</a>; Macpherson and
Platchias, <a href="#bib.bib119" title="" class="ltx_ref">2013</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Blom (<a href="#bib.bib15" title="" class="ltx_ref">[n. d.]</a>)</cite> define hallucination as <span id="S2.p1.1.1" class="ltx_text ltx_font_bold">“a percept, experienced by a waking individual, in the absence of an appropriate stimulus from the extracorporeal world”</span>.
Simply put, a hallucination is an unreal perception that feels real.
The undesired phenomenon of <span id="S2.p1.1.2" class="ltx_text ltx_font_bold">“NLG models generating unfaithful or nonsensical text”</span> shares similar characteristics with such psychological hallucinations – explaining the choice of terminology. Hallucinated text gives the impression of being fluent and natural despite being unfaithful and nonsensical. It appears to be grounded in the real context provided, although it is actually hard to specify or verify the existence of such contexts. Similar to psychological hallucination, which is hard to tell apart from other “real” perceptions, hallucinated text is also hard to capture at first glance.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Within the context of NLP, the above definition of hallucination, <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">the generated content that is nonsensical or unfaithful to the provided source content</span> <cite class="ltx_cite ltx_citemacro_citep">(Filippova, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>; Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>; Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite>, is the most inclusive and standard.
However, there do exist variations in definition across NLG tasks, which will be further described in the later task-specific sections.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Categorization</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Following the categorization from previous works <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>; Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite>, there are two main types of hallucinations, namely intrinsic hallucination and extrinsic hallucination.
To explain the definition and categorization more intuitively, we give examples of each category of hallucinations for each NLG downstream task in Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Intrinsic Hallucinations</span>: The generated output that contradicts the source content.
For instance, in the abstractive summarization task from Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the generated summary “<span id="S2.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">The first Ebola vaccine was approved in <span id="S2.I1.i1.p1.1.2.1" class="ltx_text ltx_framed_underline">2021</span></span>” contradicts the source content “<span id="S2.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">The first vaccine for Ebola was approved by the FDA in <span id="S2.I1.i1.p1.1.3.1" class="ltx_text ltx_framed_underline">2019</span>.</span>”.
</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Extrinsic Hallucinations</span>: The generated output that cannot be verified from the source content (i.e., output that can neither be supported nor contradicted by the source).
For example, in the abstractive summarization task from Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the information “<span id="S2.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">China has already started clinical trials of the COVID-19 vaccine.</span>” is not mentioned in source. We can neither find evidence for the generated output from the source nor assert that it is wrong.
Notably, the extrinsic hallucination is not always erroneous because it could be from factually correct external information <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>; Thomson and
Reiter, <a href="#bib.bib182" title="" class="ltx_ref">2020</a>)</cite>. Such factual hallucination can be helpful because it recalls additional background knowledge to improve the informativeness of the generated text.
However, in most of the literature, extrinsic hallucination is still treated with caution because its unverifiable aspect of this additional information increases the risk from a factual safety perspective. </p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Task Comparison</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The previous subsection is about the definition and categorization of hallucination commonly shared by many NLG tasks. Yet, there are some task-specific differences.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">For the abstractive summarization, data-to-text, and dialogue tasks, the main difference is in what serves as the “source” and the level of tolerance towards hallucinations.
The source in abstractive summarization is the input source text that is being summarized <cite class="ltx_cite ltx_citemacro_citep">(See
et al<span class="ltx_text">.</span>, <a href="#bib.bib166" title="" class="ltx_ref">2017</a>)</cite>, while the source in data-to-text is non-linguistic data <cite class="ltx_cite ltx_citemacro_citep">(Reiter and Dale, <a href="#bib.bib158" title="" class="ltx_ref">1997</a>; Gatt and Krahmer, <a href="#bib.bib57" title="" class="ltx_ref">2018</a>)</cite>, and the source(s) in the dialogue system is dialogue history and/or the external knowledge sentences.
Tolerance towards hallucinations is very low in both the summarization <cite class="ltx_cite ltx_citemacro_citep">(Pagnoni
et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite> and data-to-text tasks <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite> because it is essential to provide faithful generation. In contrast, the tolerance is relatively higher in dialogue systems because the desired characteristics are not only faithfulness but also user engagement, especially in open-domain dialogue systems <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2020b</a>; Ji et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">For the generative question answering (GQA) task, the exploration of hallucination is at its early stage, so there is no standard definition or categorization of hallucination yet. However, we can see that the GQA literature mainly focuses on “intrinsic hallucination” where the source is the world knowledge <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite>. Lastly, unlike the aforementioned tasks, the categorizations of hallucinations in machine translation vary within the task. Most relevant literature agrees that translated text is considered a hallucination when the source text is completely disconnected from the translated target <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>; Müller
et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2020</a>; Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite>.
For further details, please refer to Section <a href="#S11" title="11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.
</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Terminology Clarification</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Multiple terminologies are associated with the concept of hallucination. We provide clarification of the commonly used terminologies <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">hallucination</span>, <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_italic">faithfulness</span> and <span id="S2.SS3.p1.1.3" class="ltx_text ltx_font_italic">factuality</span> to resolve any confusion.
<span id="S2.SS3.p1.1.4" class="ltx_text ltx_font_italic">Faithfulness</span> is defined as staying consistent and truthful to the provided source – an antonym to ”hallucination.” Any work that tries to maximize faithfulness thus focuses on minimizing hallucination. For this reason, our survey includes all those works that address the faithfulness of machine generated outputs.
<span id="S2.SS3.p1.1.5" class="ltx_text ltx_font_italic">Factuality</span> refers to the quality of being actual or based on fact. Depending on what serves as the “fact”, ”factuality” and ”faithfulness” may or may not be the same. <cite class="ltx_cite ltx_citemacro_citet">Maynez
et al<span class="ltx_text">.</span> (<a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite> differentiate ”factuality” from ”faithfulness” by defining the “fact” to be the world knowledge.
In contrast, <cite class="ltx_cite ltx_citemacro_citet">Dong
et al<span class="ltx_text">.</span> (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite> use the source input as the “fact” to determine the factual correctness, making ”factuality” indistinguishable from ”faithfulness”.
In this paper, we adopt the definition from <cite class="ltx_cite ltx_citemacro_citet">Maynez
et al<span class="ltx_text">.</span> (<a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite> because we believe having such distinction between source knowledge and world knowledge provides a more clear understanding.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Note that the judging criteria for what is considered faithful or hallucinated (i.e., the definition of hallucination) can differ across tasks. For more details of these variation definitions, you can find in the later task-specific sections.</p>
</div>
<div id="S2.T1" class="ltx_table ltx_transformed_outer" style="width:10366.0pt;height:471.7pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:471.7pt;transform:translate(4947.17pt,4948.64pt) rotate(-90deg) ;"><figure>
<div id="S2.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:398.9pt;height:10363.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-159.4pt,4139.7pt) scale(0.555886160263696,0.555886160263696) ;">
<table id="S2.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S2.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S2.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Sub-Task</span><span id="S2.T1.1.1.1.1.2.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Type</span></td>
<td id="S2.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="7">
<span id="S2.T1.1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Source</span><span id="S2.T1.1.1.1.1.4.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S2.T1.1.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Output</span><span id="S2.T1.1.1.1.1.5.2" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S2.T1.1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S2.T1.1.1.2.2.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.2.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.2.2.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.2.2.1.1.1.1.1" class="ltx_td ltx_align_center">Abstractive</span></span>
<span id="S2.T1.1.1.2.2.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.2.2.1.1.1.2.1" class="ltx_td ltx_align_center">Summarization</span></span>
<span id="S2.T1.1.1.2.2.1.1.1.3" class="ltx_tr">
<span id="S2.T1.1.1.2.2.1.1.1.3.1" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citep">(Pagnoni
et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span></td>
<td id="S2.T1.1.1.2.2.2" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.2.2.3.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.2.2.4" class="ltx_td ltx_align_left ltx_border_t" colspan="7">
<table id="S2.T1.1.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.2.2.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2.2.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.2.2.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.2.2.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">The first vaccine for Ebola was approved by the FDA in 2019 in the US, five years after the initial outbreak in 2014. To produce the vaccine, scientists had to sequence the DNA</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.2.2.4.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T1.1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.2.2.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2.2.5.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.2.2.5.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.2.2.5.1.1.1.1.1" class="ltx_text" style="font-size:80%;">The first Ebola vaccine was approved in </span><span id="S2.T1.1.1.2.2.5.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">2021</span><span id="S2.T1.1.1.2.2.5.1.1.1.1.3" class="ltx_text" style="font-size:80%;">.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.3.3" class="ltx_tr">
<td id="S2.T1.1.1.3.3.1" class="ltx_td"></td>
<td id="S2.T1.1.1.3.3.2" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.3.3.2.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.3.3.3" class="ltx_td ltx_align_left" colspan="7">
<table id="S2.T1.1.1.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.3.3.3.1.1" class="ltx_tr">
<td id="S2.T1.1.1.3.3.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.3.3.3.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.3.3.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">of Ebola, then identify possible vaccines, and finally show successful clinical trials. Scientists say a vaccine for COVID-19 is unlikely to be ready this year, although clinical trials have already started.</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.3.3.3.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.3.3.4" class="ltx_td ltx_align_left">
<table id="S2.T1.1.1.3.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.3.3.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.3.3.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.3.3.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.3.3.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">China</span><span id="S2.T1.1.1.3.3.4.1.1.1.1.2" class="ltx_text" style="font-size:80%;"> has already started clinical trials of the COVID-19 vaccine.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.4.4" class="ltx_tr">
<td id="S2.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S2.T1.1.1.4.4.1.1" class="ltx_text" style="font-size:80%;">Dialogue</span></td>
<td id="S2.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="S2.T1.1.1.4.4.2.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.4.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.4.4.2.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.4.4.2.1.1.1.1" class="ltx_td ltx_align_center">Task-</span></span>
<span id="S2.T1.1.1.4.4.2.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.4.4.2.1.1.2.1" class="ltx_td ltx_align_center">oriented</span></span>
<span id="S2.T1.1.1.4.4.2.1.1.3" class="ltx_tr">
<span id="S2.T1.1.1.4.4.2.1.1.3.1" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite></span></span>
</span></span><span id="S2.T1.1.1.4.4.2.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.4.4.3.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_t" colspan="7" rowspan="2">
<span id="S2.T1.1.1.4.4.4.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.4.4.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.4.4.4.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.4.4.4.1.1.1.1" class="ltx_td ltx_align_justify">
<span id="S2.T1.1.1.4.4.4.1.1.1.1.1" class="ltx_p ltx_align_top">inform (NAME = pickwick hotel, PRICERANGE = moderate)</span></span></span>
</span></span><span id="S2.T1.1.1.4.4.4.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T1.1.1.4.4.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.4.4.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.4.4.5.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.4.4.5.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.4.4.5.1.1.1.1.1" class="ltx_text" style="font-size:80%;">the hotel named pickwick hotel is in a </span><span id="S2.T1.1.1.4.4.5.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">high</span><span id="S2.T1.1.1.4.4.5.1.1.1.1.3" class="ltx_text" style="font-size:80%;"> price range.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.5.5" class="ltx_tr">
<td id="S2.T1.1.1.5.5.1" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.5.5.1.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.5.5.2" class="ltx_td ltx_align_left">
<table id="S2.T1.1.1.5.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.5.5.2.1.1" class="ltx_tr">
<td id="S2.T1.1.1.5.5.2.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.5.5.2.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.5.5.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">the pickwick hotel </span><span id="S2.T1.1.1.5.5.2.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">in san diego</span><span id="S2.T1.1.1.5.5.2.1.1.1.1.3" class="ltx_text" style="font-size:80%;"> is a moderate price range</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.6.6" class="ltx_tr">
<td id="S2.T1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="S2.T1.1.1.6.6.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.6.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.6.6.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.6.6.1.1.1.1.1" class="ltx_td ltx_align_center">Open-</span></span>
<span id="S2.T1.1.1.6.6.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.6.6.1.1.1.2.1" class="ltx_td ltx_align_center">domain</span></span>
<span id="S2.T1.1.1.6.6.1.1.1.3" class="ltx_tr">
<span id="S2.T1.1.1.6.6.1.1.1.3.1" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_citep">(Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S2.T1.1.1.6.6.1.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.6.6.2.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_t" colspan="7">
<table id="S2.T1.1.1.6.6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.6.6.3.1.1" class="ltx_tr">
<td id="S2.T1.1.1.6.6.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.6.6.3.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.6.6.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Dialog History:</span></p>
</td>
</tr>
<tr id="S2.T1.1.1.6.6.3.1.2" class="ltx_tr">
<td id="S2.T1.1.1.6.6.3.1.2.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.6.6.3.1.2.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.6.6.3.1.2.1.1.1" class="ltx_text" style="font-size:80%;">Speaker 1: What do you think about Murray?</span></p>
</td>
</tr>
<tr id="S2.T1.1.1.6.6.3.1.3" class="ltx_tr">
<td id="S2.T1.1.1.6.6.3.1.3.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.6.6.3.1.3.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.6.6.3.1.3.1.1.1" class="ltx_text" style="font-size:80%;">Speaker 2: I think Murray is a great player he just needs to stay healthy in order to compete more. Who do you like best?</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.6.6.3.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T1.1.1.6.6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.6.6.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.6.6.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.6.6.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.6.6.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Speaker 1: I like </span><span id="S2.T1.1.1.6.6.4.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">Roger Nadal</span><span id="S2.T1.1.1.6.6.4.1.1.1.1.3" class="ltx_text" style="font-size:80%;"> the most!</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.7.7" class="ltx_tr">
<td id="S2.T1.1.1.7.7.1" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.7.7.1.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.7.7.2" class="ltx_td ltx_align_left" colspan="7">
<table id="S2.T1.1.1.7.7.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.7.7.2.1.1" class="ltx_tr">
<td id="S2.T1.1.1.7.7.2.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.7.7.2.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.7.7.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Knowledge: In tennis, the term Big Four refers to the quartet of men’s singles players comprising Roger Federer, Rafael Nadal, Novak Djokovic, and Andy Murray.</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.7.7.2.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.7.7.3" class="ltx_td ltx_align_left">
<table id="S2.T1.1.1.7.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.7.7.3.1.1" class="ltx_tr">
<td id="S2.T1.1.1.7.7.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.7.7.3.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.7.7.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Speaker 1: I like Djokovic. He has played </span><span id="S2.T1.1.1.7.7.3.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">in the top ten singles players of the world</span><span id="S2.T1.1.1.7.7.3.1.1.1.1.3" class="ltx_text" style="font-size:80%;">.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.8.8" class="ltx_tr">
<td id="S2.T1.1.1.8.8.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S2.T1.1.1.8.8.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.8.8.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.8.8.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.8.8.1.1.1.1.1" class="ltx_td ltx_align_center">Generative QA</span></span>
<span id="S2.T1.1.1.8.8.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.8.8.1.1.1.2.1" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2016</a>)</cite></span></span>
</span></span></td>
<td id="S2.T1.1.1.8.8.2" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.8.8.3.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_t" colspan="7">
<table id="S2.T1.1.1.8.8.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.8.8.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.8.8.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.8.8.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.8.8.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Question: dow jones industrial average please?</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.8.8.4.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T1.1.1.8.8.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.8.8.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.8.8.5.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.8.8.5.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.8.8.5.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Answer: The Dow Jones Industrial Average(DJIA) is an index of </span><span id="S2.T1.1.1.8.8.5.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">30 major U.S.stock indexes</span><span id="S2.T1.1.1.8.8.5.1.1.1.1.3" class="ltx_text" style="font-size:80%;">. The DJIAwas created in 1896 by Charles Dow, a statistician and editor of The Wall Street Journal. The index was first published in the mid-1880s, and </span><span id="S2.T1.1.1.8.8.5.1.1.1.1.4" class="ltx_text ltx_font_bold" style="font-size:80%;">was last updated on May 26,1896.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.9.9" class="ltx_tr">
<td id="S2.T1.1.1.9.9.1" class="ltx_td"></td>
<td id="S2.T1.1.1.9.9.2" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.9.9.2.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.9.9.3" class="ltx_td ltx_align_left" colspan="7"><span id="S2.T1.1.1.9.9.3.1" class="ltx_text" style="font-size:80%;">Question: definition of sadduction</span></td>
<td id="S2.T1.1.1.9.9.4" class="ltx_td ltx_align_left">
<table id="S2.T1.1.1.9.9.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.9.9.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.9.9.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.9.9.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.9.9.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Answer: Sadducees. noun. </span><span id="S2.T1.1.1.9.9.4.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">The definition of a sadducee is a person who acts in a deceitful or duplicitous manner. An example of a Sadduceee is a politician who acts deceitfully in order to gain political power</span><span id="S2.T1.1.1.9.9.4.1.1.1.1.3" class="ltx_text" style="font-size:80%;">.1 a member of a Jewish sect that was active during the Second Temple.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.10.10" class="ltx_tr">
<td id="S2.T1.1.1.10.10.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S2.T1.1.1.10.10.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.10.10.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.10.10.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.10.10.1.1.1.1.1" class="ltx_td ltx_align_center">Data2text</span></span>
<span id="S2.T1.1.1.10.10.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.10.10.1.1.1.2.1" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citep">(Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>)</cite></span></span>
</span></span></td>
<td id="S2.T1.1.1.10.10.2" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S2.T1.1.1.10.10.3.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.4.1" class="ltx_text" style="font-size:80%;">TEAM</span></td>
<td id="S2.T1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.5.1" class="ltx_text" style="font-size:80%;">CITY</span></td>
<td id="S2.T1.1.1.10.10.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.6.1" class="ltx_text" style="font-size:80%;">WIN</span></td>
<td id="S2.T1.1.1.10.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.7.1" class="ltx_text" style="font-size:80%;">LOSS</span></td>
<td id="S2.T1.1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.8.1" class="ltx_text" style="font-size:80%;">PTS</span></td>
<td id="S2.T1.1.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.9.1" class="ltx_text" style="font-size:80%;">FG_PCT</span></td>
<td id="S2.T1.1.1.10.10.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.10.10.10.1" class="ltx_text" style="font-size:80%;">BLK</span></td>
<td id="S2.T1.1.1.10.10.11" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S2.T1.1.1.10.10.11.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.10.10.11.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.10.10.11.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.10.10.11.1.1.1.1" class="ltx_td ltx_align_justify">
<span id="S2.T1.1.1.10.10.11.1.1.1.1.1" class="ltx_p ltx_align_top">The Houston Rockets <span id="S2.T1.1.1.10.10.11.1.1.1.1.1.1" class="ltx_text ltx_font_bold">(18-4)</span> defeated the Denver Nuggets (10-13) 108-96 on Saturday.</span></span></span>
</span></span></td>
</tr>
<tr id="S2.T1.1.1.11.11" class="ltx_tr">
<td id="S2.T1.1.1.11.11.1" class="ltx_td"></td>
<td id="S2.T1.1.1.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.2.1" class="ltx_text" style="font-size:80%;">Rockets</span></td>
<td id="S2.T1.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.3.1" class="ltx_text" style="font-size:80%;">Houston</span></td>
<td id="S2.T1.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.4.1" class="ltx_text" style="font-size:80%;">18</span></td>
<td id="S2.T1.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.5.1" class="ltx_text" style="font-size:80%;">5</span></td>
<td id="S2.T1.1.1.11.11.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.6.1" class="ltx_text" style="font-size:80%;">108</span></td>
<td id="S2.T1.1.1.11.11.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.7.1" class="ltx_text" style="font-size:80%;">44</span></td>
<td id="S2.T1.1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.11.11.8.1" class="ltx_text" style="font-size:80%;">7</span></td>
</tr>
<tr id="S2.T1.1.1.12.12" class="ltx_tr">
<td id="S2.T1.1.1.12.12.1" class="ltx_td"></td>
<td id="S2.T1.1.1.12.12.2" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.2.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.12.12.3" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.3.1" class="ltx_text" style="font-size:80%;">Nuggets</span></td>
<td id="S2.T1.1.1.12.12.4" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.4.1" class="ltx_text" style="font-size:80%;">Denver</span></td>
<td id="S2.T1.1.1.12.12.5" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.5.1" class="ltx_text" style="font-size:80%;">10</span></td>
<td id="S2.T1.1.1.12.12.6" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.6.1" class="ltx_text" style="font-size:80%;">13</span></td>
<td id="S2.T1.1.1.12.12.7" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.7.1" class="ltx_text" style="font-size:80%;">96</span></td>
<td id="S2.T1.1.1.12.12.8" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.8.1" class="ltx_text" style="font-size:80%;">38</span></td>
<td id="S2.T1.1.1.12.12.9" class="ltx_td ltx_align_center"><span id="S2.T1.1.1.12.12.9.1" class="ltx_text" style="font-size:80%;">7</span></td>
<td id="S2.T1.1.1.12.12.10" class="ltx_td ltx_align_left">
<table id="S2.T1.1.1.12.12.10.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.12.12.10.1.1" class="ltx_tr">
<td id="S2.T1.1.1.12.12.10.1.1.1" class="ltx_td ltx_align_justify"><span id="S2.T1.1.1.12.12.10.1.1.1.1" class="ltx_text ltx_font_bold ltx_align_top" style="font-size:80%;">Houston has won two straight games and six of their last seven.</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.13.13" class="ltx_tr">
<td id="S2.T1.1.1.13.13.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="S2.T1.1.1.13.13.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T1.1.1.13.13.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.13.13.1.1.1.1" class="ltx_tr">
<span id="S2.T1.1.1.13.13.1.1.1.1.1" class="ltx_td ltx_align_center">Translation</span></span>
<span id="S2.T1.1.1.13.13.1.1.1.2" class="ltx_tr">
<span id="S2.T1.1.1.13.13.1.1.1.2.1" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite></span></span>
</span></span></td>
<td id="S2.T1.1.1.13.13.2" class="ltx_td ltx_border_t"></td>
<td id="S2.T1.1.1.13.13.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.1.13.13.3.1" class="ltx_text" style="font-size:80%;">Intrinsic</span></td>
<td id="S2.T1.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_t" colspan="7">
<table id="S2.T1.1.1.13.13.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.13.13.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.13.13.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.13.13.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.13.13.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">迈克周四去书店。 (Michael went to the bookstore on Thursday.)</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.13.13.4.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T1.1.1.13.13.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.13.13.5.1.1" class="ltx_tr">
<td id="S2.T1.1.1.13.13.5.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.13.13.5.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.13.13.5.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Jerry didn’t go</span><span id="S2.T1.1.1.13.13.5.1.1.1.1.2" class="ltx_text" style="font-size:80%;"> to the bookstore.</span></p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T1.1.1.14.14" class="ltx_tr">
<td id="S2.T1.1.1.14.14.1" class="ltx_td ltx_border_bb"></td>
<td id="S2.T1.1.1.14.14.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.1.1.14.14.2.1" class="ltx_text" style="font-size:80%;">Extrinsic</span></td>
<td id="S2.T1.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_bb" colspan="7">
<table id="S2.T1.1.1.14.14.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.14.14.3.1.1" class="ltx_tr">
<td id="S2.T1.1.1.14.14.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.14.14.3.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.14.14.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">迈克周四去书店。 (Michael went to the bookstore on Thursday.)</span></p>
</td>
</tr>
</table>
<span id="S2.T1.1.1.14.14.3.2" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S2.T1.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_bb">
<table id="S2.T1.1.1.14.14.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.14.14.4.1.1" class="ltx_tr">
<td id="S2.T1.1.1.14.14.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S2.T1.1.1.14.14.4.1.1.1.1" class="ltx_p ltx_align_top"><span id="S2.T1.1.1.14.14.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Michael </span><span id="S2.T1.1.1.14.14.4.1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">happily</span><span id="S2.T1.1.1.14.14.4.1.1.1.1.3" class="ltx_text" style="font-size:80%;"> went to the bookstore </span><span id="S2.T1.1.1.14.14.4.1.1.1.1.4" class="ltx_text ltx_font_bold" style="font-size:80%;">with his friend.</span></p>
</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Examples of each category of hallucinations for each task.
In the Data2Text task, H/A: home/away, MIN: minutes, PTS: points, REB: rebounds, AST: assists, BLK: blocks, FG_PCT: field goals percentage. The examples for VL tasks are shown in Figure <a href="#S12.F2" title="Figure 2 ‣ Definition. ‣ 12.1. Object Hallucination in Image Captioning ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a href="#S12.F3" title="Figure 3 ‣ 12.2. Hallucination in Other VL Tasks ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a></figcaption>
</figure></div></div>
<figure id="S2.T2" class="ltx_table">
<div id="S2.T2.4" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:531.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-132.4pt,162.3pt) scale(0.620823265901172,0.620823265901172) ;">
<table id="S2.T2.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T2.4.4.5.1" class="ltx_tr">
<td id="S2.T2.4.4.5.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S2.T2.4.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.4.4.5.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Category</span></th>
<th id="S2.T2.4.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T2.4.4.5.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span><span id="S2.T2.4.4.5.1.3.2" class="ltx_text" style="font-size:80%;"></span>
</th>
<th id="S2.T2.4.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T2.4.4.5.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Works</span><span id="S2.T2.4.4.5.1.4.2" class="ltx_text" style="font-size:80%;"></span>
</th>
</tr>
<tr id="S2.T2.4.4.6.2" class="ltx_tr">
<td id="S2.T2.4.4.6.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="10"><span id="S2.T2.4.4.6.2.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.6.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.6.2.1.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.6.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.6.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Automatic</span></span></span>
<span id="S2.T2.4.4.6.2.1.1.1.2" class="ltx_tr">
<span id="S2.T2.4.4.6.2.1.1.1.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.6.2.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Metrics</span></span></span>
</span></span></td>
<td id="S2.T2.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S2.T2.4.4.6.2.2.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.6.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.6.2.2.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.6.2.2.1.1.1.1" class="ltx_td ltx_align_center">Statistical</span></span>
</span></span></td>
<td id="S2.T2.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.6.2.3.1" class="ltx_text" style="font-size:80%;">Dialogue</span></td>
<td id="S2.T2.4.4.6.2.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Shuster et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.6.2.4.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib169" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.6.2.4.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.7.3" class="ltx_tr">
<td id="S2.T2.4.4.7.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.7.3.1.1" class="ltx_text" style="font-size:80%;">Data2Text</span></td>
<td id="S2.T2.4.4.7.3.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Dhingra et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.7.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib31" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.7.3.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.7.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib200" title="" class="ltx_ref">2020b</a><span id="S2.T2.4.4.7.3.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.8.4" class="ltx_tr">
<td id="S2.T2.4.4.8.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.8.4.1.1" class="ltx_text" style="font-size:80%;">Translation</span></td>
<td id="S2.T2.4.4.8.4.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Martindale et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.8.4.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib125" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.8.4.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.9.5" class="ltx_tr">
<td id="S2.T2.4.4.9.5.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.9.5.1.1" class="ltx_text" style="font-size:80%;">Captioning</span></td>
<td id="S2.T2.4.4.9.5.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Rohrbach et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.9.5.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib160" title="" class="ltx_ref">2018</a><span id="S2.T2.4.4.9.5.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.10.6" class="ltx_tr">
<td id="S2.T2.4.4.10.6.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="6"><span id="S2.T2.4.4.10.6.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.10.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.10.6.1.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.10.6.1.1.1.1.1" class="ltx_td ltx_align_center">Model-</span></span>
<span id="S2.T2.4.4.10.6.1.1.1.2" class="ltx_tr">
<span id="S2.T2.4.4.10.6.1.1.1.2.1" class="ltx_td ltx_align_center">based</span></span>
</span></span></td>
<td id="S2.T2.4.4.10.6.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="S2.T2.4.4.10.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.10.6.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.10.6.2.1.1.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.10.6.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Abstractive</span></td>
</tr>
<tr id="S2.T2.4.4.10.6.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.10.6.2.1.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.10.6.2.1.2.1.1" class="ltx_text" style="font-size:80%;">Summarization</span></td>
</tr>
</table>
</td>
<td id="S2.T2.4.4.10.6.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.10.6.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.10.6.3.1.1" class="ltx_tr">
<td id="S2.T2.4.4.10.6.3.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Nan et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib135" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.10.6.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Durmus
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib37" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.10.6.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib192" title="" class="ltx_ref">2020a</a><span id="S2.T2.4.4.10.6.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Kryscinski et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib90" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.10.6.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.10.6.3.1.2" class="ltx_tr">
<td id="S2.T2.4.4.10.6.3.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Goodrich
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib62" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.10.6.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Pagnoni
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib140" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.10.6.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Gabriel et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib53" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.10.6.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Zhou et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib238" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.10.6.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.10.6.3.1.3" class="ltx_tr">
<td id="S2.T2.4.4.10.6.3.1.3.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Laban
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib94" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.10.6.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Falke et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib46" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.10.6.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Mishra et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib132" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.10.6.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Scialom et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.10.6.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib165" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.10.6.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.11.7" class="ltx_tr">
<td id="S2.T2.4.4.11.7.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.11.7.1.1" class="ltx_text" style="font-size:80%;">Dialogue</span></td>
<td id="S2.T2.4.4.11.7.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.11.7.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.11.7.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.11.7.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib109" title="" class="ltx_ref">2020c</a><span id="S2.T2.4.4.11.7.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Balakrishnan et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib7" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.11.7.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Honovich et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib74" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.11.7.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.11.7.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.11.7.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib43" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.11.7.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Gupta
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib67" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.11.7.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Santhanam et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.11.7.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib164" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.11.7.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.4" class="ltx_tr">
<td id="S2.T2.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.4.5.1" class="ltx_text" style="font-size:80%;">Generative QA</span></td>
<td id="S2.T2.4.4.4.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.4.4.4" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.3.3.3.3.3.3" class="ltx_tr">
<td id="S2.T2.3.3.3.3.3.3.3" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_citet">Sellam
et al<span class="ltx_text">.</span> <span id="S2.T2.3.3.3.3.3.3.3.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib167" title="" class="ltx_ref">2020</a><span id="S2.T2.3.3.3.3.3.3.3.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite><math id="S2.T2.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="S2.T2.1.1.1.1.1.1.1.m1.1a"><msup id="S2.T2.1.1.1.1.1.1.1.m1.1.1" xref="S2.T2.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T2.1.1.1.1.1.1.1.m1.1.1a" xref="S2.T2.1.1.1.1.1.1.1.m1.1.1.cmml"></mi><mo mathsize="80%" id="S2.T2.1.1.1.1.1.1.1.m1.1.1.1" xref="S2.T2.1.1.1.1.1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.1.1.1.m1.1b"><apply id="S2.T2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.1.1.1.m1.1.1"><times id="S2.T2.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T2.1.1.1.1.1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="S2.T2.3.3.3.3.3.3.3.3" class="ltx_text" style="font-size:80%;">,</span><cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> <span id="S2.T2.3.3.3.3.3.3.3.4.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib232" title="" class="ltx_ref">2020a</a><span id="S2.T2.3.3.3.3.3.3.3.5.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite><math id="S2.T2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="S2.T2.2.2.2.2.2.2.2.m2.1a"><msup id="S2.T2.2.2.2.2.2.2.2.m2.1.1" xref="S2.T2.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="S2.T2.2.2.2.2.2.2.2.m2.1.1a" xref="S2.T2.2.2.2.2.2.2.2.m2.1.1.cmml"></mi><mo mathsize="80%" id="S2.T2.2.2.2.2.2.2.2.m2.1.1.1" xref="S2.T2.2.2.2.2.2.2.2.m2.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.2.2.2.2.m2.1b"><apply id="S2.T2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S2.T2.2.2.2.2.2.2.2.m2.1.1"><times id="S2.T2.2.2.2.2.2.2.2.m2.1.1.1.cmml" xref="S2.T2.2.2.2.2.2.2.2.m2.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.2.2.2.2.2.m2.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S2.T2.2.2.2.2.2.2.2.m2.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="S2.T2.3.3.3.3.3.3.3.6" class="ltx_text" style="font-size:80%;">,</span><cite class="ltx_cite ltx_citemacro_citet">Durmus
et al<span class="ltx_text">.</span> <span id="S2.T2.3.3.3.3.3.3.3.7.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib37" title="" class="ltx_ref">2020</a><span id="S2.T2.3.3.3.3.3.3.3.8.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite><math id="S2.T2.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="S2.T2.3.3.3.3.3.3.3.m3.1a"><msup id="S2.T2.3.3.3.3.3.3.3.m3.1.1" xref="S2.T2.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="S2.T2.3.3.3.3.3.3.3.m3.1.1a" xref="S2.T2.3.3.3.3.3.3.3.m3.1.1.cmml"></mi><mo mathsize="80%" id="S2.T2.3.3.3.3.3.3.3.m3.1.1.1" xref="S2.T2.3.3.3.3.3.3.3.m3.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.3.3.3.3.m3.1b"><apply id="S2.T2.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S2.T2.3.3.3.3.3.3.3.m3.1.1"><times id="S2.T2.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="S2.T2.3.3.3.3.3.3.3.m3.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.3.3.3.3.3.m3.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S2.T2.3.3.3.3.3.3.3.m3.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
</tr>
<tr id="S2.T2.4.4.4.4.4.4" class="ltx_tr">
<td id="S2.T2.4.4.4.4.4.4.1" class="ltx_td ltx_align_left">
<cite class="ltx_cite ltx_citemacro_citet">Wang
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.4.4.4.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib192" title="" class="ltx_ref">2020a</a><span id="S2.T2.4.4.4.4.4.4.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite><math id="S2.T2.4.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="S2.T2.4.4.4.4.4.4.1.m1.1a"><msup id="S2.T2.4.4.4.4.4.4.1.m1.1.1" xref="S2.T2.4.4.4.4.4.4.1.m1.1.1.cmml"><mi id="S2.T2.4.4.4.4.4.4.1.m1.1.1a" xref="S2.T2.4.4.4.4.4.4.1.m1.1.1.cmml"></mi><mo mathsize="80%" id="S2.T2.4.4.4.4.4.4.1.m1.1.1.1" xref="S2.T2.4.4.4.4.4.4.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S2.T2.4.4.4.4.4.4.1.m1.1b"><apply id="S2.T2.4.4.4.4.4.4.1.m1.1.1.cmml" xref="S2.T2.4.4.4.4.4.4.1.m1.1.1"><times id="S2.T2.4.4.4.4.4.4.1.m1.1.1.1.cmml" xref="S2.T2.4.4.4.4.4.4.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.4.4.4.4.4.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S2.T2.4.4.4.4.4.4.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="S2.T2.4.4.4.4.4.4.1.3" class="ltx_text" style="font-size:80%;">, </span><cite class="ltx_cite ltx_citemacro_citet">Su
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.4.4.4.4.1.4.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib173" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.4.4.4.4.1.5.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.12.8" class="ltx_tr">
<td id="S2.T2.4.4.12.8.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.12.8.1.1" class="ltx_text" style="font-size:80%;">Data2Text</span></td>
<td id="S2.T2.4.4.12.8.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.12.8.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.12.8.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.12.8.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Liu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.12.8.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib115" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.12.8.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wiseman
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.12.8.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib208" title="" class="ltx_ref">2017</a><span id="S2.T2.4.4.12.8.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Dušek and
Kasner <span id="S2.T2.4.4.12.8.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib40" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.12.8.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.12.8.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.12.8.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Tian
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.12.8.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib185" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.12.8.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Filippova <span id="S2.T2.4.4.12.8.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib51" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.12.8.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Rebuffel
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.12.8.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib156" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.12.8.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.13.9" class="ltx_tr">
<td id="S2.T2.4.4.13.9.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.13.9.1.1" class="ltx_text" style="font-size:80%;">Translation</span></td>
<td id="S2.T2.4.4.13.9.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.13.9.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.13.9.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.13.9.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Kong
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib88" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.13.9.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Lee et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib96" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.13.9.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Tu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib188" title="" class="ltx_ref">2016</a><span id="S2.T2.4.4.13.9.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.13.9.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.13.9.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Feng
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib50" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.13.9.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Garg
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib56" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.13.9.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Zhou et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib238" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.13.9.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.13.9.2.1.3" class="ltx_tr">
<td id="S2.T2.4.4.13.9.2.1.3.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib154" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.13.9.2.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Parthasarathi et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.13.9.2.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib142" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.13.9.2.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.14.10" class="ltx_tr">
<td id="S2.T2.4.4.14.10.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.14.10.1.1" class="ltx_text" style="font-size:80%;">Task-Agnostic</span></td>
<td id="S2.T2.4.4.14.10.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Goyal and Durrett <span id="S2.T2.4.4.14.10.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib64" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.14.10.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Zhou et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.14.10.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib238" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.14.10.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Liu et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.14.10.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib114" title="" class="ltx_ref">2021a</a><span id="S2.T2.4.4.14.10.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.15.11" class="ltx_tr">
<td id="S2.T2.4.4.15.11.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="22"><span id="S2.T2.4.4.15.11.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.15.11.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.15.11.1.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.15.11.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.15.11.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Mitigation</span></span></span>
<span id="S2.T2.4.4.15.11.1.1.1.2" class="ltx_tr">
<span id="S2.T2.4.4.15.11.1.1.1.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.15.11.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Method</span></span></span>
</span></span></td>
<td id="S2.T2.4.4.15.11.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="6"><span id="S2.T2.4.4.15.11.2.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.15.11.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.15.11.2.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.15.11.2.1.1.1.1" class="ltx_td ltx_align_center">Data-</span></span>
<span id="S2.T2.4.4.15.11.2.1.1.2" class="ltx_tr">
<span id="S2.T2.4.4.15.11.2.1.1.2.1" class="ltx_td ltx_align_center">Related</span></span>
</span></span></td>
<td id="S2.T2.4.4.15.11.3" class="ltx_td ltx_align_center ltx_border_t">
<table id="S2.T2.4.4.15.11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.15.11.3.1.1" class="ltx_tr">
<td id="S2.T2.4.4.15.11.3.1.1.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.15.11.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Abstractive</span></td>
</tr>
<tr id="S2.T2.4.4.15.11.3.1.2" class="ltx_tr">
<td id="S2.T2.4.4.15.11.3.1.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.15.11.3.1.2.1.1" class="ltx_text" style="font-size:80%;">Summarization</span></td>
</tr>
</table>
</td>
<td id="S2.T2.4.4.15.11.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.15.11.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.15.11.4.1.1" class="ltx_tr">
<td id="S2.T2.4.4.15.11.4.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Nan et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.15.11.4.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib135" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.15.11.4.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Cao
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.15.11.4.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib20" title="" class="ltx_ref">2018</a><span id="S2.T2.4.4.15.11.4.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Zhu et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.15.11.4.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib241" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.15.11.4.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.15.11.4.1.2" class="ltx_tr">
<td id="S2.T2.4.4.15.11.4.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Gunel
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.15.11.4.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib66" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.15.11.4.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.16.12" class="ltx_tr">
<td id="S2.T2.4.4.16.12.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.16.12.1.1" class="ltx_text" style="font-size:80%;">Dialogue</span></td>
<td id="S2.T2.4.4.16.12.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.16.12.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.16.12.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.16.12.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Shen
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.16.12.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib168" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.16.12.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.16.12.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib211" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.16.12.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Honovich et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.16.12.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib74" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.16.12.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.16.12.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.16.12.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Santhanam et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.16.12.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib164" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.16.12.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Shuster et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.16.12.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib169" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.16.12.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.17.13" class="ltx_tr">
<td id="S2.T2.4.4.17.13.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.17.13.1.1" class="ltx_text" style="font-size:80%;">Generative QA</span></td>
<td id="S2.T2.4.4.17.13.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Yin
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.17.13.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib221" title="" class="ltx_ref">2016</a><span id="S2.T2.4.4.17.13.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Bi
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.17.13.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib12" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.17.13.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Fan
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.17.13.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib47" title="" class="ltx_ref">2019a</a><span id="S2.T2.4.4.17.13.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.18.14" class="ltx_tr">
<td id="S2.T2.4.4.18.14.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.18.14.1.1" class="ltx_text" style="font-size:80%;">Data2Text</span></td>
<td id="S2.T2.4.4.18.14.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.18.14.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.18.14.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.18.14.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Parikh et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.18.14.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib141" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.18.14.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang <span id="S2.T2.4.4.18.14.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib195" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.18.14.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Nie
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.18.14.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib138" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.18.14.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Liu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.18.14.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib115" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.18.14.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.18.14.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.18.14.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Rebuffel et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.18.14.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib155" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.18.14.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Nie
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.18.14.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib137" title="" class="ltx_ref">2018</a><span id="S2.T2.4.4.18.14.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.19.15" class="ltx_tr">
<td id="S2.T2.4.4.19.15.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.19.15.1.1" class="ltx_text" style="font-size:80%;">Translation</span></td>
<td id="S2.T2.4.4.19.15.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.19.15.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.19.15.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.19.15.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.19.15.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib154" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.19.15.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Lee et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.19.15.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib96" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.19.15.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.19.15.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.19.15.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Junczys-Dowmunt <span id="S2.T2.4.4.19.15.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib80" title="" class="ltx_ref">2018</a><span id="S2.T2.4.4.19.15.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Briakou and
Carpuat <span id="S2.T2.4.4.19.15.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib16" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.19.15.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.20.16" class="ltx_tr">
<td id="S2.T2.4.4.20.16.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.20.16.1.1" class="ltx_text" style="font-size:80%;">Captioning</span></td>
<td id="S2.T2.4.4.20.16.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Biten
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.20.16.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib14" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.20.16.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.21.17" class="ltx_tr">
<td id="S2.T2.4.4.21.17.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="12"><span id="S2.T2.4.4.21.17.1.1" class="ltx_text" style="font-size:80%;">
<span id="S2.T2.4.4.21.17.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T2.4.4.21.17.1.1.1.1" class="ltx_tr">
<span id="S2.T2.4.4.21.17.1.1.1.1.1" class="ltx_td ltx_align_center">Modeling</span></span>
<span id="S2.T2.4.4.21.17.1.1.1.2" class="ltx_tr">
<span id="S2.T2.4.4.21.17.1.1.1.2.1" class="ltx_td ltx_align_center">and</span></span>
<span id="S2.T2.4.4.21.17.1.1.1.3" class="ltx_tr">
<span id="S2.T2.4.4.21.17.1.1.1.3.1" class="ltx_td ltx_align_center">Inference</span></span>
</span></span></td>
<td id="S2.T2.4.4.21.17.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="S2.T2.4.4.21.17.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.21.17.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.21.17.2.1.1.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.21.17.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Abstractive</span></td>
</tr>
<tr id="S2.T2.4.4.21.17.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.21.17.2.1.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.4.4.21.17.2.1.2.1.1" class="ltx_text" style="font-size:80%;">Summarization</span></td>
</tr>
</table>
</td>
<td id="S2.T2.4.4.21.17.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.21.17.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.21.17.3.1.1" class="ltx_tr">
<td id="S2.T2.4.4.21.17.3.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Huang
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib75" title="" class="ltx_ref">2020a</a><span id="S2.T2.4.4.21.17.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Li
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib104" title="" class="ltx_ref">2018</a><span id="S2.T2.4.4.21.17.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Song et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib171" title="" class="ltx_ref">2020a</a><span id="S2.T2.4.4.21.17.3.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.21.17.3.1.2" class="ltx_tr">
<td id="S2.T2.4.4.21.17.3.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Cao
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib18" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.21.17.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Aralikatte et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib4" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.21.17.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Cao and Wang <span id="S2.T2.4.4.21.17.3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib19" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.21.17.3.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.21.17.3.1.3" class="ltx_tr">
<td id="S2.T2.4.4.21.17.3.1.3.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Chen
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib22" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.21.17.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Albrecht and Hwa <span id="S2.T2.4.4.21.17.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib3" title="" class="ltx_ref">2007</a><span id="S2.T2.4.4.21.17.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Zhao
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.21.17.3.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib235" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.21.17.3.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.22.18" class="ltx_tr">
<td id="S2.T2.4.4.22.18.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.22.18.1.1" class="ltx_text" style="font-size:80%;">Dialogue</span></td>
<td id="S2.T2.4.4.22.18.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.22.18.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.22.18.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.22.18.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Rashkin
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.22.18.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib153" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.22.18.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Balakrishnan et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.22.18.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib7" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.22.18.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Li
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.22.18.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib109" title="" class="ltx_ref">2020c</a><span id="S2.T2.4.4.22.18.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.22.18.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.22.18.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.22.18.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib42" title="" class="ltx_ref">2021a</a><span id="S2.T2.4.4.22.18.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.23.19" class="ltx_tr">
<td id="S2.T2.4.4.23.19.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.23.19.1.1" class="ltx_text" style="font-size:80%;">Generative QA</span></td>
<td id="S2.T2.4.4.23.19.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.23.19.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.23.19.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.23.19.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.23.19.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib103" title="" class="ltx_ref">2021a</a><span id="S2.T2.4.4.23.19.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Krishna
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.23.19.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib89" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.23.19.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Fan
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.23.19.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib47" title="" class="ltx_ref">2019a</a><span id="S2.T2.4.4.23.19.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.23.19.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.23.19.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Nakano et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.23.19.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib134" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.23.19.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Su
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.23.19.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib173" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.23.19.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.24.20" class="ltx_tr">
<td id="S2.T2.4.4.24.20.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.24.20.1.1" class="ltx_text" style="font-size:80%;">Data2Text</span></td>
<td id="S2.T2.4.4.24.20.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.24.20.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.24.20.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.24.20.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Liu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib115" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.24.20.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Xu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib217" title="" class="ltx_ref">2021a</a><span id="S2.T2.4.4.24.20.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Tian
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib185" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.24.20.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib196" title="" class="ltx_ref">2021a</a><span id="S2.T2.4.4.24.20.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib200" title="" class="ltx_ref">2020b</a><span id="S2.T2.4.4.24.20.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.24.20.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.24.20.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Su
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib175" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.24.20.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Rebuffel et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.24.20.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib155" title="" class="ltx_ref">2022</a><span id="S2.T2.4.4.24.20.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Filippova <span id="S2.T2.4.4.24.20.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib51" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.24.20.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Xiao and Wang <span id="S2.T2.4.4.24.20.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib212" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.24.20.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.24.20.2.1.3" class="ltx_tr">
<td id="S2.T2.4.4.24.20.2.1.3.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Puduppully and
Lapata <span id="S2.T2.4.4.24.20.2.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib149" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.24.20.2.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.25.21" class="ltx_tr">
<td id="S2.T2.4.4.25.21.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.4.4.25.21.1.1" class="ltx_text" style="font-size:80%;">Translation</span></td>
<td id="S2.T2.4.4.25.21.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S2.T2.4.4.25.21.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.4.4.25.21.2.1.1" class="ltx_tr">
<td id="S2.T2.4.4.25.21.2.1.1.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Feng
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib50" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.25.21.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Weng
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib206" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.25.21.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Lee et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib96" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.25.21.2.1.1.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.25.21.2.1.2" class="ltx_tr">
<td id="S2.T2.4.4.25.21.2.1.2.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib108" title="" class="ltx_ref">2020a</a><span id="S2.T2.4.4.25.21.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Raunak
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib154" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.25.21.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Wang and Sennrich <span id="S2.T2.4.4.25.21.2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib194" title="" class="ltx_ref">2020</a><span id="S2.T2.4.4.25.21.2.1.2.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.25.21.2.1.3" class="ltx_tr">
<td id="S2.T2.4.4.25.21.2.1.3.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib238" title="" class="ltx_ref">2021b</a><span id="S2.T2.4.4.25.21.2.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Bengio
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.3.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib10" title="" class="ltx_ref">2015</a><span id="S2.T2.4.4.25.21.2.1.3.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
<tr id="S2.T2.4.4.25.21.2.1.4" class="ltx_tr">
<td id="S2.T2.4.4.25.21.2.1.4.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Goyal
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib63" title="" class="ltx_ref">2017</a><span id="S2.T2.4.4.25.21.2.1.4.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Xu
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.25.21.2.1.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib216" title="" class="ltx_ref">2019</a><span id="S2.T2.4.4.25.21.2.1.4.1.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.4.4.26.22" class="ltx_tr">
<td id="S2.T2.4.4.26.22.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T2.4.4.26.22.1.1" class="ltx_text" style="font-size:80%;">Captioning</span></td>
<td id="S2.T2.4.4.26.22.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><cite class="ltx_cite ltx_citemacro_citet">Xiao and Wang <span id="S2.T2.4.4.26.22.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib212" title="" class="ltx_ref">2021</a><span id="S2.T2.4.4.26.22.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span>; Dai
et al<span class="ltx_text">.</span> <span id="S2.T2.4.4.26.22.2.1.1.1.1" class="ltx_text" style="font-size:80%;">(</span><a href="#bib.bib29" title="" class="ltx_ref">2022b</a><span id="S2.T2.4.4.26.22.2.2.2.2.1" class="ltx_text" style="font-size:80%;">)</span></cite></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Evaluation metrics and mitigation methods for each task. *The hallucination metrics are not specifically proposed for generative question answering (GQA), but they can be adapted for that task. </figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Contributors to Hallucination in NLG</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Hallucination from Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The main cause of hallucination from data is source-reference divergence. This divergence happens 1) as an artifact of heuristic data collection or 2) due to the nature of some NLG tasks that inevitably contain such divergence. When a model is trained on data with source-reference(target) divergence, the model can be encouraged to generate text that is not necessarily grounded and not faithful to the provided source.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Heuristic data collection</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">When collecting large-scale datasets, some works heuristically select and pair real sentences or tables as the source and target <cite class="ltx_cite ltx_citemacro_citep">(Lebret
et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2016</a>; Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>)</cite>. As a result, the target reference may contain information that cannot be supported by the source <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib195" title="" class="ltx_ref">2019</a>; Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>)</cite>.
For instance, when constructing WIKIBIO <cite class="ltx_cite ltx_citemacro_citep">(Lebret
et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2016</a>)</cite>, a dataset for generating biographical notes based on the infoboxes of Wikipedia, the authors took the Wikipedia infobox as the source and the first sentence of the Wikipedia page as the target ground-truth reference. However, the first sentence of the Wikipedia article is not necessarily equivalent to the infobox in terms of the information they contain. Indeed, <cite class="ltx_cite ltx_citemacro_citet">Dhingra et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> points out that 62% of the first sentences in WIKIBIO have additional information not stated in the corresponding infobox. Such mismatch between source and target in datasets can lead to hallucination.</p>
</div>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.1" class="ltx_p">Another problematic scenario is when duplicates from the dataset are not properly filtered out. It is almost impossible to check hundreds of gigabytes of text corpora manually. <cite class="ltx_cite ltx_citemacro_citet">Lee et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2021</a>)</cite> show that duplicated examples
from the pretraining corpus bias the model to favor generating repeats of the memorized phrases from the duplicated examples.
</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Innate divergence</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">Some NLG tasks by nature do not always have factual knowledge alignment between the source input text and the target reference, especially those that value diversity in generated output.
For instance, it is acceptable for open-domain dialogue systems to respond in chit-chat style, subjective style <cite class="ltx_cite ltx_citemacro_citep">(Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>)</cite>, or with a relevant fact that is not necessarily present in the user input, history or provided knowledge source – this improves the engagingness and diversity of the dialogue generation. However, researchers have discovered that such dataset characteristic leads to inevitable extrinsic hallucinations.
</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Hallucination from Training and Inference</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As discussed in the previous subsection, source-reference divergence existing in dataset is one of the contributors of hallucination. However, <cite class="ltx_cite ltx_citemacro_citet">Parikh et al<span class="ltx_text">.</span> (<a href="#bib.bib141" title="" class="ltx_ref">2020</a>)</cite> show that hallucination problem still occurs even when there is very little divergence in dataset. This is because there is another contributor of hallucinations – training and modeling choices of neural models <cite class="ltx_cite ltx_citemacro_citep">(Vinyals and Le, <a href="#bib.bib191" title="" class="ltx_ref">2015</a>; Koehn and Knowles, <a href="#bib.bib86" title="" class="ltx_ref">2017a</a>; Rohrbach et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2018</a>; Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Imperfect representation learning</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">The encoder has the role of comprehending and encoding input text into meaningful representations. An encoder with a defective comprehension ability could influence the degree of hallucination <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>)</cite>.
When encoders learn wrong correlations between different parts of the training data, it could result in erroneous generation that diverges from the input <cite class="ltx_cite ltx_citemacro_citep">(Tian
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020</a>; Feng
et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>; Aralikatte et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Erroneous decoding</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">The decoder takes the encoded input from the encoder and generates the final target sequence. Two aspects of decoding contribute to hallucinations. First, decoders can attend to the wrong part of the encoded input source, leading to erroneous generation <cite class="ltx_cite ltx_citemacro_citep">(Tian
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020</a>)</cite>.
Such wrong association results in generation with facts mixed up between two similar entities <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite>.
Second, the design of the decoding strategy itself can contribute to hallucinations.
<cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite> illustrate that a decoding strategy that improves the generation diversity, such as top-k sampling, is positively correlated with increased hallucination. We conjecture that deliberately added “randomness” by sampling from the top-k samples instead of choosing the most probable token increase the unexpected nature of the generation, leading to a higher chance of containing hallucinated content.
</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Exposure Bias</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">Regardless of decoding strategy choices, the exposure bias problem <cite class="ltx_cite ltx_citemacro_citep">(Bengio
et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2015</a>; Ranzato
et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2016</a>)</cite>, defined as the discrepancy in decoding between training and inference time, can be another contributor to hallucination.
It is common practice to train the decoder with teacher-forced maximum likelihood estimation (MLE) training, where the decoder is encouraged to predict the next token conditioned on the ground-truth prefix sequences. However, during the inference generation, the model generates the next token conditioned on the historical sequences previously generated by itself <cite class="ltx_cite ltx_citemacro_citep">(He
et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2021</a>)</cite>. Such a discrepancy can lead to increasingly erroneous generation, especially when the target sequence gets longer.
</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parametric knowledge bias</h5>

<div id="S3.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p1.1" class="ltx_p">Pre-training of models on a large corpus is known to result in the model memorizing knowledge in its parameters <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al<span class="ltx_text">.</span>, <a href="#bib.bib143" title="" class="ltx_ref">2019</a>; Roberts
et al<span class="ltx_text">.</span>, <a href="#bib.bib159" title="" class="ltx_ref">2020</a>; Madotto
et al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2020b</a>)</cite>. This so-called parametric knowledge helps improve the performance of downstream tasks, but also serves as another contributor to hallucinatory generation. Large pre-trained models used for downstream NLG tasks are powerful in providing generalizability and coverage, but <cite class="ltx_cite ltx_citemacro_citet">Longpre et al<span class="ltx_text">.</span> (<a href="#bib.bib116" title="" class="ltx_ref">2021</a>)</cite> have discovered that such models prioritize parametric knowledge over the provided input. In other words, models that favor generating output with their parametric knowledge instead of the information from the input source can result in the hallucination of excess information in the output.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Metrics Measuring Hallucination</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Recently, various studies have illustrated that most conventional metrics used to measure the quality of writing are not adequate for quantifying the level of hallucination <cite class="ltx_cite ltx_citemacro_citep">(Reiter, <a href="#bib.bib157" title="" class="ltx_ref">2018</a>)</cite>. It has been shown that state-of-the-art abstractive summarization systems, evaluated with metrics such as ROUGE, BLEU, and METEOR, have hallucinated content in 25% of their generated summaries <cite class="ltx_cite ltx_citemacro_citep">(Falke et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite>. A similar phenomenon has been shown in other NLG tasks, where it has been discovered that traditional metrics have a poor correlation with human judgment in terms of the hallucination problem <cite class="ltx_cite ltx_citemacro_citep">(Krishna
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2021</a>; Dhingra et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>; Durmus
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Honovich et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite>.
Therefore, there are active research efforts to define effective metrics for quantifying hallucination.
<span id="S4.p1.1.1" class="ltx_text" style="color:#000000;">FRANK <cite class="ltx_cite ltx_citemacro_citep">(Pagnoni
et al<span class="ltx_text">.</span>, <a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite> surveys the faithfulness metrics for summarization and compares these metrics’ correlations with human judgments. To assess the example-level accuracy of metrics in diverse tasks, TRUE <cite class="ltx_cite ltx_citemacro_citep">(Honovich
et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2022</a>)</cite> reports their Area Under the ROC Curve (ROC AUC) in regard to hallucinated example detection.
</span>
</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Statistical Metric</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">One of the simplest approaches is to leverage lexical features (n-grams) to calculate the information overlap and contradictions between the generated and the reference texts – the higher the mismatch counts, the lower the faithfulness and thus the higher the hallucination score.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Given that many traditional metrics leverage the target text as the ground-truth reference (e.g., ROUGE, BLEU, etc.), <cite class="ltx_cite ltx_citemacro_citet">Dhingra et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> build upon this idea and propose PARENT (Precision And Recall of Entailed n-grams from the Table) <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that PARENT is a general metric like ROUGE and BLEU, not only constrained to hallucination</span></span></span>, a metric which can also measure hallucinations using <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">both</span> the source and target text as references.
Particularly, PARENT n-gram lexical entailment matches generated text with both the source table and target text. The F1-score that combines the precision and recall of the entailment reflects the accuracy in the table-to-text task.
The source text is additionally used because it is not guaranteed that the output target text contains the complete set of information available in the input source text.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">It is common for NLG tasks to have multiple plausible outputs from the same input, which is known as one-to-many mapping <cite class="ltx_cite ltx_citemacro_citep">(Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib174" title="" class="ltx_ref">2020</a>; Guan and Huang, <a href="#bib.bib65" title="" class="ltx_ref">2020</a>)</cite>.
In practice, however, covering all the possible outputs is too expensive and almost impossible. Thus, many works simplify the hallucination evaluation setup by relying on the source text as the sole reference. Their metrics just focus on the information referred by input sources to measure hallucinations, especially intrinsic hallucinations.
For instance, <cite class="ltx_cite ltx_citemacro_citet">Wang
et al<span class="ltx_text">.</span> (<a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite> propose PARENT-T, which simplifies PARENT by only using table content as the reference.
Similarly, Knowledge F1 <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>)</cite> – a variant of unigram F1 – has been proposed for knowledge-grounded dialogue tasks to measure the overlap between the model’s generation and the knowledge used to ground the dialogue during dataset collection.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Martindale et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2019</a>)</cite> proposed a bag-of-vectors sentence similarity (BVSS) metric for measuring sentence adequacy in machine translation, that only refers to the target text. This statistical metric helps to determine whether the MT output has a different amount of information than the translation reference.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">Although simple and effective, one potential limitation of the lexical matching is that it can only handle the lexical information. Thus, it fails to deal with syntactic or semantic variations <cite class="ltx_cite ltx_citemacro_citep">(Sellam
et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Model-based Metric</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="color:#000000;">Model-based metrics leverage neural models to measure the hallucination degree in the generated text. They are proposed to handle more complex syntactic and even semantic variations. The model-based metrics comprehend the source and generated texts and detect the knowledge/content mismatches.</span> However, the neural models can be subject to errors that can propagate and adversely affect the accurate quantification of hallucination.
</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Information Extraction (IE)-based</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">It is not always easy to determine which part of the generated text contains the knowledge that requires verification. IE-based metrics use IE models to represent the knowledge in a simpler relational tuple format (e.g., <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">subject, relation, object</span>), then verify against relation tuples extracted from the source/reference.
Here, the IE model is identifying and extracting the “facts” that require verification. In this way, words containing no verifiable information (e.g., stopwords, conjunctions, etc) are not included in the verification step.
</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">For example, ground-truth reference text <span id="S4.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_typewriter">‘‘Brad Pitt was born in 1963’’</span> and generated text <span id="S4.SS2.SSS1.p2.1.2" class="ltx_text ltx_font_typewriter">‘‘Brad Pitt was born in 1961’’</span> will be mapped to the relation triples <span id="S4.SS2.SSS1.p2.1.3" class="ltx_text ltx_font_typewriter">(Brad Pitt, born-in, 1963)</span> and <span id="S4.SS2.SSS1.p2.1.4" class="ltx_text ltx_font_typewriter">(Brad Pitt, born-in, 1961)</span> respectively <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>This is an example from <cite class="ltx_cite ltx_citemacro_citep">(Goodrich
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite></span></span></span>. The mismatch between the dates (1963<math id="S4.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mo id="S4.SS2.SSS1.p2.1.m1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.1.m1.1b"><neq id="S4.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.1.m1.1c">\neq</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.1.m1.1d">≠</annotation></semantics></math>1961) indicates that there is hallucination.
One limitation associated with this approach is the potential error propagation from the IE model.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>QA-based</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">This approach implicitly measures the knowledge overlap or consistency between the generation and the source reference. This is based on the intuition that similar answers will be generated from a same question if the generation is factually consistent with the source reference. It is already put in use to evaluate hallucinations in many tasks, such as summarization <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text" style="color:#000000;"> <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib192" title="" class="ltx_ref">2020a</a>; Durmus
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Scialom et al<span class="ltx_text">.</span>, <a href="#bib.bib165" title="" class="ltx_ref">2021</a>)</cite>, dialogue <cite class="ltx_cite ltx_citemacro_citep">(Honovich et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite>, and data2text generation <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel
et al<span class="ltx_text">.</span>, <a href="#bib.bib156" title="" class="ltx_ref">2021</a>)</cite></span>.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">QA-based metric that measures the faithfulness of the generated text is consisted of three parts: First, given a generated text, a question generation (QG) model generates a set of question-answer pairs.
Second, a question answering (QA) model answers the generated questions given a ground-truth source text as the reference (containing knowledge). Lastly, the hallucination score is computed based on the similarity of the corresponding answers.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p id="S4.SS2.SSS2.p3.1" class="ltx_p">Similar to the IE-based metrics, the limitation of this approach is the potential error that might arise and propagated from either the QG model or the QA model.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Natural Language Inference (NLI) Metrics</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">There are not many labelled datasets for hallucination detection tasks, especially at the early stage when the hallucination problem starts to gain attention. As an alternative, many works leverage the NLI dataset to tackle hallucinations. Note that NLI is a task that determines whether a “hypothesis” is true (entailment), false (contradiction), or undetermined (neutral) given a “premise”. These metrics are based on the idea that only the source knowledge reference should entail the entirety of the information in faithful and hallucination-free generation  <cite class="ltx_cite ltx_citemacro_citep">(Williams
et al<span class="ltx_text">.</span>, <a href="#bib.bib207" title="" class="ltx_ref">2018</a>; Falke et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2019</a>; Mishra et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2021</a>; Kryscinski et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2020</a>; Dušek and
Kasner, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>; Honovich et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021</a>; Laban
et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2022</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2021b</a>)</cite>.
More specifically, NLI-based metrics define the hallucination/faithfulness score to be the entailment probability between the source and its generated text, also known as the percentage of times generated text entails, neutral to, and contradicts the source.
</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p">According to <cite class="ltx_cite ltx_citemacro_citet">Honovich et al<span class="ltx_text">.</span> (<a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite>, NLI-based approaches are more robust to lexical variability than token matching approaches such as IE-based and QA-based metrics. Nevertheless, as illustrated by <cite class="ltx_cite ltx_citemacro_citet">Falke et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite>, off-the-shelf NLI models tend to transfer poorly to the abstractive summarization task. Thus, there is a line of research in improving and extending the NLI paradigm specifically for hallucination evaluation purposes <cite class="ltx_cite ltx_citemacro_citep">(Falke et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2019</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2021b</a>)</cite>. Apart from generalizability, <cite class="ltx_cite ltx_citemacro_citet">Goyal and Durrett (<a href="#bib.bib64" title="" class="ltx_ref">2020</a>)</cite> point out the potential limitation of using sentence-level entailment models, namely their incapability to pinpoint and locate which parts of the generation are erroneous. In response, the authors propose a new dependency-level entailment and attempt to identify factual inconsistencies in a more fine-grained manner.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4. </span>Faithfulness Classification Metrics</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">To improve upon NLI-based metrics, task-specific datasets are constructed to improve from the NLI-based metrics.
<cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>); Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib114" title="" class="ltx_ref">2021a</a>)</cite> constructed syntactic data by automatically inserting hallucinations into training instances.
<cite class="ltx_cite ltx_citemacro_citet">Santhanam et al<span class="ltx_text">.</span> <span id="S4.SS2.SSS4.p1.1.1.1.1.1" class="ltx_text" style="color:#000000;">(</span><a href="#bib.bib164" title="" class="ltx_ref">2021</a><span id="S4.SS2.SSS4.p1.1.2.2.2.1" class="ltx_text" style="color:#000000;">)</span></cite><span id="S4.SS2.SSS4.p1.1.3" class="ltx_text" style="color:#000000;"> and <cite class="ltx_cite ltx_citemacro_citet">Honovich et al<span class="ltx_text">.</span> (<a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite> construct new corpora for faithfulness classification in dialogue responses. They manually annotate the Wizard-of-Wikipedia dataset <cite class="ltx_cite ltx_citemacro_citep">(Dinan et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>, a knowledge grounded dialog dataset, by judging whether each response is hallucinated.</span></p>
</div>
<div id="S4.SS2.SSS4.p2" class="ltx_para">
<p id="S4.SS2.SSS4.p2.1" class="ltx_p">Faithfulness specific datasets can be better than NLI datasets because entailment or neutral labels of NLI datasets and faithfulness are not equivalent.
For example, the hypothesis “Putin is U.S. president” can be considered to be either neutral to or entailed from the premise “Putin is president”. However, from the faithfulness perspective, the hypothesis contains unsupported information “U.S.”, which is deemed to be hallucination.
</p>
</div>
</section>
<section id="S4.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.5. </span>LM-based Metrics</h4>

<div id="S4.SS2.SSS5.p1" class="ltx_para">
<p id="S4.SS2.SSS5.p1.3" class="ltx_p">These metrics leverage two language models (LMs) to determine if each token is supported or not:
An unconditional LM is only trained on the targets (ground-truth references) in the dataset, while a conditional language model <math id="S4.SS2.SSS5.p1.1.m1.1" class="ltx_Math" alttext="LM_{x}" display="inline"><semantics id="S4.SS2.SSS5.p1.1.m1.1a"><mrow id="S4.SS2.SSS5.p1.1.m1.1.1" xref="S4.SS2.SSS5.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS5.p1.1.m1.1.1.2" xref="S4.SS2.SSS5.p1.1.m1.1.1.2.cmml">L</mi><mo id="S4.SS2.SSS5.p1.1.m1.1.1.1" xref="S4.SS2.SSS5.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.SS2.SSS5.p1.1.m1.1.1.3" xref="S4.SS2.SSS5.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.SSS5.p1.1.m1.1.1.3.2" xref="S4.SS2.SSS5.p1.1.m1.1.1.3.2.cmml">M</mi><mi id="S4.SS2.SSS5.p1.1.m1.1.1.3.3" xref="S4.SS2.SSS5.p1.1.m1.1.1.3.3.cmml">x</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p1.1.m1.1b"><apply id="S4.SS2.SSS5.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1"><times id="S4.SS2.SSS5.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.1"></times><ci id="S4.SS2.SSS5.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.2">𝐿</ci><apply id="S4.SS2.SSS5.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS5.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.3.2">𝑀</ci><ci id="S4.SS2.SSS5.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.3.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p1.1.m1.1c">LM_{x}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS5.p1.1.m1.1d">italic_L italic_M start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math> is trained on both source and target data.
It is assumed that the next token is inconsistent with the input if unconditional LM gets a smaller loss than conditional <math id="S4.SS2.SSS5.p1.2.m2.1" class="ltx_Math" alttext="LM_{x}" display="inline"><semantics id="S4.SS2.SSS5.p1.2.m2.1a"><mrow id="S4.SS2.SSS5.p1.2.m2.1.1" xref="S4.SS2.SSS5.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS5.p1.2.m2.1.1.2" xref="S4.SS2.SSS5.p1.2.m2.1.1.2.cmml">L</mi><mo id="S4.SS2.SSS5.p1.2.m2.1.1.1" xref="S4.SS2.SSS5.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S4.SS2.SSS5.p1.2.m2.1.1.3" xref="S4.SS2.SSS5.p1.2.m2.1.1.3.cmml"><mi id="S4.SS2.SSS5.p1.2.m2.1.1.3.2" xref="S4.SS2.SSS5.p1.2.m2.1.1.3.2.cmml">M</mi><mi id="S4.SS2.SSS5.p1.2.m2.1.1.3.3" xref="S4.SS2.SSS5.p1.2.m2.1.1.3.3.cmml">x</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p1.2.m2.1b"><apply id="S4.SS2.SSS5.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1"><times id="S4.SS2.SSS5.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.1"></times><ci id="S4.SS2.SSS5.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.2">𝐿</ci><apply id="S4.SS2.SSS5.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS5.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS2.SSS5.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.3.2">𝑀</ci><ci id="S4.SS2.SSS5.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2.SSS5.p1.2.m2.1.1.3.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p1.2.m2.1c">LM_{x}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS5.p1.2.m2.1d">italic_L italic_M start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math> during forced-path decoding <cite class="ltx_cite ltx_citemacro_citep">(Filippova, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>; Tian
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020</a>)</cite>.
We classify the generated token as hallucinatory if the loss from LM is lower. The ratio of hallucinated tokens to the total number of target tokens <math id="S4.SS2.SSS5.p1.3.m3.1" class="ltx_Math" alttext="|y|" display="inline"><semantics id="S4.SS2.SSS5.p1.3.m3.1a"><mrow id="S4.SS2.SSS5.p1.3.m3.1.2.2" xref="S4.SS2.SSS5.p1.3.m3.1.2.1.cmml"><mo stretchy="false" id="S4.SS2.SSS5.p1.3.m3.1.2.2.1" xref="S4.SS2.SSS5.p1.3.m3.1.2.1.1.cmml">|</mo><mi id="S4.SS2.SSS5.p1.3.m3.1.1" xref="S4.SS2.SSS5.p1.3.m3.1.1.cmml">y</mi><mo stretchy="false" id="S4.SS2.SSS5.p1.3.m3.1.2.2.2" xref="S4.SS2.SSS5.p1.3.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p1.3.m3.1b"><apply id="S4.SS2.SSS5.p1.3.m3.1.2.1.cmml" xref="S4.SS2.SSS5.p1.3.m3.1.2.2"><abs id="S4.SS2.SSS5.p1.3.m3.1.2.1.1.cmml" xref="S4.SS2.SSS5.p1.3.m3.1.2.2.1"></abs><ci id="S4.SS2.SSS5.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS5.p1.3.m3.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p1.3.m3.1c">|y|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS5.p1.3.m3.1d">| italic_y |</annotation></semantics></math> can reflect the hallucination degree.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Human Evaluation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Due to the challenging and imperfect nature of the current automatic evaluation of hallucinations in NLG, human evaluation <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>; Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>)</cite> is still one of the most commonly used approaches.
There are two main forms of human evaluation: (1) scoring, where human annotators rate the hallucination level in a range;
and (2) comparing, where human annotators compare the output texts with baselines or ground-truth references <cite class="ltx_cite ltx_citemacro_citep">(Sun, <a href="#bib.bib177" title="" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Multiple terminologies, such as
<span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">faithfulness</span> <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>; Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2018</a>; Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021b</a>; Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>; Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>; Filippova, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>; Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>; Tian
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020</a>; Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>; Xiao and Wang, <a href="#bib.bib212" title="" class="ltx_ref">2021</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite>,
<span id="S4.SS3.p2.1.3" class="ltx_text ltx_font_italic">factual consistency</span> <cite class="ltx_cite ltx_citemacro_citep">(Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>; Cao and Wang, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>; Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib168" title="" class="ltx_ref">2021</a>; Wu
et al<span class="ltx_text">.</span>, <a href="#bib.bib211" title="" class="ltx_ref">2021</a>; Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>, <span id="S4.SS3.p2.1.4" class="ltx_text ltx_font_italic">fidelity</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021a</a>)</cite>,
<span id="S4.SS3.p2.1.5" class="ltx_text ltx_font_italic">factualness<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><span id="footnote4.5" class="ltx_text ltx_font_upright">uses the source input as the “fact”. </span></span></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2022</a>)</cite>,
<span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">factuality<math id="S4.SS3.p2.1.1.m1.1" class="ltx_Math" alttext="{}^{4}" display="inline"><semantics id="S4.SS3.p2.1.1.m1.1a"><msup id="S4.SS3.p2.1.1.m1.1.1" xref="S4.SS3.p2.1.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.1.m1.1.1a" xref="S4.SS3.p2.1.1.m1.1.1.cmml"></mi><mn mathvariant="normal" id="S4.SS3.p2.1.1.m1.1.1.1" xref="S4.SS3.p2.1.1.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.1.m1.1b"><apply id="S4.SS3.p2.1.1.m1.1.1.cmml" xref="S4.SS3.p2.1.1.m1.1.1"><cn type="integer" id="S4.SS3.p2.1.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.1.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.1.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.1.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math></span> <cite class="ltx_cite ltx_citemacro_citep">(Dong
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite>,
or on the other hand, <span id="S4.SS3.p2.1.6" class="ltx_text ltx_font_italic">hallucination</span> <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2020a</a>; Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>; Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021a</a>; Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2021b</a>)</cite>,
<span id="S4.SS3.p2.1.7" class="ltx_text ltx_font_italic">fact contradicting</span> <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2018</a>)</cite>
are used in the human evaluation of hallucination to rate whether the generated text is in accord with the source input.
<cite class="ltx_cite ltx_citemacro_citet">Chen
et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2021b</a>); Nie
et al<span class="ltx_text">.</span> (<a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite> use finer-grained metrics for <span id="S4.SS3.p2.1.8" class="ltx_text ltx_font_italic">intrinsic hallucination</span> and <span id="S4.SS3.p2.1.9" class="ltx_text ltx_font_italic">extrinsic hallucination</span> separately.
Moreover, there are some broad metrics, such as <span id="S4.SS3.p2.1.10" class="ltx_text ltx_font_italic">Correctness</span> <cite class="ltx_cite ltx_citemacro_citep">(Balakrishnan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>; Bi
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2018</a>)</cite>,
<span id="S4.SS3.p2.1.11" class="ltx_text ltx_font_italic">Accuracy</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin
et al<span class="ltx_text">.</span>, <a href="#bib.bib221" title="" class="ltx_ref">2016</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite>,
and <span id="S4.SS3.p2.1.12" class="ltx_text ltx_font_italic">Informativeness</span> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite>
considering both missing and additional contents (extrinsic hallucinations) compared to the input source.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Hallucination Mitigation Methods</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Common mitigation methods can be divided into two categories, in accordance with two main contributors of hallucinations: <span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Data-Related Methods</span>, and <span id="S5.p1.1.2" class="ltx_text ltx_font_bold">Modeling and Inference Methods</span>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Data-Related Methods</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Building a Faithful Dataset</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Considering that noisy data encourage hallucinations, constructing faithful datasets manually is an intuitive method, and there are various ways to build such datasets:
One way is employing annotators to write clean and faithful targets from scratch given the source <cite class="ltx_cite ltx_citemacro_citep">(Gardent et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2017</a>; Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib205" title="" class="ltx_ref">2015b</a>)</cite>, which may lack diversity <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>; Gururangan et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2018</a>; Poliak et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2018</a>)</cite>.
Another way is employing annotators to rewrite real sentences on the web <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>)</cite>,
or targets in the existing dataset <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib195" title="" class="ltx_ref">2019</a>)</cite>.
Basically, the revision strategy consists of three stages:
(1) phrase trimming: removing phrases unsupported by the source in the exemplar sentence;
(2) decontextualization: resolving co-references and deleting phrases dependent on context;
(3) syntax modification: making the purified sentences flow smoothly.
Meanwhile, other works <cite class="ltx_cite ltx_citemacro_citep">(Honovich et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021</a>; Gabriel et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite> leverage the model to generate data and instruct annotators to label whether these outputs contain hallucinations or not.
While this approach is typically used to build diagnostic evaluation datasets, it has the potential to build faithful datasets.
</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Cleaning Data Automatically</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">In order to alleviate semantic noise issues, another approach is to find information that is irrelevant or contradictory to the input from the existing parallel corpus and then filter or correct the data. This approach is suitable for the case where there is a low or moderate level of noise in the original data <cite class="ltx_cite ltx_citemacro_citep">(Filippova, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>; Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p">Some works <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2021b</a>; Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib168" title="" class="ltx_ref">2021</a>; Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite> have dealt with the hallucination issue at the instance level by using a score for each source-reference pair and filtering out hallucinated ones.
This corpus filtering method consists of several steps:
(1) measuring the quality of the training samples in terms of hallucination utilizing the metrics described above;
(2) ranking these hallucination scores in descending order;
(3) selecting and filtering out the untrustworthy samples at the bottom.
Instance-level scores can lead to a signal loss because divergences occur at the word level; i.e., parts of the target sentence are loyal to the source input, while others diverge <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para">
<p id="S5.SS1.SSS2.p3.1" class="ltx_p">Considering this issue, other works <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>; Dušek
et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2019</a>)</cite> correct paired training samples, specifically the input data, according to the references. This method is mainly applied in the data-to-text task because structured data are easier to correcte than utterances.
This method consists of two steps: (1) utilizing a model to parse the meaning representation (MR), such as attribute-value pairs, from original human textual references; (2) using the MR extracted from the reference to correct the input MR through slot matching.
This method will enhance the semantic consistency between input and output without abandoning a part of the dataset.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Information Augmentation</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">It is intuitive that augmenting the inputs with external information will obtain a better representation of the source. Because the external knowledge, explicit alignment, extra training data, etc., can improve the correlation between the source and target and help the model learn better task-related features. Consequently, a better semantic understanding helps alleviate the divergence from the source issue.
Examples of the augmented information include entity information <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2021b</a>)</cite>,
extracted relation triples from source document <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2020a</a>; Cao
et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite> obtained by Fact Description Extraction, <span id="S5.SS1.SSS3.p1.1.1" class="ltx_text" style="color:#000000;">pre-executed operation results <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2018</a>)</cite>,</span>
synthetic data generated through replacement or perturbation  <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021b</a>; Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>,
retrieved external knowledge <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>; Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib241" title="" class="ltx_ref">2021</a>; Gunel
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2019</a>; Bi
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Fan
et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2019a</a>)</cite>, and retrieved similar training samples <cite class="ltx_cite ltx_citemacro_citep">(Białecki et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2012</a>)</cite>.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">These methods enforce a stronger alignment between inputs and outputs.
However, they will bring challenges due to the gap between the original source and augmented information, such as the semantic gap between an ambiguous utterance and a distinct MR of structured data,
and the format discrepancy between the structured knowledge graph and natural language.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Modeling and Inference Methods</h3>

<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Architecture</h4>

<section id="S5.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Encoder</h5>

<div id="S5.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px1.p1.1" class="ltx_p">The encoder learns to encode a variable-length sequence from input text into a fixed-length vector representation.
As we mentioned above in Section <a href="#S5.SS1.SSS3" title="5.1.3. Information Augmentation ‣ 5.1. Data-Related Methods ‣ 5. Hallucination Mitigation Methods ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.3</span></a>,
<span id="S5.SS2.SSS1.Px1.p1.1.1" class="ltx_text" style="color:#000000;">hallucination appears when the models lack semantic interpretation over the input.</span>
Some works have modified the encoder architecture in order to make it more compatible with input <span id="S5.SS2.SSS1.Px1.p1.1.2" class="ltx_text" style="color:#000000;">and learn a better representation</span>.
For example, <cite class="ltx_cite ltx_citemacro_citet">Huang
et al<span class="ltx_text">.</span> (<a href="#bib.bib75" title="" class="ltx_ref">2020a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Cao
et al<span class="ltx_text">.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite> propose a dual encoder, consisting of a sequential document encoder and a structured graph encoder to deal with the additional knowledge.
</p>
</div>
</section>
<section id="S5.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Attention</h5>

<div id="S5.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px2.p1.1" class="ltx_p">The attention mechanism is an integral component in neural networks that selectively concentrates on some parts of sequences while ignoring others based on dependencies <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2017</a>)</cite>.
In order to encourage the generator to pay more attention to the source, <cite class="ltx_cite ltx_citemacro_citet">Aralikatte et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> introduce a short circuit from the input document to the vocabulary distribution via source-conditioned bias.
<cite class="ltx_cite ltx_citemacro_citet">Krishna
et al<span class="ltx_text">.</span> (<a href="#bib.bib89" title="" class="ltx_ref">2021</a>)</cite> employ sparse attention to improve the model‘s long-range dependencies in the hope of modeling more retrieved documents so as to mitigate the hallucination in the answer.
<cite class="ltx_cite ltx_citemacro_citet">Wu
et al<span class="ltx_text">.</span> (<a href="#bib.bib211" title="" class="ltx_ref">2021</a>)</cite> adopt inductive attention, which removes potentially uninformative attention links by injecting pre-established structural information to avoid hallucinations.</p>
</div>
</section>
<section id="S5.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Decoder</h5>

<div id="S5.SS2.SSS1.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p1.1" class="ltx_p">The decoder is responsible for generating the final output in natural language given input representations <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2017</a>)</cite>.
Several work modified the decoder structures to mitigate hallucination, such as
the multi-branch decoder <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2022</a>)</cite>,
uncertainty-aware decoder <cite class="ltx_cite ltx_citemacro_citep">(Xiao and Wang, <a href="#bib.bib212" title="" class="ltx_ref">2021</a>)</cite>,
dual decoder, consisting of a sequential decoder and a tree-based decoder <cite class="ltx_cite ltx_citemacro_citep">(Song et al<span class="ltx_text">.</span>, <a href="#bib.bib171" title="" class="ltx_ref">2020a</a>)</cite>,
and constrained decoder with lexical or structural limitations <cite class="ltx_cite ltx_citemacro_citep">(Balakrishnan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>.
<span id="S5.SS2.SSS1.Px3.p1.1.1" class="ltx_text" style="color:#000000;">Based on the observation that the “randomness” from sampling-based decoding, especially near the end of sentences, can lead to hallucination, <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2022</a>)</cite> propose to iteratively reduce the “randomness” through time. </span>
These decoders improve the possibility of faithful tokens while reducing the possibility of hallucinatory ones during inference by figuring out the implicit discrepancy and dependency between tokens or restricted by explicit constraints.
<span id="S5.SS2.SSS1.Px3.p1.1.2" class="ltx_text" style="color:#000000;">Since such decoders may have more difficulty generating fluent or diverse text, there is a balance to be struck between them.</span></p>
</div>
</section>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Training</h4>

<figure id="S5.F1" class="ltx_figure"><img src="modeling.png" id="S5.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span id="S5.F1.2.1" class="ltx_text" style="color:#000000;">The frameworks of training methods.</span></figcaption>
</figure>
<section id="S5.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Planning/Sketching</h5>

<div id="S5.SS2.SSS2.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px1.p1.1" class="ltx_p">Planning is a common method to control and restrict what the model generates by informing the content and its order<span id="S5.SS2.SSS2.Px1.p1.1.1" class="ltx_text" style="color:#000000;"> <cite class="ltx_cite ltx_citemacro_citep">(Puduppully
et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2019</a>)</cite></span>. Planning can be a separate step in a two-step generator<span id="S5.SS2.SSS2.Px1.p1.1.2" class="ltx_text" style="color:#000000;"> <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2021b</a>; Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>; Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021b</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>; Puduppully and
Lapata, <a href="#bib.bib149" title="" class="ltx_ref">2021</a>)</cite>, which is prone to progressive amplification of the hallucination problem.</span>
Or be injected into the end-to-end model during generation <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib217" title="" class="ltx_ref">2021a</a>)</cite>.
Sketching has a similar function to planning, and can also be adopted for handling hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>)</cite>. The difference is that the skeleton is treated as a part of the final generated text.
<span id="S5.SS2.SSS2.Px1.p1.1.3" class="ltx_text" style="color:#000000;">While providing more controllability, such methods also need to strike a balance between faithfulness and diversity.</span>
</p>
</div>
</section>
<section id="S5.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Reinforcement Learning (RL)</h5>

<div id="S5.SS2.SSS2.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px2.p1.1" class="ltx_p">As pointed out by <cite class="ltx_cite ltx_citemacro_citet">Ranzato
et al<span class="ltx_text">.</span> (<a href="#bib.bib152" title="" class="ltx_ref">2016</a>)</cite>, word-level maximum likelihood training leads to the problem of exposure bias.
Some works <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2020a</a>; Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>; Kong
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2019</a>; Mesgar
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2021</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite> adopt RL to solve the hallucination problem, which utilizes different rewards to optimize the model.
The purpose of RL is for the agent to learn an optimal policy that maximizes the reward that accumulates from the environment <cite class="ltx_cite ltx_citemacro_citep">(Uc-Cetina et al<span class="ltx_text">.</span>, <a href="#bib.bib189" title="" class="ltx_ref">2021</a>)</cite>.The reward function is critical to RL and, if properly designed, it can provide training signals that help the model accomplish its goal of hallucination reduction.
For example, <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite> propose a slot consistency reward which is the cardinality of the difference between generated template and the slot-value pairs extracted from input dialogue act. Improving the slot consistency can help reduce the hallucination phenomenon of missing or misplacing slot values in generated templates.
<cite class="ltx_cite ltx_citemacro_citet">Mesgar
et al<span class="ltx_text">.</span> (<a href="#bib.bib129" title="" class="ltx_ref">2021</a>)</cite> attain persona consistency sub-reward via an NLI model to reduce the hallucinations in personal facts.
<cite class="ltx_cite ltx_citemacro_citet">Huang
et al<span class="ltx_text">.</span> (<a href="#bib.bib75" title="" class="ltx_ref">2020a</a>)</cite> use a combination of ROUGE and the multiple-choice cloze score as the reward function to improve the faithfulness of summarization outputs. The cloze score is similar to the QA-based metric, measuring how well a QA model can address the questions by reading the generated summary (as context), where the questions are automatically constructed from the reference summary.
As the above examples show, some RL reward functions for mitigating hallucination are inspired by existing automatic evaluation metrics.
<span id="S5.SS2.SSS2.Px2.p1.1.1" class="ltx_text" style="color:#000000;">Although RL is challenging to learn and converge due to the extremely large search space, this method has the potential to obtain the best policy for the task without an oracle.</span>
</p>
</div>
</section>
<section id="S5.SS2.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Multi-task Learning</h5>

<div id="S5.SS2.SSS2.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px3.p1.1" class="ltx_p">Multi-task learning is also utilized for handling hallucinations in different NLG tasks.
In this training paradigm, a shared model is trained on multiple tasks simultaneously to learn the commonalities of the tasks. The hallucination problem may be derived from the reliance of the training process on a single dataset, leading to the fact that the model fails to learn the actual task features. By adding proper additional tasks along with the target task during training, the model can suffer less from the hallucination problem.
For example, <cite class="ltx_cite ltx_citemacro_citet">Weng
et al<span class="ltx_text">.</span> (<a href="#bib.bib206" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Garg
et al<span class="ltx_text">.</span> (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite> incorporate a word alignment task into the translation model to improve the alignment accuracy between the input and output, and thus faithfulness.
<cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib104" title="" class="ltx_ref">2018</a>)</cite> combine an entailment task with abstractive summarization to encourage models to generate summaries entailed by and faithful to the source.
<cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite> incorporate rationale extraction and the answer generation, which allows more confident and correct answers and reduces the hallucination problem.
The Multi-task approach has several advantages, such as data efficiency improvement, overfitting reduction, and fast learning. It is crucial to choose which tasks should be learned jointly, and learning multiple tasks simultaneously presents new challenges of design and optimization <cite class="ltx_cite ltx_citemacro_citep">(Crawshaw, <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite>.
</p>
</div>
</section>
<section id="S5.SS2.SSS2.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Controllable Generation</h5>

<div id="S5.SS2.SSS2.Px4.p1" class="ltx_para">
<p id="S5.SS2.SSS2.Px4.p1.1" class="ltx_p">Current works treat the hallucination level as a controllable attribute in order to remain the hallucination in outputs at a low level.
Controllable generation techniques <span id="S5.SS2.SSS2.Px4.p1.1.1" class="ltx_text" style="color:#000000;">such as controlled re-sampling <cite class="ltx_cite ltx_citemacro_citep">(Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>)</cite>, control codes that can be provided manually <cite class="ltx_cite ltx_citemacro_citep">(Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>; Filippova, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>; Wu
et al<span class="ltx_text">.</span>, <a href="#bib.bib211" title="" class="ltx_ref">2021</a>)</cite>, or predicted automatically <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a href="#bib.bib211" title="" class="ltx_ref">2021</a>)</cite></span> are leveraged to improve faithfulness.
<span id="S5.SS2.SSS2.Px4.p1.1.2" class="ltx_text" style="color:#000000;">This method may require some annotated datasets for training.</span>
Considering that hallucination is not necessarily harmful and may bring some benefits, controllable methods can be further adapted to change the degree of hallucination to meet the demands of different real-world applications.
</p>
</div>
<div id="S5.SS2.SSS2.Px4.p2" class="ltx_para">
<p id="S5.SS2.SSS2.Px4.p2.1" class="ltx_p">Other general training methods such as regularization <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>; Müller
et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2020</a>; Kang and
Hashimoto, <a href="#bib.bib83" title="" class="ltx_ref">2020b</a>)</cite> and loss reconstruction <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib200" title="" class="ltx_ref">2020b</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2020a</a>; Wang and Sennrich, <a href="#bib.bib194" title="" class="ltx_ref">2020</a>)</cite> have also been proposed to tackle the hallucination problem.
</p>
</div>
</section>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3. </span>Post-Processing</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">Post-processing methods can correct hallucinations in the output, and this standalone task requires less training data. Especially for noisy datasets where a large proportion of the ground truth references suffer from hallucinations, modeling correction is a competitive choice to handle the hallucination problem <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021b</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Chen
et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2021b</a>); Dong
et al<span class="ltx_text">.</span> (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>); Cao
et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite> follow a generate-then-refine strategy.
<span id="S5.SS2.SSS3.p1.1.1" class="ltx_text" style="color:#000000;">While the post-processing correction step tends to result in ungrammatical texts, this method</span> allows researchers to utilise SOTA models which perform best in respect of other attributes, such as fluency, and then correct the results specifically for faithfulness by using small amounts of automatically generated training data.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Future Directions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Many studies have been conducted to tackle the hallucination problem in NLG and its downstream tasks.
As mentioned above, we have discussed common metrics and mitigation methods to advance research in these fields.
From a broader perspective, we wish to point out open challenges and potential directions in regard to <span id="S6.p1.1.1" class="ltx_text ltx_font_bold">metric</span> and <span id="S6.p1.1.2" class="ltx_text ltx_font_bold">mitigation method</span>.
</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Future Directions in Metrics Design</h3>

<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fine-grained Metrics</h5>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">Most of the existing hallucination metrics measure intrinsic and extrinsic hallucinations together as a unified metric. However, it is common for a single generation to have both types and a number of hallucinatory sub-strings. Fine-grained metrics that can distinguish between the two types of hallucinations will provide richer insight to researchers.</p>
</div>
<div id="S6.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p2.1" class="ltx_p">In order to implement a fine-graded metric, the first step would be to identify the exact location of the hallucinatory sub-strings correctly. However, some metrics such as those that are QA-based cannot identify the individual hallucinatory sub-strings. Improvements in this aspect would help improve the quality and explainability of the metrics.
The next step would be to categorize the detected hallucinatory sub-strings. The hallucinatory sub-string will be intrinsic if it is wrong or nonsensical, and extrinsic if it is non-existing in the source context. Future work that explores an automatic method of categorization would be beneficial.
</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fact-Checking</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.1" class="ltx_p">The factual verification of extrinsic hallucinations requires fact-checking against world knowledge, which can be time consuming and laborious.
Leveraging an automatic fact-checking system for extrinsic hallucination verification is, thus, other future work that requires attention.
Fact-checking consists of the knowledge evidence selection and claim verification sub-tasks, and the following are the remaining challenges associated with each sub-task.</p>
</div>
<div id="S6.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p2.1" class="ltx_p">The main research problem associated with the evidence selection sub-task is how to retrieve evidence from the <span id="S6.SS1.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_italic">world</span> knowledge. Most of the literature leverages Wikipedia as the knowledge source <cite class="ltx_cite ltx_citemacro_citep">(Thorne et al<span class="ltx_text">.</span>, <a href="#bib.bib183" title="" class="ltx_ref">2018</a>; Yoneda et al<span class="ltx_text">.</span>, <a href="#bib.bib222" title="" class="ltx_ref">2018</a>; Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2020</a>)</cite>, which is only a small part of world knowledge. Other literature attempts to use the whole web as the knowledge source
 <cite class="ltx_cite ltx_citemacro_citep">(Etzioni
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2008</a>; Magdy and Wanas, <a href="#bib.bib124" title="" class="ltx_ref">2010</a>)</cite>. However, this method leads to another research problem – “how to ensure the trustworthiness of the information we use from the web” <cite class="ltx_cite ltx_citemacro_citep">(Ginsca
et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2015</a>)</cite>. Source-level methods that leverages the meta-information of the web source (e.g., web traffic, PageRank or URL structure) have been proposed to deal with this trustworthiness issue <cite class="ltx_cite ltx_citemacro_citep">(Popat et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2016</a>; Baly et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>; Popat
et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2018</a>)</cite>.
Addressing the aforementioned issues to allow evidence selection against world knowledge will be an important future research direction.</p>
</div>
<div id="S6.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p3.1" class="ltx_p">For the verification subtask, verification models perform relatively well if given correct evidence <cite class="ltx_cite ltx_citemacro_citep">(Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">[n. d.]</a>)</cite>. However, it has been shown that verification models are prone to adversarial attacks and are not robust to negation, numerical or comparative words <cite class="ltx_cite ltx_citemacro_citep">(Thorne et al<span class="ltx_text">.</span>, <a href="#bib.bib184" title="" class="ltx_ref">2019</a>)</cite>.
Improving this weakness of verification models would also be crucial because the factuality of a sentence can easily be changed by small word changes (i.e., changes in negations, numbers, and entities).</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Generalization</h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">Although we can see that the source and output text of different tasks are in various forms,
investigating their relationship and common ground and proposing general metrics to evaluate hallucinations are worth exploring. Task-agnostic metrics with cross-domain robustness could help the research community to build a unified benchmark.
It is also important and meaningful to build open-source platforms to collaborate and standardize the evaluation metrics for NLG tasks.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Incorporation of Human Cognitive Perspective</h5>

<div id="S6.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p1.1" class="ltx_p">A good automatic metric should correlate with human evaluation.
Humans are sensitive to different types of information. For instance, proper nouns are usually more important than pronouns in the generated text. Mistakes concerning named entities are striking to human users, but automatic metrics treat them equally if not properly designed. In order to address this issue, new metrics should be designed from the human cognitive perspective.
The human ability to recognize salient information and filter the rest is evident in scenarios where the most important facts need to be determined and assessed. For instance, when signing an agreement, a prospective employee naturally skims the document to look at the entries with numbers first. In this way, humans classify what they believe is crucial.
</p>
</div>
<div id="S6.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p2.1" class="ltx_p">Automatic check-worthy detection has the potential to be applied to improve the correlation with human judgement.
Implementing the automatic human-like judgment mentioned above can further mitigate hallucination and improve NLG systems.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Future Directions in Mitigation Methods</h3>

<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">General and robust data pre-processing approaches</h5>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">Since the data format varies between downstream tasks, there is still a gap for data processing methods between tasks, and currently, no universal method is effective for all NLG tasks <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2021b</a>)</cite>.
Data pre-processing might result in grammatical errors or semantic transformation between the original and processed data, which can negatively affect the performance of generation.
Therefore, we believe that general and robust data pre-processing methods can help mitigate the hallucinations in NLG.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Hallucinations in numerals</h5>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p1.3" class="ltx_p">Most existing mitigation methods do not focus on the hallucination of numerals. However, the correctness of numerals in generated text, such as date, quantities and scalars are important for readers <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib235" title="" class="ltx_ref">2020</a>; Thawani et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib231" title="" class="ltx_ref">2020b</a>)</cite>.
For example, given the source document “<span id="S6.SS2.SSS0.Px2.p1.3.3" class="ltx_text ltx_font_italic">The optimal oxygen saturation (<math id="S6.SS2.SSS0.Px2.p1.1.1.m1.1" class="ltx_Math" alttext="SpO_{2}" display="inline"><semantics id="S6.SS2.SSS0.Px2.p1.1.1.m1.1a"><mrow id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml"><mi id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.2" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.2.cmml">S</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.3" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.3.cmml">p</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1a" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1.cmml">⁢</mo><msub id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.cmml"><mi id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.2" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.2.cmml">O</mi><mn mathvariant="normal" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.3" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1b"><apply id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1"><times id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.1"></times><ci id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.2">𝑆</ci><ci id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.3.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.3">𝑝</ci><apply id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.1.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4">subscript</csymbol><ci id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.2.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.2">𝑂</ci><cn type="integer" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.3.cmml" xref="S6.SS2.SSS0.Px2.p1.1.1.m1.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1c">SpO_{2}</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px2.p1.1.1.m1.1d">italic_S italic_p italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>) in adults with COVID-19 who are receiving supplemental oxygen is unknown. However, a target <math id="S6.SS2.SSS0.Px2.p1.2.2.m2.1" class="ltx_Math" alttext="SpO_{2}" display="inline"><semantics id="S6.SS2.SSS0.Px2.p1.2.2.m2.1a"><mrow id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.cmml"><mi id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.2" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.2.cmml">S</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1.cmml">⁢</mo><mi id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.3" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.3.cmml">p</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1a" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1.cmml">⁢</mo><msub id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.cmml"><mi id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.2" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.2.cmml">O</mi><mn mathvariant="normal" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.3" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1b"><apply id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1"><times id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.1"></times><ci id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.2.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.2">𝑆</ci><ci id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.3.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.3">𝑝</ci><apply id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.1.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4">subscript</csymbol><ci id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.2.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.2">𝑂</ci><cn type="integer" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.3.cmml" xref="S6.SS2.SSS0.Px2.p1.2.2.m2.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1c">SpO_{2}</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px2.p1.2.2.m2.1d">italic_S italic_p italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> of 92% to 96% seems logical, considering that indirect evidence from patients without COVID-19 suggests that an <math id="S6.SS2.SSS0.Px2.p1.3.3.m3.1" class="ltx_Math" alttext="SpO_{2}" display="inline"><semantics id="S6.SS2.SSS0.Px2.p1.3.3.m3.1a"><mrow id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.cmml"><mi id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.2" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.2.cmml">S</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1.cmml">⁢</mo><mi id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.3" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.3.cmml">p</mi><mo mathvariant="italic" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1a" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1.cmml">⁢</mo><msub id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.cmml"><mi id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.2" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.2.cmml">O</mi><mn mathvariant="normal" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.3" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1b"><apply id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1"><times id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.1"></times><ci id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.2.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.2">𝑆</ci><ci id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.3.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.3">𝑝</ci><apply id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.1.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4">subscript</csymbol><ci id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.2.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.2">𝑂</ci><cn type="integer" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.3.cmml" xref="S6.SS2.SSS0.Px2.p1.3.3.m3.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1c">SpO_{2}</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px2.p1.3.3.m3.1d">italic_S italic_p italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> of ¡92% or ¿96% may be harmful.</span> <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a href="https://www.covid19treatmentguidelines.nih.gov/management/critical-care/oxygenation-and-ventilation/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.covid19treatmentguidelines.nih.gov/management/critical-care/oxygenation-and-ventilation/</a></span></span></span>”, the summary “<span id="S6.SS2.SSS0.Px2.p1.3.4" class="ltx_text ltx_font_italic">The target oxygen saturation range for patients with COVID-19 is 82–86%.</span>” includes wrong numbers, which could be fatal.
Currently, some works <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>; Thawani et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib231" title="" class="ltx_ref">2020b</a>)</cite> point out that using commonsense knowledge can help to gain better numeral representation. And <cite class="ltx_cite ltx_citemacro_citet">Zhao
et al<span class="ltx_text">.</span> (<a href="#bib.bib235" title="" class="ltx_ref">2020</a>)</cite> alleviate numeral hallucinations by re-ranking candidate-generated summaries based on the verification score of quantity entities.
Therefore, we believe that explicitly modeling numerals to mitigate hallucinations is a potential direction.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Extrinsic Hallucination Mitigation</h5>

<div id="S6.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px3.p1.1" class="ltx_p">Though many works on mitigating hallucinations have been published, most do not distinguish between intrinsic and extrinsic hallucination. Moreover, the main research focus has been on dealing with intrinsic hallucination, while extrinsic hallucination has been somewhat overlooked as it is more challenging to reduce <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite>. Therefore, we believe it is worth exploring different mitigation methods for intrinsic and extrinsic hallucinations, and relevant methods in fact-checking can be potentially used for this purpose.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Hallucination in long text</h5>

<div id="S6.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px4.p1.1" class="ltx_p">Many tasks in NLG require the model to process long input texts, such as multi-document summarization and generative question answering. We think adopting existing approaches to a Longformer <cite class="ltx_cite ltx_citemacro_citep">(Beltagy
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>-based model could help encode long inputs. Meanwhile, part of dialogue systems need to generate long output text, in which the latter part may contradict history generation. Therefore, reducing self-contradiction is also an important future direction.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Reasoning</h5>

<div id="S6.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px5.p1.1" class="ltx_p">Misunderstanding facts in the source context will lead to intrinsic hallucination and errors. To help models understand the facts correctly requires reasoning over the input table or text. Moreover, if the generated text can be reasoned backwards to the source, we can assume it is faithful. There are some reasoning works in the area of dialogue <cite class="ltx_cite ltx_citemacro_citep">(Cui
et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2020</a>; Ghosal et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2021</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib199" title="" class="ltx_ref">2021b</a>)</cite>, but few in reducing hallucinations. Moreover, tasks with quantities, such as logical table-to-text generation, require numerical reasoning. Therefore, adding reasoning ability to the hallucination mitigation methods is also an interesting future direction.
</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Controllability</h5>

<div id="S6.SS2.SSS0.Px6.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px6.p1.1" class="ltx_p">Controllability means the ability of models to control the level of hallucination and strike a balance between faithfulness and diversity <cite class="ltx_cite ltx_citemacro_citep">(Rohrbach et al<span class="ltx_text">.</span>, <a href="#bib.bib160" title="" class="ltx_ref">2018</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite>. As mentioned in Section <a href="#S3" title="3. Contributors to Hallucination in NLG ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, it is acceptable for chit-chat models to generate a certain level of hallucinatory content as long as it is factual. Meanwhile, for the abstractive summarization task, there is no agreement in the research community about whether factual hallucinations are desirable or not <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite>.
Therefore, we believe controllability merits attention when exploring hallucination mitigation methods.
</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Hallucination in Abstractive Summarization</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Abstractive summarization aims to extract essential information from source documents and to generate short, concise, and readable summaries <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib223" title="" class="ltx_ref">2021</a>)</cite>. Neural networks have achieved remarkable results on abstractive summarization. However, <cite class="ltx_cite ltx_citemacro_citet">Maynez
et al<span class="ltx_text">.</span> (<a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite> observe that neural abstractive summarization models are likely to generate hallucinatory content that is unfaithful to the source document. <cite class="ltx_cite ltx_citemacro_citet">Falke et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite> analyze three recent abstractive summarization systems and show that 25% of the summaries generated from state-of-the-art models have hallucinated content. In addition, <cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> mention that even if a summary contains a large amount of hallucinatory content, it can achieve a high ROUGE <cite class="ltx_cite ltx_citemacro_citep">(Lin, <a href="#bib.bib110" title="" class="ltx_ref">2004</a>)</cite> score. This has encouraged researchers to actively devise ways to improve the evaluation of abstractive summarization, especially from the hallucination perspective.
</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In this section, we review the current progress in automatic evaluation and the mitigation of hallucination, and list the remaining challenges for future work. In addition, it is worth mentioning that researchers have used various terms to describe the hallucination phenomenon, such as faithfulness, factual errors, and factual consistency, and we will use the original terms from their papers in the remainder of this section.
</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Hallucination Definition in Abstractive Summarization</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">The definition of hallucination in abstractive summarization follows that in Section <a href="#S2" title="2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Specifically, we adopt the definition from <cite class="ltx_cite ltx_citemacro_citep">(Maynez
et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2020</a>)</cite>: given a document and its abstractive summary, a summary is hallucinated if it has any spans not supported by the input document.
Once again, intrinsic hallucination refers to output content that contradicts the source, while extrinsic hallucination refers to output content that the source cannot verify.
For instance, in Table 3, given the input article shown in the caption,
an example of intrinsic hallucination is “<span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_italic">The Ebola vaccine was rejected by the FDA in 2019,</span>” because this statement contradicts the given content “<span id="S7.SS1.p1.1.2" class="ltx_text ltx_font_italic">The first vaccine for Ebola was approved by the FDA in 2019 in the US</span>”.
And an example of extrinsic hallucination is “<span id="S7.SS1.p1.1.3" class="ltx_text ltx_font_italic">China has already started clinical trials of the COVID-19 vaccine,</span>” because this statement is not mentioned in the given content. We can neither find evidence of it from the input article nor assert that it is wrong.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Pagnoni
et al<span class="ltx_text">.</span> (<a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite> define fine-grained types of factual errors in summaries.
As mentioned in <a href="#S2.SS3" title="2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>, since the “fact” here refers to source knowledge, “factual error” can be treated as hallucination, and we can adopt this classification as a sub-type of hallucination.
They establish three categories as semantic frame error, discourse error, and content verifiability error.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Hallucination Metrics in Abstractive Summarization</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Existing metrics for hallucination in abstractive summarization are mainly model-based. Following <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2021</a>)</cite>, we divide the hallucination metrics into two categories: (1) unsupervised metrics and (2) semi-supervised metrics.
Note that existing hallucination metrics evaluate both intrinsic and extrinsic hallucinations together in one metric because it is difficult to automatically distinguish between them.</p>
</div>
<section id="S7.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.1. </span>Unsupervised Metrics</h4>

<div id="S7.SS2.SSS1.p1" class="ltx_para">
<p id="S7.SS2.SSS1.p1.1" class="ltx_p">Given that hallucination is a newly emerging problem, there are only a few hallucination-related datasets. Therefore, researchers have proposed to adopt other datasets to build unsupervised hallucination metrics. There are three types of such unsupervised metrics: (1) information extraction (IE)-based metrics, (2) natural language inferencing (NLI)-based metrics, (3) question answering (QA)-based metrics.</p>
</div>
<section id="S7.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">IE-based Metrics</h5>

<div id="S7.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S7.SS2.SSS1.Px1.p1.1" class="ltx_p">As mentioned in Section <a href="#S4" title="4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, IE-based metrics leverage IE models to extract knowledge as relation tuples (<span id="S7.SS2.SSS1.Px1.p1.1.1" class="ltx_text ltx_font_italic">subject, relation, object</span>) from both the generation and knowledge source to analyze the factual accuracy of the generation <cite class="ltx_cite ltx_citemacro_citep">(Goodrich
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite>. However, IE models are not 100% reliable yet (making errors in the identification of the relation tuples). Therefore, <cite class="ltx_cite ltx_citemacro_citet">Nan et al<span class="ltx_text">.</span> (<a href="#bib.bib135" title="" class="ltx_ref">2021</a>)</cite> propose an entity-based metric relying on the Named-Entity Recognition model, which is relatively more robust. Their metric builds on the assumption that there will be a different set of named entities in the gold and generated summary if there exists hallucination.</p>
</div>
</section>
<section id="S7.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">NLI-based Metrics</h5>

<div id="S7.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S7.SS2.SSS1.Px2.p1.1" class="ltx_p">As mentioned in Section <a href="#S4" title="4. Metrics Measuring Hallucination ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the NLI-model (textual entailment model) can be utilized to measure hallucination based on the assumption that a faithful summary will be entailed by the gold source.
However, <cite class="ltx_cite ltx_citemacro_citet">Falke et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2019</a>)</cite> discover that models trained on NLI datasets can not transfer well to abstractive summarization tasks, degrading the reliability of NLI-based hallucination metrics. To improve NLI models for hallucination evaluation, they release collected annotations as additional test data. Other efforts have also been made to further improve NLI models. <cite class="ltx_cite ltx_citemacro_citet">Mishra et al<span class="ltx_text">.</span> (<a href="#bib.bib132" title="" class="ltx_ref">2021</a>)</cite> find that the low performance of NLI-based metrics is mainly caused by the length of the premises in NLI datasets being shorter than the source documents in abstractive summarization. Thus, the authors propose to convert multiple-choice reading comprehension datasets into long premise NLI datasets automatically. The results indicate that long-premise NLI datasets help the model achieve a higher performance than the original NLI datasets. In addition, <cite class="ltx_cite ltx_citemacro_citet">Laban
et al<span class="ltx_text">.</span> (<a href="#bib.bib94" title="" class="ltx_ref">2022</a>)</cite> introduce a simple but efficient method called SUMMAC<math id="S7.SS2.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="{}_{Conv}" display="inline"><semantics id="S7.SS2.SSS1.Px2.p1.1.m1.1a"><msub id="S7.SS2.SSS1.Px2.p1.1.m1.1.1" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.cmml"><mi id="S7.SS2.SSS1.Px2.p1.1.m1.1.1a" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.cmml"></mi><mrow id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.cmml"><mi id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.2" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.2.cmml">C</mi><mo id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.3" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.3.cmml">o</mi><mo id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1a" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.4" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.4.cmml">n</mi><mo id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1b" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1.cmml">⁢</mo><mi id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.5" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.5.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.SSS1.Px2.p1.1.m1.1b"><apply id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1"><apply id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1"><times id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.1"></times><ci id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.2.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.2">𝐶</ci><ci id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.3.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.3">𝑜</ci><ci id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.4.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.4">𝑛</ci><ci id="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.5.cmml" xref="S7.SS2.SSS1.Px2.p1.1.m1.1.1.1.5">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.SSS1.Px2.p1.1.m1.1c">{}_{Conv}</annotation><annotation encoding="application/x-llamapun" id="S7.SS2.SSS1.Px2.p1.1.m1.1d">start_FLOATSUBSCRIPT italic_C italic_o italic_n italic_v end_FLOATSUBSCRIPT</annotation></semantics></math> by applying NLI models to sentence units that are segmented from documents. The performance of their model is better than applying NLI models to the whole document.
</p>
</div>
</section>
<section id="S7.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">QA-based Metrics</h5>

<div id="S7.SS2.SSS1.Px3.p1" class="ltx_para">
<p id="S7.SS2.SSS1.Px3.p1.1" class="ltx_p">QA-based metrics measure the knowledge overlap or consistency between summaries and the source documents based on the intuition that QA models will achieve similar answers if the summaries are factually consistent with the source documents. QA-based metrics such as FEQA <cite class="ltx_cite ltx_citemacro_citep">(Durmus
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>, QAGS <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib192" title="" class="ltx_ref">2020a</a>)</cite><span id="S7.SS2.SSS1.Px3.p1.1.1" class="ltx_text" style="color:#000000;">, and QuestEval <cite class="ltx_cite ltx_citemacro_citep">(Scialom et al<span class="ltx_text">.</span>, <a href="#bib.bib165" title="" class="ltx_ref">2021</a>)</cite> follow</span> three steps to obtain a final score: (1) a QG model generates questions from the summaries, (2) a QA model obtains answers from the source documents, and (3) calculate the score by comparing the set of answers from source documents and the set of answers from summaries.
The results show that <span id="S7.SS2.SSS1.Px3.p1.1.2" class="ltx_text" style="color:#000000;">these reference-free metrics</span> have substantially higher correlations with human judgments of faithfulness than the baseline metrics.
<cite class="ltx_cite ltx_citemacro_citet">Gabriel et al<span class="ltx_text">.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite> further analyze the FEQA and find that the effectiveness of QA-based metrics depends on the question. They also provide a meta-evaluation framework that includes QA metrics.</p>
</div>
</section>
</section>
<section id="S7.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.2. </span>Semi-Supervised Metrics</h4>

<div id="S7.SS2.SSS2.p1" class="ltx_para">
<p id="S7.SS2.SSS2.p1.1" class="ltx_p">Semi-supervised metrics are trained on the synthetic data generated from summarization datasets. Trained on these task-specific corpora, models can judge whether the generated summaries are hallucinatory.
<cite class="ltx_cite ltx_citemacro_citet">Kryscinski et al<span class="ltx_text">.</span> (<a href="#bib.bib90" title="" class="ltx_ref">2020</a>)</cite> propose a weakly supervised model named FactCC for evaluating factual consistency. The model is trained jointly for three tasks: (1) checking whether the synthetic sentences remain factually consistent, (2) extracting supporting spans in the source documents, and (3) extracting inconsistent spans in the summaries, if any exist.
They transfer this model to check whether the summaries generated from summarization models are factually consistent. Results show that the performance of their FactCC model surpasses the classifiers trained on the MNLI or FEVER datasets. <cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> introduce a method to fine-tune a pre-trained language model on synthetic data with automatically inserted hallucinations in order to detect the hallucinatory content in summaries. The model can classify whether spans in the machine-generated summaries are faithful to the article. This method shows higher correlations with human factual consistency evaluation than the baselines.</p>
</div>
</section>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3. </span>Hallucination Mitigation in Abstractive Summarization</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">Recently, many approaches have been proposed to reduce the hallucination phenomenon in abstractive summarization.</p>
</div>
<section id="S7.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.1. </span>Architecture Method.</h4>

<div id="S7.SS3.SSS1.p1" class="ltx_para">
<p id="S7.SS3.SSS1.p1.1" class="ltx_p">Seq-to-seq <cite class="ltx_cite ltx_citemacro_citep">(Sutskever
et al<span class="ltx_text">.</span>, <a href="#bib.bib179" title="" class="ltx_ref">2014</a>)</cite> models are widely used and achieve state-of-the-art performance in abstractive summarization. Researchers have made modifications to the architecture design of the seq-to-seq models to reduce hallucinated content in the summaries. We describe various efforts made to improve the encoder, decoder, or both the encoder and decoder of the seq-to-seq models.</p>
</div>
<section id="S7.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Encoder</h5>

<div id="S7.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S7.SS3.SSS1.Px1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib241" title="" class="ltx_ref">2021</a>)</cite> propose to use an explicit graph neural network (GNN) to encode the fact tuples extracted from source documents. In addition to an explicit graph encoder, <cite class="ltx_cite ltx_citemacro_citet">Huang
et al<span class="ltx_text">.</span> (<a href="#bib.bib75" title="" class="ltx_ref">2020a</a>)</cite> further design a multiple-choice cloze test reward to encourage the model to better understand entity interactions. Moreover, <cite class="ltx_cite ltx_citemacro_citet">Gunel
et al<span class="ltx_text">.</span> (<a href="#bib.bib66" title="" class="ltx_ref">2019</a>)</cite> use external knowledge from Wikipedia to make knowledge embeddings, which the results show improve factual consistency.</p>
</div>
</section>
<section id="S7.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Decoder</h5>

<div id="S7.SS3.SSS1.Px2.p1" class="ltx_para">
<p id="S7.SS3.SSS1.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Song et al<span class="ltx_text">.</span> (<a href="#bib.bib171" title="" class="ltx_ref">2020a</a>)</cite> present the incorporation of a sequential decoder with a tree-based decoder to generate a summary sentence and its syntactic parse. This joint generation is performed improve faithfulness. <cite class="ltx_cite ltx_citemacro_citet">Aralikatte et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> introduce the Focus Attention Mechanism, which encourages decoders to generate tokens similar or topical to the source documents. The results on the BBC extreme summarization task show that models augmented with the Focus Attention Mechanism generate more faithful summaries.</p>
</div>
</section>
<section id="S7.SS3.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Encoder-decoder</h5>

<div id="S7.SS3.SSS1.Px3.p1" class="ltx_para">
<p id="S7.SS3.SSS1.Px3.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Cao
et al<span class="ltx_text">.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite> extract fact descriptions from the source text and apply a dual-attention seq-to-seq framework to force the summaries to be conditioned on both source documents and the extracted fact descriptions. <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib104" title="" class="ltx_ref">2018</a>)</cite> propose an entailment-aware encoder and decoder with multi-task learning which incorporates the entailment knowledge into abstractive summarization models.</p>
</div>
</section>
</section>
<section id="S7.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.2. </span>Training Method</h4>

<div id="S7.SS3.SSS2.p1" class="ltx_para">
<p id="S7.SS3.SSS2.p1.1" class="ltx_p">Aside from architecture modification, some works improved the training approach to reduce hallucination. <cite class="ltx_cite ltx_citemacro_citet">Cao and Wang (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite> introduce a contrastive learning method to train summarization models. The positive training data are reference summaries, while the negative training data are automatically generated hallucinatory summaries, and the contrastive learning system is trained to distinguish between them. In the dialogue summarization field, <cite class="ltx_cite ltx_citemacro_citet">Tang et al<span class="ltx_text">.</span> (<a href="#bib.bib180" title="" class="ltx_ref">2021</a>)</cite> propose another contrastive fine-tuning strategy, named CONFIT, that can improve the factual consistency and overall quality of summaries.</p>
</div>
</section>
<section id="S7.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.3. </span>Post-Processing Method</h4>

<div id="S7.SS3.SSS3.p1" class="ltx_para">
<p id="S7.SS3.SSS3.p1.1" class="ltx_p">Some works carry out post-editing to reduce the hallucination of the model-generated summaries, which are viewed as draft summaries. <cite class="ltx_cite ltx_citemacro_citet">Dong
et al<span class="ltx_text">.</span> (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite> propose SpanFact, a pair of factual correction models that use knowledge learned from QA models to correct the spans in the generated summaries. Similar to SpanFact, <cite class="ltx_cite ltx_citemacro_citet">Cao
et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite> introduce a post-editing corrector module to identify and correct hallucinatory content in generated summaries. The corrector module is trained on synthetic data which are created by adding a series of heuristic transformations to reference summaries.
<cite class="ltx_cite ltx_citemacro_citet">Zhao
et al<span class="ltx_text">.</span> (<a href="#bib.bib235" title="" class="ltx_ref">2020</a>)</cite> present HERMAN, a system that learns to recognize quantities (dates, amounts of money, etc.) in the generated summary and verify their factual consistency with the source text. According to the quantity hallucination score, the system chooses the most faithful summary where the source text supports its quantity terms from the candidate-generated summaries. <cite class="ltx_cite ltx_citemacro_citet">Chen
et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2021b</a>)</cite> introduce a contrast candidate generation and selection system to do post-processing. The contrast candidate generation model replaces the named entities in the generated summaries with ones present in the source documents, and the contrast candidate selection model will select the best candidate as the final output summary.</p>
</div>
</section>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4. </span>Future Directions in Abstractive Summarization</h3>

<section id="S7.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Factual Hallucination Evaluation</h5>

<div id="S7.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS4.SSS0.Px1.p1.1" class="ltx_p">Factual hallucinations contain information not found in source content, though it is factually correct. In the summarization task, this kind of hallucination could lead to better summaries. However, there is little work focused on evaluating factual hallucination explicitly. Fact-checking approaches could be potentially used in this regard.</p>
</div>
</section>
<section id="S7.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Extrinsic Hallucination Mitigation</h5>

<div id="S7.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS4.SSS0.Px2.p1.1" class="ltx_p">There has been little research on extrinsic hallucinations as it is more challenging to detect and mitigate content based on world knowledge. We believe it is worth exploring extrinsic hallucination in terms of evaluation metrics and mitigation methods.</p>
</div>
</section>
<section id="S7.SS4.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Hallucination in Dialogue Summarization</h5>

<div id="S7.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S7.SS4.SSS0.Px3.p1.1" class="ltx_p">In conversational data, the discourse relations between utterances and co-references between speakers are more complicated than from, say, news articles. For example, <cite class="ltx_cite ltx_citemacro_citet">Zhong et al<span class="ltx_text">.</span> (<a href="#bib.bib236" title="" class="ltx_ref">2021</a>)</cite> show that 74% of samples in the QMSum dataset consist of inconsistent facts. We believe exploring the hallucination issue in dialogue summarization is an important and special component of research into hallucination in abstractive summarization.</p>
</div>
</section>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Hallucination in Dialogue Generation</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Dialogue generation is an NLG task that automatically generates responses according to user utterances. The generated responses are required to be fluent, coherent, and consistent with the dialogue history. The dialogue generation task can be divided into two sub-tasks: (1) task-oriented dialogue generation; (2) open-domain dialogue generation. A task-oriented dialogue system aims to complete a certain task according to a user query in a specific domain, such as restaurant booking, hotel recommendation, and calendar checking. Meanwhile, an open-domain dialogue system aims to establish a multi-turn, long-term conversation with users while providing the users with an engaging experience.</p>
</div>
<section id="S8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1. </span>Hallucination Definition in Dialogue Generation</h3>

<div id="S8.SS1.p1" class="ltx_para">
<p id="S8.SS1.p1.1" class="ltx_p">The hallucination problem also exists in the dialogue generation task. It is important to note that a dialogue system is expected either to provide the user with the required information or to provide an engaging response without repeating utterances from the dialogue history. Thus, the tolerance for producing proper “hallucination” from the dialogue history is relatively higher.</p>
</div>
<div id="S8.SS1.p2" class="ltx_para">
<p id="S8.SS1.p2.1" class="ltx_p">The definition of hallucination in this task can be adopted from the general definition as follows: (1) <span id="S8.SS1.p2.1.1" class="ltx_text ltx_font_bold">Intrinsic hallucination</span>: the generated response is contradictory to the dialogue history or the external knowledge sentences. In the examples of intrinsic hallucination shown in Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we can verify that the output contradicts the inputs: In one example, the input is a “<span id="S8.SS1.p2.1.2" class="ltx_text ltx_font_italic">moderate</span>” price range, but the model mistakenly generates a sentence with a “<span id="S8.SS1.p2.1.3" class="ltx_text ltx_font_italic">high</span>” price range. In another case, the confusion of the names “<span id="S8.SS1.p2.1.4" class="ltx_text ltx_font_italic">Roger Federer</span>” and “<span id="S8.SS1.p2.1.5" class="ltx_text ltx_font_italic">Rafael Nadal</span>” causes the output generation of “<span id="S8.SS1.p2.1.6" class="ltx_text ltx_font_italic">Roger Nadal</span>”. (2) <span id="S8.SS1.p2.1.7" class="ltx_text ltx_font_bold">Extrinsic hallucination</span>: the generated response is hard to verify with the dialogue history or the external knowledge sentences. Responses with extrinsic hallucination are impossible to verify with the given inputs. “<span id="S8.SS1.p2.1.8" class="ltx_text ltx_font_italic">Pickwick hotel</span>” might be “<span id="S8.SS1.p2.1.9" class="ltx_text ltx_font_italic">in san diego</span>”, and Djokovic may have been “<span id="S8.SS1.p2.1.10" class="ltx_text ltx_font_italic">in the top ten singles players of the world</span>”. However, we do not have enough information to check the truth of these statements.</p>
</div>
<div id="S8.SS1.p3" class="ltx_para">
<p id="S8.SS1.p3.1" class="ltx_p">In the following sections, the hallucination problem in open-domain and task-oriented dialogue generation tasks will be separately discussed according to the their natures.
</p>
</div>
</section>
<section id="S8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2. </span>Open-domain Dialogue Generation</h3>

<div id="S8.SS2.p1" class="ltx_para">
<p id="S8.SS2.p1.1" class="ltx_p">While the term “hallucination” seems to have newly emerged in the NLP field, a related behavior, “inconsistency”, of neural models has been widely discussed. This behavior has been pointed out as a shortcoming of generation-based approaches for open-domain chatbots <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2020b</a>; Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2020</a>; Roller et al<span class="ltx_text">.</span>, <a href="#bib.bib161" title="" class="ltx_ref">2020</a>)</cite>.
Two possible types of inconsistency occur in open-domain dialogue generation: (1) inconsistency among the system utterances, such as when the system contradicts its previous utterance; (2) inconsistency with an external source, such as factually incorrect utterances. Whereas the first type is described using the term ”inconsistency” <cite class="ltx_cite ltx_citemacro_citep">(Welleck
et al<span class="ltx_text">.</span>, <a href="#bib.bib203" title="" class="ltx_ref">2019b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2020b</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2021a</a>)</cite> or ”incoherence” <cite class="ltx_cite ltx_citemacro_citep">(Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>; Beyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite>, some have recently started to call the second type ”hallucination” <cite class="ltx_cite ltx_citemacro_citep">(Roller et al<span class="ltx_text">.</span>, <a href="#bib.bib162" title="" class="ltx_ref">2021</a>; Mielke
et al<span class="ltx_text">.</span>, <a href="#bib.bib131" title="" class="ltx_ref">2020</a>)</cite>. Self-inconsistency can be considered as an intrinsic hallucination problem, while the external inconsistency involves both intrinsic and extrinsic hallucinations, depending on the reference source.</p>
</div>
<div id="S8.SS2.p2" class="ltx_para">
<p id="S8.SS2.p2.1" class="ltx_p">As mentioned earlier, a certain level of hallucination may be acceptable in open-domain chit-chat as long as it does not involve severe factual issues. Moreoever, it is almost impossible to verify factual correctness since the system usually lacks a connection to external resources. With the introduction of knowledge-grounded dialogue tasks <cite class="ltx_cite ltx_citemacro_citep">(Zhou
et al<span class="ltx_text">.</span>, <a href="#bib.bib239" title="" class="ltx_ref">2018</a>; Dinan et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>, which provide an external reference, however, there has been more active discussion of hallucination in open-domain dialogue generation.
</p>
</div>
<section id="S8.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.2.1. </span>Self-Consistency</h4>

<div id="S8.SS2.SSS1.p1" class="ltx_para">
<p id="S8.SS2.SSS1.p1.1" class="ltx_p">In end-to-end generative open-domain dialogue systems, the inconsistency among system utterances has been pointed out as the bottleneck to human-level performance  <cite class="ltx_cite ltx_citemacro_citep">(Vinyals and Le, <a href="#bib.bib191" title="" class="ltx_ref">2015</a>)</cite>. We often observe an inconsistency in the answers to semantically similar yet not identical questions. For example, a system may answer the questions of “What is your name?” and “May I ask your name?” with different responses. Persona consistency has been the center of attention <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2016</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018</a>)</cite> and it is one of the most obvious cases of self-contradiction regarding the character of the dialogue system. ”Persona” is defined as the character that a dialogue system plays during a conversation, and can be composed of identity, language behavior, and an interaction style <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2016</a>)</cite>. While some works has set their objective as teaching models to utilize speaker-level embeddings <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2016</a>; Madotto
et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2019</a>)</cite>, others condition generation with a set of descriptions about a persona, which we will discuss in detail in the next section.</p>
</div>
</section>
<section id="S8.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.2.2. </span>External Consistency</h4>

<div id="S8.SS2.SSS2.p1" class="ltx_para">
<p id="S8.SS2.SSS2.p1.1" class="ltx_p">Besides self-consistency, an open-domain dialogue system should also generate persona-consistent and informative responses corresponding so as to user utterances to further engage with the user during conversation. In this process, an external resource containing explicit persona information or world knowledge is introduced into the system to assist the model generation process.</p>
</div>
<div id="S8.SS2.SSS2.p2" class="ltx_para">
<p id="S8.SS2.SSS2.p2.1" class="ltx_p">The PersonaChat datasets <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib229" title="" class="ltx_ref">2018</a>; Dinan
et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> have accelerated research into persona consistency <cite class="ltx_cite ltx_citemacro_citep">(Hancock
et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2019</a>; Kulikov
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019</a>; Mazaré et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2018</a>; Yavuz
et al<span class="ltx_text">.</span>, <a href="#bib.bib220" title="" class="ltx_ref">2019</a>; Zemlyanskiy and
Sha, <a href="#bib.bib225" title="" class="ltx_ref">2018</a>; Wolf
et al<span class="ltx_text">.</span>, <a href="#bib.bib209" title="" class="ltx_ref">2019</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib233" title="" class="ltx_ref">2020c</a>)</cite>. In PersonaChat datasets, each conversation has persona descriptions such as “I like to ski” or “I am a high school teacher” attached. By conditioning the response generation on the persona description, a chit-chat model is expected to acquire an ability to generate a more persona-consistent response. Lately, the application of NLI methods <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2020b</a>; Song
et al<span class="ltx_text">.</span>, <a href="#bib.bib170" title="" class="ltx_ref">2020b</a>)</cite> or reinforcement learning frameworks <cite class="ltx_cite ltx_citemacro_citep">(Mesgar
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2021</a>)</cite> have been investigated. Although these methods conditioned on the PersonaChat datasets have been successful, further investigation of approaches that do not rely on a given set of persona descriptions is necessary because such descriptions are not always available, and covering every aspect of a persona with them is impossible.
</p>
</div>
<div id="S8.SS2.SSS2.p3" class="ltx_para">
<p id="S8.SS2.SSS2.p3.1" class="ltx_p">In addition to PersonaChat-related research, the knowledge-grounded dialogue (KGD) task in the open-domain requires the model to generate informative responses with the help of an external knowledge graph (KG) or knowledge corpus <cite class="ltx_cite ltx_citemacro_citep">(Zhou
et al<span class="ltx_text">.</span>, <a href="#bib.bib239" title="" class="ltx_ref">2018</a>; Dinan et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>. Hallucination in conversations, which is also considered as a factual consistency problem, has raised much research interest recently <cite class="ltx_cite ltx_citemacro_citep">(Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2021a</a>; Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>; Rashkin
et al<span class="ltx_text">.</span>, <a href="#bib.bib153" title="" class="ltx_ref">2021</a>; Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>)</cite>. Here, we continue to split the hallucination problem in the KGD task into intrinsic hallucination and extrinsic hallucination. Most of the KGD works tackle the hallucination problem when responses contain information that contradicts (intrinsic) or cannot be found in the provided knowledge input (extrinsic).
Since world knowledge is enormous and ever-changing, the extrinsic hallucination may be factual but hard to verify. <cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite> further adopt the same definition of hallucination as mentioned above to the knowledge graph-grounded dialogue task, where intrinsic hallucination indicates the case of misusing either the subject or object of the knowledge triple;
and extrinsic hallucination indicates that there is no corresponding valid knowledge triple in the gold reference knowledge.
Recently, there have been some attempts to generate informative responses without explicit knowledge inputs, but with the help of the implicit knowledge inside large pre-trained language models instead <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib218" title="" class="ltx_ref">2021b</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib240" title="" class="ltx_ref">2021a</a>)</cite> during the inference time. Under this setting, the study of extrinsic hallucination is of great value but still poorly investigated.</p>
</div>
</section>
<section id="S8.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.2.3. </span>Hallucination Metrics</h4>

<div id="S8.SS2.SSS3.p1" class="ltx_para">
<p id="S8.SS2.SSS3.p1.1" class="ltx_p">For generation-based dialogue systems, especially open-domain chatbots, the hallucination evaluation method remains an open problem <cite class="ltx_cite ltx_citemacro_citep">(Roller et al<span class="ltx_text">.</span>, <a href="#bib.bib161" title="" class="ltx_ref">2020</a>)</cite>. As of now, there is no standard metric. Therefore, chatbots are usually evaluated by humans on factual consistency or factual correctness <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a href="#bib.bib211" title="" class="ltx_ref">2021</a>; Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>)</cite>. We also introduce some automatic statistical and model-based metrics as a reference, which will be described in more detail below.
</p>
</div>
<section id="S8.SS2.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Variants of F1 Metrics</h5>

<div id="S8.SS2.SSS3.Px1.p1" class="ltx_para">
<p id="S8.SS2.SSS3.Px1.p1.1" class="ltx_p"><span id="S8.SS2.SSS3.Px1.p1.1.1" class="ltx_text ltx_font_bold">Knowledge F1 (KF1)</span> measures the overlap between the generated responses and the gold knowledge sentences to which the human referred for conversation during dataset collection <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a href="#bib.bib169" title="" class="ltx_ref">2021</a>)</cite>. KF1 attempts to capture whether a model can generate knowledgable responses by correctly utilizing the relevant knowledge. KF1 is only available for datasets with labeled ground-truth knowledge. <cite class="ltx_cite ltx_citemacro_citet">Shuster et al<span class="ltx_text">.</span> (<a href="#bib.bib169" title="" class="ltx_ref">2021</a>)</cite> further propose <span id="S8.SS2.SSS3.Px1.p1.1.2" class="ltx_text ltx_font_bold">Rare F1 (RF1)</span>, which only considers the infrequent words in the dataset when calculating F1 to avoid influence from the common uni-grams. The authors define an infrequent word as being in the lower half of the cumulative frequency distribution of the reference corpus.</p>
</div>
</section>
<section id="S8.SS2.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Model-based Metric</h5>

<div id="S8.SS2.SSS3.Px2.p1" class="ltx_para">
<p id="S8.SS2.SSS3.Px2.p1.1" class="ltx_p"><span id="S8.SS2.SSS3.Px2.p1.1.1" class="ltx_text" style="color:#000000;">Natural language has its natural on the flexibility of the surface forms with the same semantics, so overlap-based metrics cannot provide the comprehensive evaluation.</span>
Recently, several works have proposed evaluation metrics for measuring consistency, such as using natural language inference (NLI) <cite class="ltx_cite ltx_citemacro_citep">(Welleck
et al<span class="ltx_text">.</span>, <a href="#bib.bib203" title="" class="ltx_ref">2019b</a>; Dziri
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>, training learnable evaluation metrics <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib226" title="" class="ltx_ref">2021a</a>)</cite>, or releasing an additional test set for coherence <cite class="ltx_cite ltx_citemacro_citep">(Beyer
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite>.
<span id="S8.SS2.SSS3.Px2.p1.1.2" class="ltx_text" style="color:#000000;">These methods are more flexible and supports the generated responses with different surface forms.</span>
For the KGD task, <cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2021b</a>)</cite> propose the BEGIN benchmark, which consists of samples taken from <cite class="ltx_cite ltx_citemacro_citet">Dinan et al<span class="ltx_text">.</span> (<a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite> with additional human annotation and a new classification task extending the NLI paradigm. <cite class="ltx_cite ltx_citemacro_citet">Honovich et al<span class="ltx_text">.</span> (<a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite> present a trainable metric for the KGD task, which also applies NLI. It is also noteworthy that <cite class="ltx_cite ltx_citemacro_citet">Gupta
et al<span class="ltx_text">.</span> (<a href="#bib.bib67" title="" class="ltx_ref">2021</a>)</cite> propose datasets that can benefit fact-checking systems specialized for dialogue systems.
The Conv-FEVER corpus <cite class="ltx_cite ltx_citemacro_citep">(Santhanam et al<span class="ltx_text">.</span>, <a href="#bib.bib164" title="" class="ltx_ref">2021</a>)</cite> is a factual consistency detection dataset, which was created by adapting the Wizard-of-Wikipedia dataset <cite class="ltx_cite ltx_citemacro_citep">(Dinan et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2019</a>)</cite>. It consists of both factually consistent and inconsistent responses and can be used to train a classifier to detect factually inconsistent responses with respect to the knowledge provided.</p>
</div>
</section>
</section>
<section id="S8.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.2.4. </span>Mitigation Methods</h4>

<div id="S8.SS2.SSS4.p1" class="ltx_para">
<p id="S8.SS2.SSS4.p1.1" class="ltx_p">The hallucination issue can be mitigated by data pre-processing, which includes introducing extra information into the data. <cite class="ltx_cite ltx_citemacro_citet">Shen
et al<span class="ltx_text">.</span> (<a href="#bib.bib168" title="" class="ltx_ref">2021</a>)</cite> propose a measurement based on seven attributes of the dialogue quality, including self-consistency. Based on this measurement, the untrustworthy samples which get lower scores are filtered out from the training set to improve the model performance in terms of self-consistency (i.e., intrinsic hallucination).
<cite class="ltx_cite ltx_citemacro_citet">Shuster et al<span class="ltx_text">.</span> (<a href="#bib.bib169" title="" class="ltx_ref">2021</a>)</cite> conduct a comprehensive investigation on a retrieval-augmented KGD task where a retriever is introduced to the system for knowledge selection. The authors study several key problems, such as whether retrieval helps reduce hallucinations and how the generation should be augmented with the retrieved knowledge. The experimental results show that retrieval helps substantially in improving performance on KGD tasks and in reducing the hallucination in conversations without sacrificing conversational ability.</p>
</div>
<div id="S8.SS2.SSS4.p2" class="ltx_para">
<p id="S8.SS2.SSS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Rashkin
et al<span class="ltx_text">.</span> (<a href="#bib.bib153" title="" class="ltx_ref">2021</a>)</cite> introduce a set of control codes and concatenate them with dialogue inputs to reduce the hallucination by forcing the model to be more aware of how the response relies on the knowledge evidence in the response generation.
Some researchers have also tried to reduce hallucinated responses during generation by improving dialogue modeling. <cite class="ltx_cite ltx_citemacro_citet">Wu
et al<span class="ltx_text">.</span> (<a href="#bib.bib211" title="" class="ltx_ref">2021</a>)</cite> apply inductive attention into transformer-based dialogue models, and potentially uninformative attention links are removed with respect to a piece of pre-established structural information between the dialogue context and the provided knowledge.
Instead of improving the dialogue response generation model itself, <cite class="ltx_cite ltx_citemacro_citet">Dziri
et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2021a</a>)</cite> present a response refinement strategy with a token-level hallucination critic and entity-mention retriever, so that the original dialogue model is left without retraining. The former module is designed to label the hallucinated entity mentioned in the generated responses, while the retriever is trained to retrieve more faithful entities from the provided knowledge graph.</p>
</div>
</section>
</section>
<section id="S8.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.3. </span>Task-oriented Dialogue Generation</h3>

<div id="S8.SS3.p1" class="ltx_para">
<p id="S8.SS3.p1.1" class="ltx_p">A task-oriented dialogue system is often composed of several modules: a natural language understanding (NLU) module, a dialogue manager (DM), and a natural language generation (NLG) module <cite class="ltx_cite ltx_citemacro_citep">(Gao
et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2018</a>; Jurafsky and
Marin, <a href="#bib.bib81" title="" class="ltx_ref">2019</a>)</cite>. Intrinsic hallucination can occur between the DM and NLG, where a dialogue act such as <span id="S8.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">recommend(NAME=</span><span id="S8.SS3.p1.1.2" class="ltx_text ltx_font_italic">peninsula hotel</span><span id="S8.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">, AREA=</span><span id="S8.SS3.p1.1.4" class="ltx_text ltx_font_italic">tsim sha tsui</span><span id="S8.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">)</span> is transformed into a natural language representation “the hotel named <span id="S8.SS3.p1.1.6" class="ltx_text ltx_font_italic">peninsula hotel</span> is located in <span id="S8.SS3.p1.1.7" class="ltx_text ltx_font_italic">tsim sha tsui</span> area.” <cite class="ltx_cite ltx_citemacro_citep">(Balakrishnan et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite>.</p>
</div>
<section id="S8.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.3.1. </span>Hallucination Metrics</h4>

<div id="S8.SS3.SSS1.p1" class="ltx_para">
<p id="S8.SS3.SSS1.p1.4" class="ltx_p">To evaluate hallucination, <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> combine traditional metrics such as the BLEU score and human evaluation as well as hallucination-specific automatic metrics. Following previous works such as <cite class="ltx_cite ltx_citemacro_citep">(Wen et al<span class="ltx_text">.</span>, <a href="#bib.bib204" title="" class="ltx_ref">2015a</a>; Dušek and Jurčíček, <a href="#bib.bib39" title="" class="ltx_ref">2016</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citep">(Tran and Nguyen, <a href="#bib.bib186" title="" class="ltx_ref">2017</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite> use the slot error rate, which is computed by <math id="S8.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="(p+q)/N" display="inline"><semantics id="S8.SS3.SSS1.p1.1.m1.1a"><mrow id="S8.SS3.SSS1.p1.1.m1.1.1" xref="S8.SS3.SSS1.p1.1.m1.1.1.cmml"><mrow id="S8.SS3.SSS1.p1.1.m1.1.1.1.1" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.2" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.2" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml">p</mi><mo id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.1" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.cmml">+</mo><mi id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.3" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.3.cmml">q</mi></mrow><mo stretchy="false" id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.3" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S8.SS3.SSS1.p1.1.m1.1.1.2" xref="S8.SS3.SSS1.p1.1.m1.1.1.2.cmml">/</mo><mi id="S8.SS3.SSS1.p1.1.m1.1.1.3" xref="S8.SS3.SSS1.p1.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S8.SS3.SSS1.p1.1.m1.1b"><apply id="S8.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1"><divide id="S8.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.2"></divide><apply id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1"><plus id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.1"></plus><ci id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.2">𝑝</ci><ci id="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.3.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.1.1.1.3">𝑞</ci></apply><ci id="S8.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S8.SS3.SSS1.p1.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.SSS1.p1.1.m1.1c">(p+q)/N</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.SSS1.p1.1.m1.1d">( italic_p + italic_q ) / italic_N</annotation></semantics></math>, where <math id="S8.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S8.SS3.SSS1.p1.2.m2.1a"><mi id="S8.SS3.SSS1.p1.2.m2.1.1" xref="S8.SS3.SSS1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S8.SS3.SSS1.p1.2.m2.1b"><ci id="S8.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S8.SS3.SSS1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.SSS1.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.SSS1.p1.2.m2.1d">italic_N</annotation></semantics></math> represents the total number of slots extracted by another model in the dialogue act. Here, <math id="S8.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S8.SS3.SSS1.p1.3.m3.1a"><mi id="S8.SS3.SSS1.p1.3.m3.1.1" xref="S8.SS3.SSS1.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S8.SS3.SSS1.p1.3.m3.1b"><ci id="S8.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S8.SS3.SSS1.p1.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.SSS1.p1.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.SSS1.p1.3.m3.1d">italic_p</annotation></semantics></math> stands for the missing slots in the generated template, and <math id="S8.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S8.SS3.SSS1.p1.4.m4.1a"><mi id="S8.SS3.SSS1.p1.4.m4.1.1" xref="S8.SS3.SSS1.p1.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S8.SS3.SSS1.p1.4.m4.1b"><ci id="S8.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S8.SS3.SSS1.p1.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.SSS1.p1.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.SSS1.p1.4.m4.1d">italic_q</annotation></semantics></math> is the number of redundant slots.
On the other hand, <cite class="ltx_cite ltx_citemacro_citet">Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> introduce a novel metric called the tree accuracy, which determines whether the prediction’s tree structure is identical to that of the input meaning representations.</p>
</div>
</section>
<section id="S8.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">8.3.2. </span>Mitigation Methods</h4>

<div id="S8.SS3.SSS2.p1" class="ltx_para">
<p id="S8.SS3.SSS2.p1.1" class="ltx_p">While <cite class="ltx_cite ltx_citemacro_citet">Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> propose to adopt tree-structured semantic representations and add constraints on decoding, <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib109" title="" class="ltx_ref">2020c</a>)</cite> frame a reinforcement learning problem to which they apply a bootstrapping algorithm to sample training instances and then leverage a reward related to slot consistency.
Recently, there has emerged another line of research in task-oriented dialogue, which is to build a single end-to-end system rather than connecting several modules (e.g., <cite class="ltx_cite ltx_citemacro_citet">Eric and Manning (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>); Wu
et al<span class="ltx_text">.</span> (<a href="#bib.bib210" title="" class="ltx_ref">2019</a>); Madotto
et al<span class="ltx_text">.</span> (<a href="#bib.bib123" title="" class="ltx_ref">2018</a>); Madotto et al<span class="ltx_text">.</span> (<a href="#bib.bib120" title="" class="ltx_ref">2020a</a>)</cite>). As discussed in previous sections of this paper, there is potential for such end-to-end systems to produce extrinsic hallucinations, yet this remains less explored. For example, a model might generate a response with an entity that appears out of nowhere. In the example of hotel recommendation in Hong Kong given above, a model could generate a response such as “the hotel named <span id="S8.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_italic">raffles hotel</span> is located in <span id="S8.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_italic">central</span> area,<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Raffles Hotel is a hotel located in Downtown Core, Singapore.</span></span></span>” which cannot be verified from the knowledge base of the system.
</p>
</div>
</section>
</section>
<section id="S8.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.4. </span>Future Directions in Dialogue Generation</h3>

<section id="S8.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Self-Contradiction in Dialogue Systems</h5>

<div id="S8.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S8.SS4.SSS0.Px1.p1.1" class="ltx_p">One of the possible reasons for self-contradiction is that current dialogue systems tend to have a short memory of dialogue history <cite class="ltx_cite ltx_citemacro_citep">(Roller et al<span class="ltx_text">.</span>, <a href="#bib.bib161" title="" class="ltx_ref">2020</a>)</cite>.
Firstly, common dialogue datasets provide several turns of conversation, yet these are not long enough to assess a model’s ability to deal with a long context. To overcome this, <cite class="ltx_cite ltx_citemacro_citet">Xu
et al<span class="ltx_text">.</span> (<a href="#bib.bib213" title="" class="ltx_ref">2021c</a>)</cite> introduce a new dataset that consists of, on average, over 40 utterances per episode. Secondly, we often truncate dialogue history into fewer turns to fit into models such as Transformer-based architectures, which makes it difficult for a model to memorize the past. In addition to the works on dialogue summarization, e.g., <cite class="ltx_cite ltx_citemacro_citet">Gliwa
et al<span class="ltx_text">.</span> (<a href="#bib.bib60" title="" class="ltx_ref">2019</a>)</cite>, it would be beneficial to apply other works which are aiming to grasp the longer context but do not focus on dialogue generation <cite class="ltx_cite ltx_citemacro_citep">(Beltagy
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>; Zaheer et al<span class="ltx_text">.</span>, <a href="#bib.bib224" title="" class="ltx_ref">2020</a>; Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib234" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S8.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Fact-checking in dialogue systems</h5>

<div id="S8.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S8.SS4.SSS0.Px2.p1.1" class="ltx_p">In addition to the factual consistency in responses from knowledge grounded dialogue systems, fact-checking is a future direction in dealing with the hallucination problem in dialogue systems <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2021</a>)</cite>. Dialogue fact-checking involves verifiable claim detection, which is an important line in distinguishing hallucination-prone dialogue, and evidence retrieval from an external source. This fact-checking in the dialogue system could be utilized not only as an evaluation metric for facilitating factual consistency but also to model such a system.</p>
</div>
</section>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Hallucination in Generative Question Answering</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Generative question answering (GQA) aims to generate an abstractive answer rather than extract an answer to a given question from provided passages <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019b</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite>. It is an important task since many of the everyday questions that humans deal with and pose to search engines require in-depth explanations <cite class="ltx_cite ltx_citemacro_citep">(Khashabi et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2021</a>)</cite> (e.g., <span id="S9.p1.1.1" class="ltx_text ltx_font_italic">why/how..?</span>), and the answers are normally long and cannot be directly extracted from existing phrase spans. A GQA system can be integrated with a search engine <cite class="ltx_cite ltx_citemacro_citep">(Metzler
et al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2021</a>)</cite> to empower more intelligent search or combined with a virtual conversation agent to enhance user experience.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p id="S9.p2.1" class="ltx_p">Normally, a GQA system involves searching an external knowledge source for information relevant to the question. Then it generates the answer based on the retrieved information <cite class="ltx_cite ltx_citemacro_citep">(Krishna
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2021</a>)</cite>. In most cases, no single source (document) contains the answer, and multiple retrieved documents will be considered for answer generation. Those documents may contain redundant, complementary, or contradictory information. Thus, hallucination is common in the generated answers.</p>
</div>
<div id="S9.p3" class="ltx_para">
<p id="S9.p3.1" class="ltx_p">The hallucination problem is one of the most important challenges in GQA. Since an essential goal of a GQA system is to provide factualy-correct answers given the question, hallucination in the answer will mislead the user and damage the system performance dramatically.</p>
</div>
<section id="S9.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.1. </span>Hallucination Definition in GQA</h3>

<div id="S9.SS1.p1" class="ltx_para">
<p id="S9.SS1.p1.1" class="ltx_p">As a challenging yet under-explored task, there is no standard definition of hallucination in GQA. However, almost all the works on GQA <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019b</a>; Krishna
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2021</a>; Nakano et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2021</a>; Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib173" title="" class="ltx_ref">2022</a>)</cite> involve a human evaluation process, in which the <span id="S9.SS1.p1.1.1" class="ltx_text ltx_font_italic">factual correctness</span> measuring the faithfulness of the generated answer can be seen as a measurement of the hallucination; i.e., the more faithful the answer is, the less hallucinated content it contains. The most recent such work  <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite> uses the term <span id="S9.SS1.p1.1.2" class="ltx_text ltx_font_italic">semantic drift</span>, which indicates how the answer drifts away from a correct one during generation, and this can also be seen as a specific definition of hallucination in GQA.</p>
</div>
<div id="S9.SS1.p2" class="ltx_para">
<p id="S9.SS1.p2.1" class="ltx_p">In line with the general categorization of hallucination in Section  <a href="#S2.SS1" title="2.1. Categorization ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, we give two concrete hallucination examples in GQA in Table  <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The sources of both questions are Wikipedia web pages. For the first question, “<span id="S9.SS1.p2.1.1" class="ltx_text ltx_font_italic">dow jones industrial average please?</span>”, the generated answer “<span id="S9.SS1.p2.1.2" class="ltx_text ltx_font_italic">index of 30 major U.S. stock indexes</span>” conflicts with the statement “<span id="S9.SS1.p2.1.3" class="ltx_text ltx_font_italic">of 30 prominent companies listed on stock exchanges in the United States</span>” from Wikipedia. So we categorize it as an intrinsic hallucination. For the second example, the sentences “<span id="S9.SS1.p2.1.4" class="ltx_text ltx_font_italic">The definition of a Sadducee is a person who acts in a deceitful or duplicitous manner. An example of a Sadduceee is a politician who acts deceitfully in order to gain political power</span>” in the generated answer can not be verified from the source documents; thus, we categorize it as an extrinsic hallucination.</p>
</div>
</section>
<section id="S9.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.2. </span>Hallucination-related Metrics in GQA</h3>

<div id="S9.SS2.p1" class="ltx_para">
<p id="S9.SS2.p1.1" class="ltx_p">Currently, there is no automatic metric to evaluate hallucination in QGA specifically. While most works on GQA use automatic evaluation metrics such as ROUGE score and F1 to measure the quality of the answer, these N-gram overlap-based metrics are not a meaningful way to evaluate hallucination due to their poor correlation with human judgments, as indicated by <cite class="ltx_cite ltx_citemacro_citet">Krishna
et al<span class="ltx_text">.</span> (<a href="#bib.bib89" title="" class="ltx_ref">2021</a>)</cite>. On the other hand, almost all the GQA-related work involves a human evaluation process as a complement to the automatic evaluation. Normally, human annotators will be asked to assign a score indicating the faithfulness of the answer, which can also be viewed as a measurement of the answer hallucination. However, the metrics obtained via human evaluation come normally from a small sample of the data.</p>
</div>
<div id="S9.SS2.p2" class="ltx_para">
<p id="S9.SS2.p2.1" class="ltx_p">Metrics such as <span id="S9.SS2.p2.1.1" class="ltx_text ltx_font_italic">semantic overlap</span>  <cite class="ltx_cite ltx_citemacro_citep">(Sellam
et al<span class="ltx_text">.</span>, <a href="#bib.bib167" title="" class="ltx_ref">2020</a>)</cite>, a learned evaluation metric based on BERT that models human judgments, could be considered a better measurement of hallucination for GQA. Other metrics such as the <span id="S9.SS2.p2.1.2" class="ltx_text ltx_font_italic">factual correctness</span> can also be considered as a way to measure hallucination in GQA. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib232" title="" class="ltx_ref">2020a</a>)</cite> propose to explicitly measure the factual correctness of a generated text against the reference by first extracting facts via an information extraction (IE) module. Then they define and measure the factual accuracy score to be the ratio of facts in the generation text equal to the corresponding facts in the reference.</p>
</div>
<div id="S9.SS2.p3" class="ltx_para">
<p id="S9.SS2.p3.1" class="ltx_p"><span id="S9.SS2.p3.1.1" class="ltx_text ltx_font_italic">Factual consistency</span>, which measures the faithfulness of the generated answer given its source documents, can be employed as another way to measure hallucination in GQA. <cite class="ltx_cite ltx_citemacro_citet">Durmus
et al<span class="ltx_text">.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2020</a>); Wang
et al<span class="ltx_text">.</span> (<a href="#bib.bib192" title="" class="ltx_ref">2020a</a>)</cite> propose an automatic QA-based metric to measure faithfulness in summary, leveraging the recent advances in machine reading comprehension. They first use a question generation model to construct question-answer pairs from the summary, and then a QA model is applied to extract short answer spans from the given source document for the question. The extracted answers that do not match the provided answers indicate unfaithful information in the summary. While these metrics were first proposed in summarization works, they can be easily adopted in generative QA to measure hallucinations in the generated long-form answer.</p>
</div>
<div id="S9.SS2.p4" class="ltx_para">
<p id="S9.SS2.p4.1" class="ltx_p">The most recent work on GQA by  <cite class="ltx_cite ltx_citemacro_citet">Su
et al<span class="ltx_text">.</span> (<a href="#bib.bib173" title="" class="ltx_ref">2022</a>)</cite> proposed to estimate the faithfulness of the generated long-form answer via <span id="S9.SS2.p4.1.1" class="ltx_text ltx_font_italic">zero-shot short answer recall</span> on extractive QA datasets. They first generate long-form answers for questions from two extractive QA datasets Natural Questions(NQ) <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski
et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2019</a>)</cite> and HotpotQA <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib219" title="" class="ltx_ref">2018</a>)</cite>, both of which contains large-scale question-answer pairs, then they measure the ratio of golden short answer span contained in the generated long answer as an estimation of faithfulness of the generated long-answer. While the idea is similar to the factual consistency metric in summarization work <cite class="ltx_cite ltx_citemacro_citep">(Durmus
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>, and also matches with our intuition to some extent, its correlation with human evaluation on faithfulness has not been verified.</p>
</div>
</section>
<section id="S9.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.3. </span>Hallucination Mitigation in GQA</h3>

<div id="S9.SS3.p1" class="ltx_para">
<p id="S9.SS3.p1.1" class="ltx_p">Unlike conditional text generation tasks such as summarization, or data-to-text generation, in which the source documents are provided and normally related to the target generation, the hallucination problem in GQA is more complicated. Generally speaking, it might come from two sources: 1) the incompetency of the retriever, which retrieves documents irrelevant to the answer, and 2) the <span id="S9.SS3.p1.1.1" class="ltx_text ltx_font_italic">intrinsic</span> and <span id="S9.SS3.p1.1.2" class="ltx_text ltx_font_italic">extrinsic</span> hallucination in the conditional generation model itself. Normally these two parts are interconnected and cause hallucinations in the answer.</p>
</div>
<div id="S9.SS3.p2" class="ltx_para">
<p id="S9.SS3.p2.1" class="ltx_p">Early works on GQA mostly tried to improve the faithfulness of the answer by investigating reliable external knowledge sources or incorporating multiple information sources.
<cite class="ltx_cite ltx_citemacro_citet">Yin
et al<span class="ltx_text">.</span> (<a href="#bib.bib221" title="" class="ltx_ref">2016</a>)</cite> propose Neural Generative Question Answering (GENQA), an end-to-end model that generates answers to simple factoid questions based on the knowledge base, while <cite class="ltx_cite ltx_citemacro_citet">Bi
et al<span class="ltx_text">.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> propose the Knowledge-Enriched Answer Generator (KEAG) to generate a natural answer by integrating facts from four different information sources, namely, questions, passages, vocabulary, and knowledge.
<span id="S9.SS3.p2.1.1" class="ltx_text" style="color:#000000;">Nevertheless, these methods rely on the existence of high-quality, relevant resources which are not easily available.</span></p>
</div>
<div id="S9.SS3.p3" class="ltx_para">
<p id="S9.SS3.p3.1" class="ltx_p">Recent works focus more on the conditional generation model. <cite class="ltx_cite ltx_citemacro_citet">Fan
et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2019a</a>)</cite> construct a local knowledge graph for each question to compress the information and reduce redundancy from the retrieved documents, which can be viewed as an early trial to mitigate hallucination. <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib103" title="" class="ltx_ref">2021a</a>)</cite> propose Rationale-Enriched Answer Generator (REAG), in which they add an extraction task to obtain the rationale for an answer at the encoding stage, and the decoder is expected to generate the answer based on both the extracted rationale and original input. The recent work <cite class="ltx_cite ltx_citemacro_citep">(Krishna
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2021</a>)</cite> employs a Routing Transformer (RT), a sparse attention-based Transformer-based model that employs local attention and mini-batch k-means clustering for long-range dependence, as the answer generator in the hope of modeling more retrieved documents to mitigate the hallucination in the answer. <cite class="ltx_cite ltx_citemacro_citet">Su
et al<span class="ltx_text">.</span> (<a href="#bib.bib173" title="" class="ltx_ref">2022</a>)</cite> propose a framework named RBG (<span id="S9.SS3.p3.1.1" class="ltx_text ltx_font_bold">r</span>ead <span id="S9.SS3.p3.1.2" class="ltx_text ltx_font_bold">b</span>efore <span id="S9.SS3.p3.1.3" class="ltx_text ltx_font_bold">g</span>enerate), to jointly models answer generation with machine reading. They augment the generation model with fine-grained, answer-related salient information predicted by the MRC module, to enhance answer faithfulness.
<span id="S9.SS3.p3.1.4" class="ltx_text" style="color:#000000;">Such methods can exploit and utilize the information in the original input better, while they require the extra effort of building models to extract that information.</span></p>
</div>
<div id="S9.SS3.p4" class="ltx_para">
<p id="S9.SS3.p4.1" class="ltx_p">Most recently, <cite class="ltx_cite ltx_citemacro_citet">Lin
et al<span class="ltx_text">.</span> (<a href="#bib.bib111" title="" class="ltx_ref">2021</a>)</cite> propose a benchmark, which comprises 817 questions that span 38 categories, to measure the truthfulness of a language model in the QA task. This work investigates the performances of GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(Brown
et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, GPT-Neo/J <cite class="ltx_cite ltx_citemacro_citep">(Wang and
Komatsuzaki, <a href="#bib.bib193" title="" class="ltx_ref">2021</a>)</cite>, GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a href="#bib.bib150" title="" class="ltx_ref">2019</a>)</cite> and a T5-based model <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al<span class="ltx_text">.</span>, <a href="#bib.bib151" title="" class="ltx_ref">2020</a>)</cite>. The results suggest that simply scaling up the model is less promising than fine-tuning it in terms of improving truthfulness since larger models are better at learning the training distribution from web data and thus tend to produce more imitative falsehoods. In another recent work, <cite class="ltx_cite ltx_citemacro_citet">Nakano et al<span class="ltx_text">.</span> (<a href="#bib.bib134" title="" class="ltx_ref">2021</a>)</cite> fine-tune GPT-3 to answer long-form questions with a web-browsing environment, which allows the model to navigate the web as well as use human feedback to optimize answer quality directly using imitation learning <cite class="ltx_cite ltx_citemacro_citep">(Hussein
et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2017</a>)</cite>.
<span id="S9.SS3.p4.1.1" class="ltx_text" style="color:#000000;">While this method seems promising, it also hinges on how that feedback is processed.</span></p>
</div>
</section>
<section id="S9.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.4. </span>Future Directions in GQA</h3>

<div id="S9.SS4.p1" class="ltx_para">
<p id="S9.SS4.p1.1" class="ltx_p">While GQA is challenging yet under-explored, many possible directions could be explored to improve the answer quality and mitigate hallucination.
First, better automatic evaluation metrics are needed to measure hallucination. The previously mentioned metrics, such as the semantic overlap between the generated answer and the ground-truth answer, the faithfulness of the generated answer, and factual consistency between the answer and the source documents, only consider one aspect of hallucination. Metrics that can consider all the factors related to hallucination (such as semantic overlap, faithfulness, or factual consistency) could be designed.
Second, datasets with hallucination annotations should be proposed since none of the current GQA datasets have that information. Another possible direction to mitigate hallucination in the answer is improving the performance of the models. We need better retrieval models that retrieve relevant information according to queries and generation models that can synthesize more accurate answers from multi-source documents.</p>
</div>
</section>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10. </span>Hallucination in Data-to-Text Generation</h2>

<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p">Data-to-Text Generation is the task of generating natural language descriptions conditioned on structured data <cite class="ltx_cite ltx_citemacro_citep">(Kukich, <a href="#bib.bib91" title="" class="ltx_ref">1983</a>; McKeown, <a href="#bib.bib128" title="" class="ltx_ref">1992</a>)</cite>, such as tables <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>; Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>)</cite>, database records <cite class="ltx_cite ltx_citemacro_citep">(Chisholm
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2017</a>)</cite>, and knowledge graphs <cite class="ltx_cite ltx_citemacro_citep">(Gardent et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite>.
Although this field has been recently boosted by neural text generation models, it is well known that these models are prone to hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>)</cite> because of the gap between structured data and text, which may cause semantic misunderstanding and erroneous correlation.
Moreover, the tolerance of hallucination is very low when this task is applied to the real world, such as in the case of patient information table description <cite class="ltx_cite ltx_citemacro_citep">(Thomson and
Reiter, <a href="#bib.bib182" title="" class="ltx_ref">2020</a>)</cite>, and analysis of experimental results tables in a scientific report.
Recent years have seen a growth of interest in hallucinations in Data-to-Text Generation, and researchers have proposed works from the aspect of evaluation and mitigation.</p>
</div>
<section id="S10.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.1. </span>Hallucination Definition in Data-to-Text Generation</h3>

<div id="S10.SS1.p1" class="ltx_para">
<p id="S10.SS1.p1.1" class="ltx_p">The definition and categories of hallucination in Data-to-Text Generation follow the descriptions in Section <a href="#S2" title="2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We follow the general hallucination definition in this task:
(1) Intrinsic Hallucinations: the generated text contains information that is contradicted by the input data <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite>. For example, in Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, “<span id="S10.SS1.p1.1.1" class="ltx_text ltx_font_italic">The Houston Rockets (18-4)</span>” uses the information “<span id="S10.SS1.p1.1.2" class="ltx_text ltx_font_italic">[TEAM: Rockets, CITY:Houston, WIN:18, LOSS: 5]</span>” in the source table. However, “<span id="S10.SS1.p1.1.3" class="ltx_text ltx_font_italic">(18-4)</span>” is contradicted by “<span id="S10.SS1.p1.1.4" class="ltx_text ltx_font_italic">[LOSS: 5]</span>” and it should be “<span id="S10.SS1.p1.1.5" class="ltx_text ltx_font_italic">(18-5)</span>”.
(2) Extrinsic Hallucinations: the generated text contains extra information irrelevant to the input  <cite class="ltx_cite ltx_citemacro_citep">(Dhingra et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>; Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite>. For example, in Table <a href="#S2.T1" title="Table 1 ‣ 2.3. Terminology Clarification ‣ 2. Definitions ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, “<span id="S10.SS1.p1.1.6" class="ltx_text ltx_font_italic">Houston has won two straight games and six of their last seven.</span>” is not mentioned in the source table <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib195" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S10.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.2. </span>Hallucination Metrics in Data-to-Text Generation</h3>

<section id="S10.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Statistical</h5>

<div id="S10.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S10.SS2.SSS0.Px1.p1.5" class="ltx_p">PARENT <cite class="ltx_cite ltx_citemacro_citep">(Dhingra et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> measures the accuracy of table-to-text generation by aligning n-grams from the reference description <math id="S10.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S10.SS2.SSS0.Px1.p1.1.m1.1a"><mi mathcolor="#000000" id="S10.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S10.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S10.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.1.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px1.p1.1.m1.1c">R</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px1.p1.1.m1.1d">italic_R</annotation></semantics></math><span id="S10.SS2.SSS0.Px1.p1.3.2" class="ltx_text" style="color:#000000;"> and generated texts <math id="S10.SS2.SSS0.Px1.p1.2.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S10.SS2.SSS0.Px1.p1.2.1.m1.1a"><mi mathcolor="#000000" id="S10.SS2.SSS0.Px1.p1.2.1.m1.1.1" xref="S10.SS2.SSS0.Px1.p1.2.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px1.p1.2.1.m1.1b"><ci id="S10.SS2.SSS0.Px1.p1.2.1.m1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.2.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px1.p1.2.1.m1.1c">G</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px1.p1.2.1.m1.1d">italic_G</annotation></semantics></math> to the table <math id="S10.SS2.SSS0.Px1.p1.3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S10.SS2.SSS0.Px1.p1.3.2.m2.1a"><mi mathcolor="#000000" id="S10.SS2.SSS0.Px1.p1.3.2.m2.1.1" xref="S10.SS2.SSS0.Px1.p1.3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px1.p1.3.2.m2.1b"><ci id="S10.SS2.SSS0.Px1.p1.3.2.m2.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.3.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px1.p1.3.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px1.p1.3.2.m2.1d">italic_T</annotation></semantics></math></span>. And it is the average F-score by combining the entailment precision and recall.
<cite class="ltx_cite ltx_citemacro_citet">Wang
et al<span class="ltx_text">.</span> (<a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite> modify PARENT and denote this table-focused version as PARENT-T.
Different from PARENT, which evaluates <span id="S10.SS2.SSS0.Px1.p1.5.3" class="ltx_text" style="color:#000000;">i-th</span> instance <math id="S10.SS2.SSS0.Px1.p1.4.m2.3" class="ltx_Math" alttext="(T_{i},R_{i},G_{i})" display="inline"><semantics id="S10.SS2.SSS0.Px1.p1.4.m2.3a"><mrow id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml"><mo stretchy="false" id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.4" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml">(</mo><msub id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.cmml"><mi id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.2" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.2.cmml">T</mi><mi id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.3" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.3.cmml">i</mi></msub><mo id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.5" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml">,</mo><msub id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.cmml"><mi id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.2" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.2.cmml">R</mi><mi id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.3" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.3.cmml">i</mi></msub><mo id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.6" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml">,</mo><msub id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.cmml"><mi id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.2" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.2.cmml">G</mi><mi id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.3" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.7" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px1.p1.4.m2.3b"><vector id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.4.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3"><apply id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1">subscript</csymbol><ci id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.2.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.2">𝑇</ci><ci id="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.3.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.1.1.1.1.3">𝑖</ci></apply><apply id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.1.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2">subscript</csymbol><ci id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.2.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.2">𝑅</ci><ci id="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.3.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.2.2.2.2.3">𝑖</ci></apply><apply id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.1.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3">subscript</csymbol><ci id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.2.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.2">𝐺</ci><ci id="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.3.cmml" xref="S10.SS2.SSS0.Px1.p1.4.m2.3.3.3.3.3">𝑖</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px1.p1.4.m2.3c">(T_{i},R_{i},G_{i})</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px1.p1.4.m2.3d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, PARENT-T ignores the reference description R and evaluates each instance <math id="S10.SS2.SSS0.Px1.p1.5.m3.2" class="ltx_Math" alttext="(T_{i},G_{i})" display="inline"><semantics id="S10.SS2.SSS0.Px1.p1.5.m3.2a"><mrow id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.3.cmml"><mo stretchy="false" id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.3" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.3.cmml">(</mo><msub id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.cmml"><mi id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.2" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.2.cmml">T</mi><mi id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.3" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.4" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.3.cmml">,</mo><msub id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.cmml"><mi id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.2" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.2.cmml">G</mi><mi id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.3" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.5" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px1.p1.5.m3.2b"><interval closure="open" id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.3.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2"><apply id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.1.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1">subscript</csymbol><ci id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.2.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.2">𝑇</ci><ci id="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.3.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.1.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2">subscript</csymbol><ci id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.2.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.2">𝐺</ci><ci id="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.3.cmml" xref="S10.SS2.SSS0.Px1.p1.5.m3.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px1.p1.5.m3.2c">(T_{i},G_{i})</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px1.p1.5.m3.2d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
</section>
<section id="S10.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">IE-based</h5>

<div id="S10.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S10.SS2.SSS0.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Liu
et al<span class="ltx_text">.</span> (<a href="#bib.bib115" title="" class="ltx_ref">2021b</a>)</cite> estimate hallucination with two entity-centric metrics: table record coverage (the ratio of covered records in a table) and hallucinated ratio (the ratio of hallucinated entities in text).
This metric firstly uses entity recognition to extract the entities of input and generated output,
then aligns these entities by heuristic matching strategies,
and finally calculates the ratios of faithful and hallucinated entities separately.
Moreover, there are some general post-hoc IE-based metrics that could be applied to hallucination evaluation, such as Slot Error Rate (SER) <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib217" title="" class="ltx_ref">2021a</a>)</cite>, Content Selection (CS), Relation Generation (RG), and Content Ordering (CO) <cite class="ltx_cite ltx_citemacro_citep">(Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>; Wang, <a href="#bib.bib195" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S10.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">QA-based</h5>

<div id="S10.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S10.SS2.SSS0.Px3.p1.1" class="ltx_p"><span id="S10.SS2.SSS0.Px3.p1.1.1" class="ltx_text" style="color:#000000;">Data-QuestEval <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel
et al<span class="ltx_text">.</span>, <a href="#bib.bib156" title="" class="ltx_ref">2021</a>)</cite> adapt QuestEval <cite class="ltx_cite ltx_citemacro_citep">(Scialom et al<span class="ltx_text">.</span>, <a href="#bib.bib165" title="" class="ltx_ref">2021</a>)</cite> from summarization into data-to-text generation.
First, a <span id="S10.SS2.SSS0.Px3.p1.1.1.1" class="ltx_text ltx_font_italic">textual QG model</span> is trained on a textual QA dataset.
For each sample (structured data, textual descriptions), the <span id="S10.SS2.SSS0.Px3.p1.1.1.2" class="ltx_text ltx_font_italic">textual QG model</span> generates synthetic problems based on the descriptions.
The structured data, textual descriptions (answers), and synthetic questions make up a synthetic QG/QA dataset to train <span id="S10.SS2.SSS0.Px3.p1.1.1.3" class="ltx_text ltx_font_italic">synthetic QA/QG models</span>.
Then, the <span id="S10.SS2.SSS0.Px3.p1.1.1.4" class="ltx_text ltx_font_italic">synthetic QG</span> model generates questions based on the textual description to be evaluated. The <span id="S10.SS2.SSS0.Px3.p1.1.1.5" class="ltx_text ltx_font_italic">synthetic QA</span> model then generates answers based on a synthetic question and the structured input data.
Finally, BERTScore <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib230" title="" class="ltx_ref">2019a</a>)</cite> measures the similarity between the generated answer and description, indicating faithfulness.
</span></p>
</div>
</section>
<section id="S10.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">NLI-based</h5>

<div id="S10.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S10.SS2.SSS0.Px4.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Dušek and
Kasner (<a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite> recognize the textual entailment between the input data and the output text for both omissions and hallucinations with an NLI model. This work measures the semantic accuracy in two directions: check omissions by inferring whether the input fact is entailed by the generated text and check hallucinations by inferring the generated text from the input.</p>
</div>
</section>
<section id="S10.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">LM-based</h5>

<div id="S10.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S10.SS2.SSS0.Px5.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Filippova (<a href="#bib.bib51" title="" class="ltx_ref">2020</a>); Tian
et al<span class="ltx_text">.</span> (<a href="#bib.bib185" title="" class="ltx_ref">2020</a>)</cite> are based on the intuition that when an unconditional LM, only trained on the targets, gets a smaller loss than a conditional <math id="S10.SS2.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="LM_{x}" display="inline"><semantics id="S10.SS2.SSS0.Px5.p1.1.m1.1a"><mrow id="S10.SS2.SSS0.Px5.p1.1.m1.1.1" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.2" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml">L</mi><mo id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.1" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml"><mi id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.2" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml">M</mi><mi id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.3" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml">x</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S10.SS2.SSS0.Px5.p1.1.m1.1b"><apply id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1"><times id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.1"></times><ci id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.2">𝐿</ci><apply id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.1.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3">subscript</csymbol><ci id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.2">𝑀</ci><ci id="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml" xref="S10.SS2.SSS0.Px5.p1.1.m1.1.1.3.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.SS2.SSS0.Px5.p1.1.m1.1c">LM_{x}</annotation><annotation encoding="application/x-llamapun" id="S10.SS2.SSS0.Px5.p1.1.m1.1d">italic_L italic_M start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math>, trained on both sources and targets, the token is predicted unfaithfully. Thus, they calculate the ratio of hallucinated tokens to the total target length to measure the hallucination level.</p>
</div>
</section>
</section>
<section id="S10.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.3. </span>Hallucination Mitigation in Data-to-Text Generation</h3>

<section id="S10.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data-Related Methods</h5>

<div id="S10.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S10.SS3.SSS0.Px1.p1.1" class="ltx_p">Several clean and faithful corpora are collected to tackle the challenges from data infidelity.
TOTTO <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020</a>)</cite> is an open-domain faithful table-to-text dataset, where each sample includes a Wikipedia table with several highlighted cells and a description.
To ensure that targets exclude hallucinations, the annotators revise existing Wikipedia candidate sentences and clear the parts unsupported by the table.
Moreover, RotoWire-FG (Fact-Grounding) <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib195" title="" class="ltx_ref">2019</a>)</cite> is a purified and enlarged and enriched version of RotoWire <cite class="ltx_cite ltx_citemacro_citep">(Wiseman
et al<span class="ltx_text">.</span>, <a href="#bib.bib208" title="" class="ltx_ref">2017</a>)</cite> generating NBA game summaries from score tables.
Annotators trim the hallucination part in target texts and extract the mapped table records as content plans to better align input tables and output summaries.</p>
</div>
<div id="S10.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S10.SS3.SSS0.Px1.p2.1" class="ltx_p">For data processing, <span id="S10.SS3.SSS0.Px1.p2.1.1" class="ltx_text" style="color:#000000;">OpAtt <cite class="ltx_cite ltx_citemacro_citep">(Nie
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2018</a>)</cite> designs a gating mechanism and a quantization module for the symbolic operation to augment the record table with pre-calculated results.</span>
<cite class="ltx_cite ltx_citemacro_citet">Nie
et al<span class="ltx_text">.</span> (<a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite> utilize a language understanding module to improve the equivalence between the input MR and the reference utterance in the dataset.
They train an NLU model with an iterative relabeling procedure:
First, they train the model on original data; parse the MR by model inference; train the model on new paired data with high confidence; and then repeat the above processes.
<cite class="ltx_cite ltx_citemacro_citet">Liu
et al<span class="ltx_text">.</span> (<a href="#bib.bib115" title="" class="ltx_ref">2021b</a>)</cite> select training instances based on faithfulness ranking. Finer-grained than the above instance-level method, <cite class="ltx_cite ltx_citemacro_citet">Rebuffel et al<span class="ltx_text">.</span> (<a href="#bib.bib155" title="" class="ltx_ref">2022</a>)</cite> label tokens according to co-occurrence analysis and sentence structure through dependency parsing in the pre-processing step to explicate the correspondence between the input table and the text.
<span id="S10.SS3.SSS0.Px1.p2.1.2" class="ltx_text" style="color:#000000;">Generally, the data-related methods are appropriate when the training dataset is noisy.</span></p>
</div>
</section>
<section id="S10.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Modeling and Inference Methods</h5>

<div id="S10.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S10.SS3.SSS0.Px2.p1.1" class="ltx_p">Planning and skeleton generation are common methods to improve the faithfulness to the input in data-to-text tasks. <cite class="ltx_cite ltx_citemacro_citet">Liu
et al<span class="ltx_text">.</span> (<a href="#bib.bib115" title="" class="ltx_ref">2021b</a>)</cite> propose a two-step generator with a separate text planner augmented by auxiliary entity information.
The planner predicts the plausible content plan based on the input data. Then, given the above input data and the content plan, the sequence generator generates the text.
Similarly, Plan-then-Generate <cite class="ltx_cite ltx_citemacro_citep">(Su
et al<span class="ltx_text">.</span>, <a href="#bib.bib175" title="" class="ltx_ref">2021</a>)</cite> also consists of a content planner and a sequence generator.
In addition, this work adopts a structure-aware RL training to generate output text following the generated content plan faithfully.
<cite class="ltx_cite ltx_citemacro_citet">Puduppully and
Lapata <span id="S10.SS3.SSS0.Px2.p1.1.1.1.1.1" class="ltx_text" style="color:#000000;">(</span><a href="#bib.bib149" title="" class="ltx_ref">2021</a><span id="S10.SS3.SSS0.Px2.p1.1.2.2.2.1" class="ltx_text" style="color:#000000;">)</span></cite><span id="S10.SS3.SSS0.Px2.p1.1.3" class="ltx_text" style="color:#000000;"> first induce a macro plan consisting of multiple sequences of entities and events from the input table and its corresponding multi-paragraph long document. The predicted macro plan then serves as the input to an encoder-decoder model for surface realization.</span>
SANA <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib196" title="" class="ltx_ref">2021a</a>)</cite> is a skeleton-based two-stage model that includes skeleton generation to select key tokens from the source table and edit-based generation to produce texts via iterative insertion and deletion operations.
In contrast to the above two-step model using planning or skeleton, AGGGEN <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib217" title="" class="ltx_ref">2021a</a>)</cite> is an end-to-end model that jointly learns to plan and generate at the same time.
This architecture with a Hidden Markov Model and Transformer encoder-decoder reintroduces explicit sentence planning stages into neural systems by aligning facts in the target text to input representations.</p>
</div>
<div id="S10.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S10.SS3.SSS0.Px2.p2.1" class="ltx_p">Other modeling methods have also been proposed to mitigate the hallucination problem.
Conjecturing that hallucinations can be caused by inattention to the source, <cite class="ltx_cite ltx_citemacro_citet">Tian
et al<span class="ltx_text">.</span> (<a href="#bib.bib185" title="" class="ltx_ref">2020</a>)</cite> propose a confidence score and a variational Bayes training framework to learn the score from data.
<cite class="ltx_cite ltx_citemacro_citet">Wang
et al<span class="ltx_text">.</span> (<a href="#bib.bib200" title="" class="ltx_ref">2020b</a>)</cite> introduce a table-text optimal-transport matching loss and an embedding similarity loss to encourage faithfulness.
The hallucination degree can also be treated as a controllable factor in generating texts.
In <cite class="ltx_cite ltx_citemacro_citet">Filippova (<a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite>, the hallucination degree of each training sample is estimated and converted into a categorical value which is a part of the inputs as a controlled setting. This approach does not require the dismissal of any input or modification of the model structure.
</p>
</div>
<div id="S10.SS3.SSS0.Px2.p3" class="ltx_para">
<p id="S10.SS3.SSS0.Px2.p3.1" class="ltx_p">To mitigate hallucinations at the inference step, <cite class="ltx_cite ltx_citemacro_citet">Rebuffel et al<span class="ltx_text">.</span> (<a href="#bib.bib155" title="" class="ltx_ref">2022</a>)</cite> propose a Multi-Branch Decoder that leverages word-level alignment labels between the input table and paired text to learn the relevant parts of the training instance. These word-level labels are gained through dependency parsing during the pre-processing step.
The branches separately integrate three co-dependent control factors: content, hallucination, and fluency.
Uncertainty-aware beam search (UABS) <cite class="ltx_cite ltx_citemacro_citep">(Xiao and Wang, <a href="#bib.bib212" title="" class="ltx_ref">2021</a>)</cite> is an extension to beam search to reduce hallucination. Considering that the hallucination probability is positively correlated with predictive uncertainty, this work adds a weighted penalty term in the beam search which is able to balance the predictive probability and uncertainty. <span id="S10.SS3.SSS0.Px2.p3.1.1" class="ltx_text" style="color:#000000;">This approach is task-agnostic and can also be applied to other tasks, such as image captioning.</span></p>
</div>
<div id="S10.SS3.SSS0.Px2.p4" class="ltx_para">
<p id="S10.SS3.SSS0.Px2.p4.1" class="ltx_p"><span id="S10.SS3.SSS0.Px2.p4.1.1" class="ltx_text" style="color:#000000;">These various types of methods do not necessarily conflict and can collaborate to solve the hallucination problem in data-to-text generation. </span></p>
</div>
</section>
</section>
<section id="S10.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">10.4. </span>Future Directions in Data-to-Text Generation</h3>

<div id="S10.SS4.p1" class="ltx_para">
<p id="S10.SS4.p1.1" class="ltx_p">Given the challenges brought by the discrepancy between structure data and natural text, and the low fault tolerance in the Data-to-Text Generation task, there are several potential directions worth exploring in terms of hallucination.</p>
</div>
<div id="S10.SS4.p2" class="ltx_para">
<p id="S10.SS4.p2.1" class="ltx_p">Firstly, numbers contain information about scales and are common and crucial in the Data-to-Text task  <cite class="ltx_cite ltx_citemacro_citep">(Suadaa et al<span class="ltx_text">.</span>, <a href="#bib.bib176" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib231" title="" class="ltx_ref">2020b</a>)</cite>.
It is frequent to have errors in numbers, which results in hallucinations and infidelity.
This is a serious problem for Data-to-Text generation, yet models rarely give special consideration to the numbers found in the table or text <cite class="ltx_cite ltx_citemacro_citep">(Thawani et al<span class="ltx_text">.</span>, <a href="#bib.bib181" title="" class="ltx_ref">2021</a>)</cite>. The current automatic metrics of hallucinations also do not specifically treat numbers.
This indiscriminate treatment contradicts findings in cognitive neuroscience, where numbers are known to be represented differently from lexical words in a different part of the brain <cite class="ltx_cite ltx_citemacro_citep">(Göbel and
Rushworth, <a href="#bib.bib61" title="" class="ltx_ref">2004</a>)</cite>.
Thus, considering or highlighting numbers when mitigating and assessing hallucinations is worth exploring. This requires the generative model to learn a better numerical presentation and capture scales, which will reduce the hallucinations caused by the misunderstanding of numbers.</p>
</div>
<div id="S10.SS4.p3" class="ltx_para">
<p id="S10.SS4.p3.1" class="ltx_p">Moreover, for the logical data-to-text generation task, rather than surface-level generation, logical inference, calculation, and comparison are required, which is challenging and causes hallucinations more easily.
Thus, reasoning (including numerical reasoning), which is usually combined with graph structures <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> is another direction to improve the accuracy of entity relationships and alleviate hallucinations.</p>
</div>
</section>
</section>
<section id="S11" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">11. </span>Hallucinations in Neural Machine Translation</h2>

<div id="S11.p1" class="ltx_para">
<p id="S11.p1.1" class="ltx_p">Neural Machine Translation (NMT) is the task of generating translation of the source language into the target language via inference, given parallel data samples for training. Compared to statistical machine translation (SMT) the output of NMT is usually quite fluent and of human-level quality, which creates the danger of misinforming users when there are hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Martindale et al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<section id="S11.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">11.1. </span>Hallucinations Definition and Categories in NMT</h3>

<div id="S11.SS1.p1" class="ltx_para">
<p id="S11.SS1.p1.1" class="ltx_p">The problem of hallucination was identified with the deployment of the first NMT models. Early work comparing SMT and NMT systems <cite class="ltx_cite ltx_citemacro_citep">(Koehn and Knowles, <a href="#bib.bib87" title="" class="ltx_ref">2017b</a>)</cite>, without explicitly using the term “hallucination”, mentioned that NMT models tend to “sacrifice adequacy for the sake of fluency” especially when evaluated with out-of-domain test sets. Following further development of NMT, most of the relevant research papers agree that translated text is considered a hallucination when it is completely disconnected from the source  <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>; Müller
et al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2020</a>)</cite>.
The categorization of hallucination in NMT is unlike that in any other NLG tasks, and uses various terms that are often overlapping. In order to maintain consistency with other NLG tasks, in this section we use the intrinsic and extrinsic hallucination categories applied to the NMT task by <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite>. After a formal definition, we will describe other identified types of hallucinations and hallucination categories mentioned in the relevant literature.</p>
</div>
<section id="S11.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Intrinsic and Extrinsic Hallucinations</h5>

<div id="S11.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S11.SS1.SSS0.Px1.p1.1" class="ltx_p">Following the idea that hallucinations are outputs that are disconnected from the source, <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> suggest categorizing the hallucinatory content based on the way the output is disconnected:</p>
<ul id="S11.I1" class="ltx_itemize">
<li id="S11.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S11.I1.i1.p1" class="ltx_para">
<p id="S11.I1.i1.p1.1" class="ltx_p">Intrinsic Hallucination: translations contain incorrect information compared to information present in the source.
In Table <a href="#S11.T3" title="Table 3 ‣ Other Categories and Types of Hallucinations ‣ 11.1. Hallucinations Definition and Categories in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the example of such hallucination is “Jerry doesn’t go”, since the original name in the source is “Mike” and the verb “to go” is not negated.</p>
</div>
</li>
<li id="S11.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S11.I1.i2.p1" class="ltx_para">
<p id="S11.I1.i2.p1.1" class="ltx_p">Extrinsic Hallucination: translations produce additional content without any regard to the source. In Table <a href="#S11.T3" title="Table 3 ‣ Other Categories and Types of Hallucinations ‣ 11.1. Hallucinations Definition and Categories in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, “happily” and “with his friend” are the two examples of the hallucinatory content since they are added without any apparent connection to the input.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S11.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Other Categories and Types of Hallucinations</h5>

<div id="S11.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S11.SS1.SSS0.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite> propose an alternative categorization of hallucinations. They divide hallucinations into hallucinations under perturbations and natural hallucinations. Hallucinations under perturbation are those that can be observed if a model tested on the perturbed and unperturbed test set returns drastically different content. Their work on hallucinations under perturbation strictly follows the algorithm proposed by <cite class="ltx_cite ltx_citemacro_citet">Lee et al<span class="ltx_text">.</span> (<a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>; see Section <a href="#S11.SS2.SSS2.Px2" title="Entropy Measure ‣ 11.2.2. Model-Based Metrics ‣ 11.2. Hallucination Metrics in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.2.2</span></a> on the entropy measure. The second category, natural hallucinations, are created with a connection to the noise in the dataset and can be further divided into detached and oscillatory, where detached hallucinations mean that a target translation is semantically disconnected from a source input, and oscillatory hallucinations mean those that are decoupled from the source by manifesting a repeating n-gram. <cite class="ltx_cite ltx_citemacro_citet">Tu
et al<span class="ltx_text">.</span> (<a href="#bib.bib188" title="" class="ltx_ref">2016</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Kong
et al<span class="ltx_text">.</span> (<a href="#bib.bib88" title="" class="ltx_ref">2019</a>)</cite> analyze this phenomenon under the name “over-translation”, that is, a repetitive appearance of words that were not in the source text. Conversely, under-translation is skipping the words that need to be translated <cite class="ltx_cite ltx_citemacro_citep">(Tu
et al<span class="ltx_text">.</span>, <a href="#bib.bib188" title="" class="ltx_ref">2016</a>)</cite>. Finally, abrupt jumps to the end of the sequence and outputs that remain mostly in the source language are also examples of hallucinatory content <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<figure id="S11.T3" class="ltx_table">
<div id="S11.T3.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:3202.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.1pt,496.0pt) scale(0.763523722761047,0.763523722761047) ;">
<table id="S11.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S11.T3.1.1.1.1" class="ltx_tr">
<th id="S11.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S11.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Category</span></th>
<th id="S11.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S11.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Source</span></th>
<th id="S11.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S11.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Correct Translation</span></th>
<th id="S11.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S11.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Hallucinatory Translation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S11.T3.1.1.2.1" class="ltx_tr">
<th id="S11.T3.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Intrinsic</th>
<th id="S11.T3.1.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">迈克周四去书店。</th>
<td id="S11.T3.1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S11.T3.1.1.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.2.1.3.1.1" class="ltx_tr">
<td id="S11.T3.1.1.2.1.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.2.1.3.1.1.1.1" class="ltx_p ltx_align_top">Mike goes to the bookstore on Thursday.</p>
</td>
</tr>
</table>
</td>
<td id="S11.T3.1.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S11.T3.1.1.2.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.2.1.4.1.1" class="ltx_tr">
<td id="S11.T3.1.1.2.1.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.2.1.4.1.1.1.1" class="ltx_p ltx_align_top">Jerry doesn’t go to the bookstore on Thursday.</p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S11.T3.1.1.3.2" class="ltx_tr">
<th id="S11.T3.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Extrinsic</th>
<th id="S11.T3.1.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">迈克周四去书店。</th>
<td id="S11.T3.1.1.3.2.3" class="ltx_td ltx_align_left">
<table id="S11.T3.1.1.3.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.3.2.3.1.1" class="ltx_tr">
<td id="S11.T3.1.1.3.2.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.3.2.3.1.1.1.1" class="ltx_p ltx_align_top">Mike goes to the bookstore on Thursday.</p>
</td>
</tr>
</table>
</td>
<td id="S11.T3.1.1.3.2.4" class="ltx_td ltx_align_left">
<table id="S11.T3.1.1.3.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.3.2.4.1.1" class="ltx_tr">
<td id="S11.T3.1.1.3.2.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.3.2.4.1.1.1.1" class="ltx_p ltx_align_top">Mike happily goes to the bookstore on Thursday with his friend.</p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S11.T3.1.1.4.3" class="ltx_tr">
<th id="S11.T3.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Detached</th>
<th id="S11.T3.1.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<table id="S11.T3.1.1.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.4.3.2.1.1" class="ltx_tr">
<td id="S11.T3.1.1.4.3.2.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.4.3.2.1.1.1.1" class="ltx_p ltx_align_top">Das kann man nur feststellen, wenn die kontrollen mit einer großen intensität durchgeführt werden.</p>
</td>
</tr>
</table>
</th>
<td id="S11.T3.1.1.4.3.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S11.T3.1.1.4.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.4.3.3.1.1" class="ltx_tr">
<td id="S11.T3.1.1.4.3.3.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.4.3.3.1.1.1.1" class="ltx_p ltx_align_top">This can only be detected if controls undertaken are more rigorous.</p>
</td>
</tr>
</table>
</td>
<td id="S11.T3.1.1.4.3.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S11.T3.1.1.4.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.4.3.4.1.1" class="ltx_tr">
<td id="S11.T3.1.1.4.3.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.4.3.4.1.1.1.1" class="ltx_p ltx_align_top">Blood alone moves the wheel of history, i say to you and you will understand, it is a privilege to fight.</p>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S11.T3.1.1.5.4" class="ltx_tr">
<th id="S11.T3.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Oscillatory</th>
<th id="S11.T3.1.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">
<table id="S11.T3.1.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.5.4.2.1.1" class="ltx_tr">
<td id="S11.T3.1.1.5.4.2.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.5.4.2.1.1.1.1" class="ltx_p ltx_align_top">1995 das produktionsvolumen von 30 millionen pizzen wird erreicht.</p>
</td>
</tr>
</table>
</th>
<td id="S11.T3.1.1.5.4.3" class="ltx_td ltx_align_left ltx_border_bb">
<table id="S11.T3.1.1.5.4.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.5.4.3.1.1" class="ltx_tr">
<td id="S11.T3.1.1.5.4.3.1.1.1" class="ltx_td ltx_align_left">1995 the production</td>
</tr>
<tr id="S11.T3.1.1.5.4.3.1.2" class="ltx_tr">
<td id="S11.T3.1.1.5.4.3.1.2.1" class="ltx_td ltx_align_left">reached 30 million pizzas.</td>
</tr>
</table>
</td>
<td id="S11.T3.1.1.5.4.4" class="ltx_td ltx_align_left ltx_border_bb">
<table id="S11.T3.1.1.5.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S11.T3.1.1.5.4.4.1.1" class="ltx_tr">
<td id="S11.T3.1.1.5.4.4.1.1.1" class="ltx_td ltx_align_justify">
<p id="S11.T3.1.1.5.4.4.1.1.1.1" class="ltx_p ltx_align_top">The US, for example, has been in the past two decades, but has been in the same position as the US, and has been in the United States.</p>
</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Categories and examples of hallucinations in MT by <cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite></figcaption>
</figure>
</section>
</section>
<section id="S11.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">11.2. </span>Hallucination Metrics in NMT</h3>

<div id="S11.SS2.p1" class="ltx_para">
<p id="S11.SS2.p1.1" class="ltx_p">The definition of hallucinations in machine translation (MT) tends to be qualitative and subjective, and thus researchers often identify hallucinated content manually. Most detrimentally, the appearance of hallucinations is found not to affect the BLEU score of the translated text <cite class="ltx_cite ltx_citemacro_citep">(Tian
et al<span class="ltx_text">.</span>, <a href="#bib.bib185" title="" class="ltx_ref">2020</a>; Zhou et al<span class="ltx_text">.</span>, <a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite>. There are, nevertheless, several notable efforts to automatize and quantify the search for hallucinations using statistical methods.</p>
</div>
<section id="S11.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">11.2.1. </span>Statistical Metrics</h4>

<div id="S11.SS2.SSS1.p1" class="ltx_para">
<p id="S11.SS2.SSS1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Martindale et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2019</a>)</cite> propose identifying sentence adequacy using the bag-of-vectors sentence similarity (BVSS) metric. This metric indicates that the information is lost because the reference contains more information than the MT output, or the MT output contains more information than the reference.</p>
</div>
</section>
<section id="S11.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">11.2.2. </span>Model-Based Metrics</h4>

<section id="S11.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Auxiliary Decoder</h5>

<div id="S11.SS2.SSS2.Px1.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px1.p1.1" class="ltx_p">“Faithfulness” refers to the amount of source meaning that is faithfully expressed in the translation, and it is used interchangeably with the term “adequacy” <cite class="ltx_cite ltx_citemacro_citep">(Tu
et al<span class="ltx_text">.</span>, <a href="#bib.bib187" title="" class="ltx_ref">2017</a>; Feng
et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Feng
et al<span class="ltx_text">.</span> (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> propose adding another “evaluation decoder” apart from the standard translation decoder. In their work, faithfulness is based on word-by-word translation probabilities, and is calculated in the evaluation module along with translation fluency. The loss returned by the evaluation module helps to adjust the probability returned by the translation module.</p>
</div>
</section>
<section id="S11.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Entropy Measure</h5>

<div id="S11.SS2.SSS2.Px2.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px2.p1.1" class="ltx_p">In scenarios where the ground truth of a translation is not available, an entropy measure of the average attention distribution can be used to detect hallucinations. <cite class="ltx_cite ltx_citemacro_citet">Tu
et al<span class="ltx_text">.</span> (<a href="#bib.bib188" title="" class="ltx_ref">2016</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Garg
et al<span class="ltx_text">.</span> (<a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite> show that hallucinations are visible in attention matrices. When the model outputs correct translation, the attention mechanism attends to the entire input sequence throughout decoding. However, it tends to concentrate on one point when the model outputs hallucinatory content.
The entropy is calculated on the average attention weights when the model does or does not produce hallucinations during testing.
For comparison, a clean test set is used along with the purposefully perturbed one, which is created to incite hallucinations (test sets featuring multiple repetitions).
The mean entropy returned by hallucinatory models diverges from the mean of the models that do not produce hallucinations spontaneously <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S11.SS2.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Token Level Hallucination Detection</h5>

<div id="S11.SS2.SSS2.Px3.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px3.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> propose a method for detecting hallucinated tokens within a sentence, making the search more fine-grained. They use a synthetic dataset that is created by adding noise to the source data, more specifically it is generated by a language model with certain tokens of correct translations masked. Tokens in synthetic data are labeled as hallucinated (1) or not (0). Then the authors compute the hallucination prediction loss between binary labels and the tokens from the hallucinated sentence.
This work further employs a word alignment-based method and overlap-based method as baselines for hallucination.</p>
</div>
</section>
<section id="S11.SS2.SSS2.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Similarity-based Mathods</h5>

<div id="S11.SS2.SSS2.Px4.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px4.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> use an unsupervised model that extracts alignments from similarity matrices of word embeddings <cite class="ltx_cite ltx_citemacro_citep">(Sabet
et al<span class="ltx_text">.</span>, <a href="#bib.bib163" title="" class="ltx_ref">2020</a>)</cite>, and then predicts the target token as hallucinated if it is not aligned to the source.
<cite class="ltx_cite ltx_citemacro_citet">Parthasarathi et al<span class="ltx_text">.</span> (<a href="#bib.bib142" title="" class="ltx_ref">2021</a>)</cite> propose calculating faithfulness by computing similarity scores between perturbed source sentence and target sentence after applying the same perturbation.</p>
</div>
</section>
<section id="S11.SS2.SSS2.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Overlap-based Mathods</h5>

<div id="S11.SS2.SSS2.Px5.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px5.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> predict that the target token is hallucinated if it does not appear in the source. Since the target and source are two different languages, the authors use the density matching method for bilingual synonyms from <cite class="ltx_cite ltx_citemacro_citet">Zhou
et al<span class="ltx_text">.</span> (<a href="#bib.bib237" title="" class="ltx_ref">2019</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Kong
et al<span class="ltx_text">.</span> (<a href="#bib.bib88" title="" class="ltx_ref">2019</a>)</cite> suggest the Coverage Difference Ratio (CDR) as the metric to evaluate adequacy, which is especially successful in finding cases of under-translation. It is estimated by comparing source words covered by generated translation with human translations.</p>
</div>
<div id="S11.SS2.SSS2.Px5.p2" class="ltx_para">
<p id="S11.SS2.SSS2.Px5.p2.1" class="ltx_p">The overlap-based methods for detecting hallucinations are heuristics based on the assumption that all translated words should appear in the source. However, this is not always the case, e.g., when paraphrasing or using synonyms. Using word embeddings as similarity-based methods helps avoid such simplifications and allows more diverse, synonymous translations.
</p>
</div>
</section>
<section id="S11.SS2.SSS2.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Approximate Natural Hallucination Detection</h5>

<div id="S11.SS2.SSS2.Px6.p1" class="ltx_para">
<p id="S11.SS2.SSS2.Px6.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite> propose Approximate Natural Hallucination (ANH) detection based on the fact that hallucinations often occur as oscillations (repeating n-grams) and the lower unique bigram count indicates a higher appearance of oscillatory hallucinations. Furthermore, the ANH detection method searches for repeated targets in the translation output. Their method finds translation above a certain n-gram threshold and searches for repeated targets in the output translation, following the assumption that if hallucinations are often incited by aligning unique sources to the same target, then repeating targets will also appear during the inference <cite class="ltx_cite ltx_citemacro_citep">(Tu
et al<span class="ltx_text">.</span>, <a href="#bib.bib188" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S11.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">11.3. </span>Hallucination Mitigation Methods in NMT</h3>

<div id="S11.SS3.p1" class="ltx_para">
<p id="S11.SS3.p1.1" class="ltx_p">Hallucinations in MT are hard to discover for a person who is not fluent in the target language, and thus they can lead to many possible errors, or even dangers. Out of all the natural language generation tasks, NMT engines such as Google in the English-speaking internet and Baidu in the Sinosphere are probably the most widely accessible to netizens. Consequently, there is a big interest in improving NMT´s performance, also by mitigating hallucinations. This subsection compiles methods of mitigating hallucinations in NMT.</p>
</div>
<section id="S11.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">11.3.1. </span>Data-Related</h4>

<div id="S11.SS3.SSS1.p1" class="ltx_para">
<p id="S11.SS3.SSS1.p1.1" class="ltx_p">Data augmentation appears to be one of the most common methods for removing hallucination. <cite class="ltx_cite ltx_citemacro_citet">Lee et al<span class="ltx_text">.</span> (<a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite> suggest addition of perturbed sentences. Furthermore, perturbation, where the insertions of most common tokens are placed at the beginning of the sentence, seems to be the most successful in hallucination mitigation. A disadvantage of this method is the need to understand different types of hallucinations produced by the model in order to apply a correct augmentation method.
Corpus filtering is a method of mitigating hallucinations caused by the noise in the dataset by removing the repetitive and mismatching source and target sequences <cite class="ltx_cite ltx_citemacro_citep">(Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Junczys-Dowmunt <span id="S11.SS3.SSS1.p1.1.1.1.1.1" class="ltx_text" style="color:#000000;">(</span><a href="#bib.bib80" title="" class="ltx_ref">2018</a><span id="S11.SS3.SSS1.p1.1.2.2.2.1" class="ltx_text" style="color:#000000;">)</span></cite><span id="S11.SS3.SSS1.p1.1.3" class="ltx_text" style="color:#000000;"> implements a cross-entropy data filtering method for bilingual data, which uses cross-entropy scores calculated for noisy pairs according to two translation models trained on the clean data. The scores that suggest dissagreament between sentence pairs from two models are subsequently penalized.</span></p>
</div>
<div id="S11.SS3.SSS1.p2" class="ltx_para">
<p id="S11.SS3.SSS1.p2.1" class="ltx_p">While <cite class="ltx_cite ltx_citemacro_citep">(Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>; Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Junczys-Dowmunt, <a href="#bib.bib80" title="" class="ltx_ref">2018</a>)</cite> define noise as mismatched source and target sentences,  <cite class="ltx_cite ltx_citemacro_citep">(Briakou and
Carpuat, <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> analyzes the influence of fine-grained semantic divergences on NMT outputs. The authors consequently propose a mitigation method for fine-grained divergences based on semantic factors. The tags are applied to each source and target sentence to inform about the position of divergent tokens. Factorizing divergence not only helps to mitigate hallucinations, but improves the overall performance of the NMT. This shows that tagging small semantic divergences can provide useful information for the network during training.</p>
</div>
</section>
<section id="S11.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">11.3.2. </span>Modeling and Inference</h4>

<div id="S11.SS3.SSS2.p1" class="ltx_para">
<p id="S11.SS3.SSS2.p1.1" class="ltx_p">Overexposure bias is a common problem in NMT, amplified by the teacher-forcing technique used in sequence-to-sequence models. The models are trained on the ground truth, but during inference, they attend to the past predictions, which can be incorrect <cite class="ltx_cite ltx_citemacro_citep">(Ranzato
et al<span class="ltx_text">.</span>, <a href="#bib.bib152" title="" class="ltx_ref">2016</a>; Kong
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2019</a>)</cite>.
To mitigate this problem, <cite class="ltx_cite ltx_citemacro_citet">Wang and Sennrich (<a href="#bib.bib194" title="" class="ltx_ref">2020</a>)</cite> propose substituting MLE as a training objective with minimum risk training (MRT) <cite class="ltx_cite ltx_citemacro_citep">(Och, <a href="#bib.bib139" title="" class="ltx_ref">2003</a>)</cite>.
Scheduled sampling is a classic method of mitigating overexposure bias first proposed by <cite class="ltx_cite ltx_citemacro_citep">(Bengio
et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2015</a>)</cite>. Based on that method, <cite class="ltx_cite ltx_citemacro_citep">(Goyal
et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2017</a>)</cite> create a differentiable approximation to greedy decoding that shows a good performance in the NMT task. <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib216" title="" class="ltx_ref">2019</a>)</cite> propose further improvement of the scheduled sampling algorithm for NMT by optimizing the probability of source and target word alignments. This improvement helps to address the issue flexibility in word order between a source and target language when performing scheduled sampling.</p>
</div>
<div id="S11.SS3.SSS2.p2" class="ltx_para">
<p id="S11.SS3.SSS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> propose a method of improving self-training of NMT based on hallucination detection. They create hallucination labels (see Section <a href="#S11.SS2.SSS2.Px3" title="Token Level Hallucination Detection ‣ 11.2.2. Model-Based Metrics ‣ 11.2. Hallucination Metrics in NMT ‣ 11. Hallucinations in Neural Machine Translation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.2.2</span></a>), and then discard losses of tokens predicted as hallucinations, which is known as token loss truncation. This is similar to the method proposed by <cite class="ltx_cite ltx_citemacro_citet">Kang and
Hashimoto (<a href="#bib.bib82" title="" class="ltx_ref">2020a</a>)</cite>, the latter for full sentences in the summarization task. Furthermore, instead of adjusting losses, <cite class="ltx_cite ltx_citemacro_citet">Zhou et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2021b</a>)</cite> mask the hidden states of the discarded losses in the decoder in a procedure called decoder HS masking. Experimental results show both a translation quality improvement in terms of BLEU and also a large reduction in hallucination. The token loss truncation method shows good results in the low-resource languages scenario.</p>
</div>
<div id="S11.SS3.SSS2.p3" class="ltx_para">
<p id="S11.SS3.SSS2.p3.1" class="ltx_p">Another method to mitigate the impact of noisy datasets is tilted empirical risk minimization (TERM), a training objective proposed by <cite class="ltx_cite ltx_citemacro_citet">Li
et al<span class="ltx_text">.</span> (<a href="#bib.bib108" title="" class="ltx_ref">2020a</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite> mentions that techniques such as dropout, L2E regularization, and clipping tend to decrease the number of hallucinations. Lastly, several authors propose methods of improving phrase alignment that are helpful both in increasing translation accuracy and identifying content that did not appear in the source translation <cite class="ltx_cite ltx_citemacro_citep">(Weng
et al<span class="ltx_text">.</span>, <a href="#bib.bib206" title="" class="ltx_ref">2020</a>; Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib228" title="" class="ltx_ref">2021b</a>; Garg
et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite>.
</p>
</div>
</section>
</section>
<section id="S11.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">11.4. </span>Future Directions in NMT</h3>

<div id="S11.SS4.p1" class="ltx_para">
<p id="S11.SS4.p1.1" class="ltx_p">The future work on hallucinations in NMT is to define hallucinations in a quantifiable manner; i.e., to specify a cut-off value between translation error and hallucinated content using a particular metric.
<cite class="ltx_cite ltx_citemacro_citet">Martindale et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2019</a>)</cite> propose a threshold between fluency and adequacy which is the closest to this ideal. They, however, do not concentrate on hallucinated content as such, and thus fluent but inadequate sentences may not always indicate hallucinations but also other types of translation errors.
<cite class="ltx_cite ltx_citemacro_citet">Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> mention constrained decoding as a method to mitigate hallucinations in dialogue systems, but it could also be applied in NMT. <cite class="ltx_cite ltx_citemacro_citep">(Hokamp and Liu, <a href="#bib.bib71" title="" class="ltx_ref">2017</a>; Post and Vilar, <a href="#bib.bib147" title="" class="ltx_ref">2018</a>; Song
et al<span class="ltx_text">.</span>, <a href="#bib.bib172" title="" class="ltx_ref">2019</a>; Dinu
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2019</a>; Susanto
et al<span class="ltx_text">.</span>, <a href="#bib.bib178" title="" class="ltx_ref">2020</a>; Xu and Carpuat, <a href="#bib.bib215" title="" class="ltx_ref">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Xu and Carpuat, <a href="#bib.bib214" title="" class="ltx_ref">2020</a>)</cite> use constrained decoding to incorporate specific terminology into MT, but the above methods can be repurposed to mitigate hallucinations.
</p>
</div>
<div id="S11.SS4.p2" class="ltx_para">
<p id="S11.SS4.p2.1" class="ltx_p">Another direction for future work on hallucinations is improving existing methods of searching for hallucinatory content, such as the algorithms proposed by <cite class="ltx_cite ltx_citemacro_citet">Lee et al<span class="ltx_text">.</span> (<a href="#bib.bib96" title="" class="ltx_ref">2019</a>); Feng
et al<span class="ltx_text">.</span> (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Raunak
et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite>, that are computationally expensive <cite class="ltx_cite ltx_citemacro_citep">(Raunak
et al<span class="ltx_text">.</span>, <a href="#bib.bib154" title="" class="ltx_ref">2021</a>)</cite> or require the creation of an additional perturbed test-set <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite>.
Similarly, for mitigation of lack of faithfulness and fluency, the method proposed by <cite class="ltx_cite ltx_citemacro_citet">Feng
et al<span class="ltx_text">.</span> (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> requires the creation of a one-to-many architecture (one encoder and two decoders), which is also computationally expensive.
Future directions would therefore include simplification of existing hallucination evaluation methods, applying them to different architectures like CNNs and transformers, and possibly conducting research on finding simpler hallucination search methods.</p>
</div>
</section>
</section>
<section id="S12" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">12. </span>Hallucination in Vision-Language Generation</h2>

<div id="S12.p1" class="ltx_para">
<p id="S12.p1.1" class="ltx_p">With the vast advancement of the Transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib190" title="" class="ltx_ref">2017</a>; Dosovitskiy et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite> in both CV and NLP, there is a trend to pre-train large-scale unified vision-language (VL) models <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib197" title="" class="ltx_ref">2022b</a>; Dai
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2022a</a>; Li
et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2022</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib201" title="" class="ltx_ref">2022c</a>; Alayrac
et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2022</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib198" title="" class="ltx_ref">2022a</a>)</cite> to perform vision grounded text generation tasks, such as image captioning and visual question answering (VQA). Generally, there are two common schemas for vision-language pre-training: 1) pre-train from scratch with a massive amount of image-text pairs as well as optionally a large text-only corpus; or 2) initialize model parameters from a large pre-trained LM and then adapt it to the VL domain with adequate image-text pairs. Either way, the learned vision and language representations are aligned in the same multimodal space and the resulting model can be seen as a LM that understands visual information. Therefore, the hallucination problem is also observed in VL models due to similar reasons as found in NLG.</p>
</div>
<div id="S12.p2" class="ltx_para">
<p id="S12.p2.1" class="ltx_p">In the VL domain, the research on hallucination is still in its very early stage and how to measure and mitigate hallucination is an open question. In this section, we first review the hallucination in image captioning as it is the only VL task that has corresponding previous research works. Then, we introduce hallucination phenomena found in other VL tasks. Finally, we discuss potential future research directions on this problem.</p>
</div>
<section id="S12.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">12.1. </span>Object Hallucination in Image Captioning</h3>

<section id="S12.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Definition.</h5>

<div id="S12.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S12.SS1.SSS0.Px1.p1.1" class="ltx_p">Object hallucination is defined as models generating captions that contain non-existent or inaccurate objects from the input image. Following tasks in NLG, we also categorize object hallucination into intrinsic and extrinsic ones:</p>
</div>
<figure id="S12.F2" class="ltx_figure"><img src="x1.png" id="S12.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="540" height="215" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Examples of intrinsic and extrinsic object hallucination in image captioning.</figcaption>
</figure>
<div id="S12.SS1.SSS0.Px1.p2" class="ltx_para">
<ul id="S12.I1" class="ltx_itemize">
<li id="S12.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S12.I1.i1.p1" class="ltx_para">
<p id="S12.I1.i1.p1.1" class="ltx_p">Intrinsic Object Hallucination: captions contain incorrect or definitely non-existent objects given the input image. For example in Figure <a href="#S12.F2" title="Figure 2 ‣ Definition. ‣ 12.1. Object Hallucination in Image Captioning ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, there is no <span id="S12.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">“mirror”</span> or <span id="S12.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">“football”</span> on top of the chest in the given image.</p>
</div>
</li>
<li id="S12.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S12.I1.i2.p1" class="ltx_para">
<p id="S12.I1.i2.p1.1" class="ltx_p">Extrinsic Object Hallucination: captions contain objects cannot be verified their existence from the input image. For example in Figure <a href="#S12.F2" title="Figure 2 ‣ Definition. ‣ 12.1. Object Hallucination in Image Captioning ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we cannot verify whether there are <span id="S12.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">“letters”</span> in the drawer or a <span id="S12.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">“fan”</span> on the roof.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S12.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Metrics</h5>

<div id="S12.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S12.SS1.SSS0.Px2.p1.2" class="ltx_p">To automatically measure object hallucination, <cite class="ltx_cite ltx_citemacro_citet">Rohrbach et al<span class="ltx_text">.</span> (<a href="#bib.bib160" title="" class="ltx_ref">2018</a>)</cite> propose the CHAIR (Caption Hallucination Assessment with Image Relevance) metric, which calculates what proportion of object words generated are actually in the image according to the ground truth captions. Specifically, there are two variants of it, which are CHAIR<math id="S12.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="{}_{i}" display="inline"><semantics id="S12.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S12.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S12.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S12.SS1.SSS0.Px2.p1.1.m1.1.1a" xref="S12.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"></mi><mi id="S12.SS1.SSS0.Px2.p1.1.m1.1.1.1" xref="S12.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S12.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S12.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p1.1.m1.1.1"><ci id="S12.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p1.1.m1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S12.SS1.SSS0.Px2.p1.1.m1.1c">{}_{i}</annotation><annotation encoding="application/x-llamapun" id="S12.SS1.SSS0.Px2.p1.1.m1.1d">start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT</annotation></semantics></math> and CHAIR<math id="S12.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="{}_{s}" display="inline"><semantics id="S12.SS1.SSS0.Px2.p1.2.m2.1a"><msub id="S12.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S12.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S12.SS1.SSS0.Px2.p1.2.m2.1.1a" xref="S12.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"></mi><mi id="S12.SS1.SSS0.Px2.p1.2.m2.1.1.1" xref="S12.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S12.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S12.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S12.SS1.SSS0.Px2.p1.2.m2.1.1"><ci id="S12.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p1.2.m2.1.1.1">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S12.SS1.SSS0.Px2.p1.2.m2.1c">{}_{s}</annotation><annotation encoding="application/x-llamapun" id="S12.SS1.SSS0.Px2.p1.2.m2.1d">start_FLOATSUBSCRIPT italic_s end_FLOATSUBSCRIPT</annotation></semantics></math> defined as follows,</p>
</div>
<div id="S12.SS1.SSS0.Px2.p2" class="ltx_para">
<table id="S13.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S12.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S12.Ex1.m1.1" class="ltx_Math" alttext="\displaystyle\textrm{CHAIR}_{i}=\frac{\textrm{\# \{hallucinated objects\}}}{\textrm{\# \{all objects in ground truth\}}},\textrm{CHAIR}_{s}=\frac{\textrm{\# \{hallucinated captions\}}}{\textrm{\# \{all captions\}}}." display="inline"><semantics id="S12.Ex1.m1.1a"><mrow id="S12.Ex1.m1.1.1.1"><mrow id="S12.Ex1.m1.1.1.1.1.2" xref="S12.Ex1.m1.1.1.1.1.3.cmml"><mrow id="S12.Ex1.m1.1.1.1.1.1.1" xref="S12.Ex1.m1.1.1.1.1.1.1.cmml"><msub id="S12.Ex1.m1.1.1.1.1.1.1.2" xref="S12.Ex1.m1.1.1.1.1.1.1.2.cmml"><mtext id="S12.Ex1.m1.1.1.1.1.1.1.2.2" xref="S12.Ex1.m1.1.1.1.1.1.1.2.2a.cmml">CHAIR</mtext><mi id="S12.Ex1.m1.1.1.1.1.1.1.2.3" xref="S12.Ex1.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S12.Ex1.m1.1.1.1.1.1.1.1" xref="S12.Ex1.m1.1.1.1.1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S12.Ex1.m1.1.1.1.1.1.1.3" xref="S12.Ex1.m1.1.1.1.1.1.1.3.cmml"><mfrac id="S12.Ex1.m1.1.1.1.1.1.1.3a" xref="S12.Ex1.m1.1.1.1.1.1.1.3.cmml"><mtext id="S12.Ex1.m1.1.1.1.1.1.1.3.2" xref="S12.Ex1.m1.1.1.1.1.1.1.3.2a.cmml"># {hallucinated objects}</mtext><mtext id="S12.Ex1.m1.1.1.1.1.1.1.3.3" xref="S12.Ex1.m1.1.1.1.1.1.1.3.3a.cmml"># {all objects in ground truth}</mtext></mfrac></mstyle></mrow><mo id="S12.Ex1.m1.1.1.1.1.2.3" xref="S12.Ex1.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S12.Ex1.m1.1.1.1.1.2.2" xref="S12.Ex1.m1.1.1.1.1.2.2.cmml"><msub id="S12.Ex1.m1.1.1.1.1.2.2.2" xref="S12.Ex1.m1.1.1.1.1.2.2.2.cmml"><mtext id="S12.Ex1.m1.1.1.1.1.2.2.2.2" xref="S12.Ex1.m1.1.1.1.1.2.2.2.2a.cmml">CHAIR</mtext><mi id="S12.Ex1.m1.1.1.1.1.2.2.2.3" xref="S12.Ex1.m1.1.1.1.1.2.2.2.3.cmml">s</mi></msub><mo id="S12.Ex1.m1.1.1.1.1.2.2.1" xref="S12.Ex1.m1.1.1.1.1.2.2.1.cmml">=</mo><mstyle displaystyle="true" id="S12.Ex1.m1.1.1.1.1.2.2.3" xref="S12.Ex1.m1.1.1.1.1.2.2.3.cmml"><mfrac id="S12.Ex1.m1.1.1.1.1.2.2.3a" xref="S12.Ex1.m1.1.1.1.1.2.2.3.cmml"><mtext id="S12.Ex1.m1.1.1.1.1.2.2.3.2" xref="S12.Ex1.m1.1.1.1.1.2.2.3.2a.cmml"># {hallucinated captions}</mtext><mtext id="S12.Ex1.m1.1.1.1.1.2.2.3.3" xref="S12.Ex1.m1.1.1.1.1.2.2.3.3a.cmml"># {all captions}</mtext></mfrac></mstyle></mrow></mrow><mo lspace="0em" id="S12.Ex1.m1.1.1.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S12.Ex1.m1.1b"><apply id="S12.Ex1.m1.1.1.1.1.3.cmml" xref="S12.Ex1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S12.Ex1.m1.1.1.1.1.3a.cmml" xref="S12.Ex1.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S12.Ex1.m1.1.1.1.1.1.1.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1"><eq id="S12.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.1"></eq><apply id="S12.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S12.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S12.Ex1.m1.1.1.1.1.1.1.2.2a.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.2.2"><mtext id="S12.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.2.2">CHAIR</mtext></ci><ci id="S12.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S12.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3"><divide id="S12.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3"></divide><ci id="S12.Ex1.m1.1.1.1.1.1.1.3.2a.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3.2"><mtext id="S12.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3.2"># {hallucinated objects}</mtext></ci><ci id="S12.Ex1.m1.1.1.1.1.1.1.3.3a.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3.3"><mtext id="S12.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S12.Ex1.m1.1.1.1.1.1.1.3.3"># {all objects in ground truth}</mtext></ci></apply></apply><apply id="S12.Ex1.m1.1.1.1.1.2.2.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2"><eq id="S12.Ex1.m1.1.1.1.1.2.2.1.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.1"></eq><apply id="S12.Ex1.m1.1.1.1.1.2.2.2.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S12.Ex1.m1.1.1.1.1.2.2.2.1.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S12.Ex1.m1.1.1.1.1.2.2.2.2a.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.2.2"><mtext id="S12.Ex1.m1.1.1.1.1.2.2.2.2.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.2.2">CHAIR</mtext></ci><ci id="S12.Ex1.m1.1.1.1.1.2.2.2.3.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.2.3">𝑠</ci></apply><apply id="S12.Ex1.m1.1.1.1.1.2.2.3.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3"><divide id="S12.Ex1.m1.1.1.1.1.2.2.3.1.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3"></divide><ci id="S12.Ex1.m1.1.1.1.1.2.2.3.2a.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3.2"><mtext id="S12.Ex1.m1.1.1.1.1.2.2.3.2.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3.2"># {hallucinated captions}</mtext></ci><ci id="S12.Ex1.m1.1.1.1.1.2.2.3.3a.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3.3"><mtext id="S12.Ex1.m1.1.1.1.1.2.2.3.3.cmml" xref="S12.Ex1.m1.1.1.1.1.2.2.3.3"># {all captions}</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S12.Ex1.m1.1c">\displaystyle\textrm{CHAIR}_{i}=\frac{\textrm{\# \{hallucinated objects\}}}{\textrm{\# \{all objects in ground truth\}}},\textrm{CHAIR}_{s}=\frac{\textrm{\# \{hallucinated captions\}}}{\textrm{\# \{all captions\}}}.</annotation><annotation encoding="application/x-llamapun" id="S12.Ex1.m1.1d">CHAIR start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG # {hallucinated objects} end_ARG start_ARG # {all objects in ground truth} end_ARG , CHAIR start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = divide start_ARG # {hallucinated captions} end_ARG start_ARG # {all captions} end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S12.SS1.SSS0.Px2.p3" class="ltx_para ltx_noindent">
<p id="S12.SS1.SSS0.Px2.p3.2" class="ltx_p">CHAIR<math id="S12.SS1.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="{}_{i}" display="inline"><semantics id="S12.SS1.SSS0.Px2.p3.1.m1.1a"><msub id="S12.SS1.SSS0.Px2.p3.1.m1.1.1" xref="S12.SS1.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S12.SS1.SSS0.Px2.p3.1.m1.1.1a" xref="S12.SS1.SSS0.Px2.p3.1.m1.1.1.cmml"></mi><mi id="S12.SS1.SSS0.Px2.p3.1.m1.1.1.1" xref="S12.SS1.SSS0.Px2.p3.1.m1.1.1.1.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S12.SS1.SSS0.Px2.p3.1.m1.1b"><apply id="S12.SS1.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p3.1.m1.1.1"><ci id="S12.SS1.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p3.1.m1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S12.SS1.SSS0.Px2.p3.1.m1.1c">{}_{i}</annotation><annotation encoding="application/x-llamapun" id="S12.SS1.SSS0.Px2.p3.1.m1.1d">start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT</annotation></semantics></math> measures per-instance object hallucination, i.e. what fraction of object instances in each generated caption are hallucinated. CHAIR<math id="S12.SS1.SSS0.Px2.p3.2.m2.1" class="ltx_Math" alttext="{}_{s}" display="inline"><semantics id="S12.SS1.SSS0.Px2.p3.2.m2.1a"><msub id="S12.SS1.SSS0.Px2.p3.2.m2.1.1" xref="S12.SS1.SSS0.Px2.p3.2.m2.1.1.cmml"><mi id="S12.SS1.SSS0.Px2.p3.2.m2.1.1a" xref="S12.SS1.SSS0.Px2.p3.2.m2.1.1.cmml"></mi><mi id="S12.SS1.SSS0.Px2.p3.2.m2.1.1.1" xref="S12.SS1.SSS0.Px2.p3.2.m2.1.1.1.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S12.SS1.SSS0.Px2.p3.2.m2.1b"><apply id="S12.SS1.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S12.SS1.SSS0.Px2.p3.2.m2.1.1"><ci id="S12.SS1.SSS0.Px2.p3.2.m2.1.1.1.cmml" xref="S12.SS1.SSS0.Px2.p3.2.m2.1.1.1">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S12.SS1.SSS0.Px2.p3.2.m2.1c">{}_{s}</annotation><annotation encoding="application/x-llamapun" id="S12.SS1.SSS0.Px2.p3.2.m2.1d">start_FLOATSUBSCRIPT italic_s end_FLOATSUBSCRIPT</annotation></semantics></math> measures per-sentence object hallucination, i.e. what fraction of generated captions include at least one hallucinated object. For example, to calculate CHAIR scores for the MSCOCO dataset <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2014</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Rohrbach et al<span class="ltx_text">.</span> (<a href="#bib.bib160" title="" class="ltx_ref">2018</a>)</cite> apply the 80-object list used in the MSCOCO segmentation challenge <cite class="ltx_cite ltx_citemacro_citet">Lu
et al<span class="ltx_text">.</span> (<a href="#bib.bib117" title="" class="ltx_ref">2018</a>)</cite> and find exact matches of object words or phrases in captions.</p>
</div>
</section>
<section id="S12.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Mitigation</h5>

<div id="S12.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S12.SS1.SSS0.Px3.p1.1" class="ltx_p">As a research problem that is in its early stage, there are currently a limited number of approaches proposed to mitigate object hallucination in image captioning. <cite class="ltx_cite ltx_citemacro_citet">Biten
et al<span class="ltx_text">.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite> hypothesize that the main cause of object hallucination is the systematic co-occurence of particular object categories in input images. They propose three simple yet effective ways of data augmentation to make the co-occurence statistics matrix more uniform to mitigate object hallucination. Results show that their introduced method can reduce object hallucination without changing model architectures. From another perspective, <cite class="ltx_cite ltx_citemacro_citet">Xiao and Wang (<a href="#bib.bib212" title="" class="ltx_ref">2021</a>)</cite> propose an uncertainty-aware beam search method for decoding and exhibit that reducing uncertainty can lead to less hallucination. Specifically, a weighted penalty term is added to the beam search objective to balance between log probability and predictive uncertainty of the selected word candidates. More recently, <cite class="ltx_cite ltx_citemacro_citet">Dai
et al<span class="ltx_text">.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2022b</a>)</cite> analyze object hallucination in VL pre-training and propose a novel pre-training objective named object masked language modeling to alleviate this problem.
</p>
</div>
</section>
</section>
<section id="S12.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">12.2. </span>Hallucination in Other VL Tasks</h3>

<div id="S12.SS2.p1" class="ltx_para">
<p id="S12.SS2.p1.1" class="ltx_p">In addition to image captioning, hallucination has also been observed in other VL tasks and raised as an open research question. For example, in open-ended visual question answering, Figure <a href="#S12.F3" title="Figure 3 ‣ 12.2. Hallucination in Other VL Tasks ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (left and right) shows that the model could generate seem likely answers when we only see the text, however wrong when given the image. Moreover, Figure <a href="#S12.F3" title="Figure 3 ‣ 12.2. Hallucination in Other VL Tasks ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (middle) indicates that hallucination can also be triggered by adversarially prompting an unanswerable question. The model will imagine an unsupported answer that commonly matches the given visual scene.</p>
</div>
<figure id="S12.F3" class="ltx_figure"><img src="x2.png" id="S12.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="747" height="301" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Examples of hallucination in visual question answering (taken from <cite class="ltx_cite ltx_citemacro_citep">(Alayrac
et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>). The bold text is the output generated by the model and the part before it is the input prompt.</figcaption>
</figure>
</section>
<section id="S12.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">12.3. </span>Future Directions in VL</h3>

<div id="S12.SS3.p1" class="ltx_para">
<p id="S12.SS3.p1.1" class="ltx_p">For future research on the hallucination problem in VL, we summarize three promising directions.
Firstly, hallucination in VL is still in the early stage. There is a lack of empirical and theoretical analyses in many tasks, such as visual storytelling, visual commonsense reasoning, video captioning, etc. Secondly, more effective evaluation metrics are needed. For example, although CHAIR can automatically evaluate the degree of object hallucination in image captioning, it requires a pre-defined list of object categories, which does not generalize well. Furthermore, for the hallucination types discussed in Section <a href="#S12.SS2" title="12.2. Hallucination in Other VL Tasks ‣ 12. Hallucination in Vision-Language Generation ‣ Survey of Hallucination in Natural Language Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12.2</span></a>, currently there is no automatic metric. Therefore, we cannot perform quantitative evaluations for them. Thirdly, we believe how to perform controlled generation <cite class="ltx_cite ltx_citemacro_citep">(Rebuffel et al<span class="ltx_text">.</span>, <a href="#bib.bib155" title="" class="ltx_ref">2022</a>; Dai
et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022b</a>)</cite> with visual grounding is a promising direction to mitigate hallucination in VL.</p>
</div>
</section>
</section>
<section id="S13" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">13. </span>Conclusion</h2>

<div id="S13.p1" class="ltx_para">
<p id="S13.p1.1" class="ltx_p">In this survey, we provide the first comprehensive overview of the hallucination problem in NLG, summarizing existing evaluation metrics, mitigation methods, and the remaining challenges for future research.
Hallucination is an artifact of neural-based NLG and is of concern because they appear fluent and can therefore be misleading to users. In some scenarios and tasks, hallucination can cause harm. We survey various contributors to hallucination, ranging from noisy data, erroneous parametric knowledge, incorrect attention mechanism, inappropriate training strategy, to inference exposure bias, etc. We show that there are two categories of hallucinations, namely intrinsic hallucination and extrinsic hallucination, and they need to be treated differently with diverse mitigation strategies. Hallucination is relatively easy to detect in abstractive summarization and in NMT against the evidence in the source. For dialogue systems, it is important to balance diversity vs consistency in dialogue responses. Hallucination in GQA and VL tasks is detrimental to the performance, but research on mitigation methods is still very preliminary in these areas. For data-to-text generation, hallucination arises from the discrepancy between the input and output format. Most methods to mitigate hallucinations in NMT either aim to reduce dataset noise or alleviate exposure bias.
In the VL domain, models also generate unfaithful output given the visual scene, and recent works have mainly focused on the object hallucination problem.
There remain many challenges ahead in identifying and mitigating hallucinations in NLG, and we hope research in this area can benefit from this survey.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alayrac
et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jean-Baptiste Alayrac,
Jeff Donahue, Pauline Luc,
Antoine Miech, Iain Barr,
Yana Hasson, Karel Lenc,
Arthur Mensch, Katie Millican,
Malcolm Reynolds, Roman Ring,
Eliza Rutherford, Serkan Cabi,
Tengda Han, Zhitao Gong,
Sina Samangooei, Marianne Monteiro,
Jacob Menick, Sebastian Borgeaud,
Andy Brock, Aida Nematzadeh,
Sahand Sharifzadeh, Mikolaj Binkowski,
Ricardo Barreira, Oriol Vinyals,
Andrew Zisserman, and Karen Simonyan.
2022.

</span>
<span class="ltx_bibblock">Flamingo: a Visual Language Model for Few-Shot
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2204.14198
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albrecht and Hwa (2007)</span>
<span class="ltx_bibblock">
Joshua Albrecht and
Rebecca Hwa. 2007.

</span>
<span class="ltx_bibblock">A Re-examination of Machine Learning Approaches for
Sentence-Level MT Evaluation. In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 45th Annual Meeting of the Association of Computational Linguistics</em>.
Association for Computational Linguistics,
Prague, Czech Republic, 880–887.

</span>
<span class="ltx_bibblock">
<a href="https://aclanthology.org/P07-1111" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/P07-1111</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aralikatte et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Rahul Aralikatte, Shashi
Narayan, Joshua Maynez, Sascha Rothe,
and Ryan McDonald. 2021.

</span>
<span class="ltx_bibblock">Focus Attention: Promoting Faithfulness and
Diversity in Summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">ACL</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai
et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Xiang Bai, Xinggang Wang,
Longin Jan Latecki, Wenyu Liu, and
Zhuowen Tu. 2009.

</span>
<span class="ltx_bibblock">Active Skeleton for Non-rigid Object Detection. In
<em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">2009 IEEE 12th International Conference on Computer
Vision</em>. 575–582.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.1109/ICCV.2009.5459188" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCV.2009.5459188</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker and Kanade (2000)</span>
<span class="ltx_bibblock">
S. Baker and T.
Kanade. 2000.

</span>
<span class="ltx_bibblock">Hallucinating Faces. In
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings Fourth IEEE International Conference on
Automatic Face and Gesture Recognition (Cat. No. PR00580)</em>.
83–88.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.1109/AFGR.2000.840616" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/AFGR.2000.840616</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balakrishnan et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Anusha Balakrishnan,
Jinfeng Rao, Kartikeya Upasani,
Michael White, and Rajen Subba.
2019.

</span>
<span class="ltx_bibblock">Constrained Decoding for Neural NLG from
Compositional Representations in Task-Oriented Dialogue. In
<em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. Association
for Computational Linguistics, Florence, Italy,
831–844.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P19-1080" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1080</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baly et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ramy Baly, Georgi
Karadzhov, Dimitar Alexandrov, James
Glass, and Preslav Nakov.
2018.

</span>
<span class="ltx_bibblock">Predicting Factuality of Reporting and Bias of News
Media Sources. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing</em>.
3528–3539.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beltagy
et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Iz Beltagy, Matthew E.
Peters, and Arman Cohan.
2020.

</span>
<span class="ltx_bibblock">Longformer: The Long-Document Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">arXiv:2004.05150</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio
et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Samy Bengio, Oriol
Vinyals, Navdeep Jaitly, and Noam
Shazeer. 2015.

</span>
<span class="ltx_bibblock">Scheduled Sampling for Sequence Prediction with
Recurrent Neural Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 28 (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beyer
et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Anne Beyer, Sharid
Loáiciga, and David Schlangen.
2021.

</span>
<span class="ltx_bibblock">Is Incoherence Surprising? Targeted Evaluation of
Coherence Prediction from Language Models. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies</em>. Association for Computational
Linguistics, Online, 4164–4173.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.naacl-main.328" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.naacl-main.328</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bi
et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bin Bi, Chen Wu,
Ming Yan, Wei Wang,
Jiangnan Xia, and Chenliang Li.
2019.

</span>
<span class="ltx_bibblock">Incorporating External Knowledge into Machine
Reading for Generative Question Answering. In
<em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)</em>.
2521–2530.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Białecki et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Andrzej Białecki,
Robert Muir, Grant Ingersoll, and
Lucid Imagination. 2012.

</span>
<span class="ltx_bibblock">Apache lucene 4. In
<em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">SIGIR 2012 workshop on open source information
retrieval</em>. 17.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biten
et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ali Furkan Biten,
Lluís Gómez, and Dimosthenis
Karatzas. 2022.

</span>
<span class="ltx_bibblock">Let There Be a Clock on the Beach: Reducing Object
Hallucination in Image Captioning. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the IEEE/CVF Winter Conference on Applications of Computer Vision
(WACV)</em>. 1381–1390.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blom ([n. d.])</span>
<span class="ltx_bibblock">
Jan Dirk Blom.
[n. d.].

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">A Dictionary of Hallucinations</em>.

</span>
<span class="ltx_bibblock">Springer.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briakou and
Carpuat (2021)</span>
<span class="ltx_bibblock">
Eleftheria Briakou and
Marine Carpuat. 2021.

</span>
<span class="ltx_bibblock">Beyond Noise: Mitigating the Impact of Fine-grained
Semantic Divergences on Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2105.15087
(2021).

</span>
<span class="ltx_bibblock">arXiv:2105.15087

<a href="https://arxiv.org/abs/2105.15087" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2105.15087</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown
et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann,
Nick Ryder, Melanie Subbiah,
Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh,
Daniel Ziegler, Jeffrey Wu,
Clemens Winter, Chris Hesse,
Mark Chen, Eric Sigler,
Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and
Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners. In
<em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, H. Larochelle,
M. Ranzato, R. Hadsell,
M. F. Balcan, and H. Lin (Eds.),
Vol. 33. Curran Associates, Inc.,
1877–1901.

</span>
<span class="ltx_bibblock">
<a href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao
et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Meng Cao, Yue Dong,
Jiapeng Wu, and Jackie Chi Kit Cheung.
2020.

</span>
<span class="ltx_bibblock">Factual Error Correction for Abstractive
Summarization Models. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
6251–6258.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao and Wang (2021)</span>
<span class="ltx_bibblock">
Shuyang Cao and Lu
Wang. 2021.

</span>
<span class="ltx_bibblock">CLIFF: Contrastive Learning for Improving
Faithfulness and Factuality in Abstractive Summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">EMNLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao
et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ziqiang Cao, Furu Wei,
Wenjie Li, and Sujian Li.
2018.

</span>
<span class="ltx_bibblock">Faithful to the Original: Fact Aware Neural
Abstractive Summarization. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, Vol. 32.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini
et al<span id="bib.bib21.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian
Tramèr, Eric Wallace, Matthew
Jagielski, Ariel Herbert-Voss, Katherine
Lee, Adam Roberts, Tom B Brown,
Dawn Song, Úlfar Erlingsson,
et al<span id="bib.bib21.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Extracting Training Data from Large Language
Models.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Sihao Chen, Fan Zhang,
Kazoo Sone, and Dan Roth.
2021b.

</span>
<span class="ltx_bibblock">Improving Faithfulness in Abstractive Summarization
with Contrast Candidate Generation and Selection. In
<em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies</em>. 5935–5941.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Wenqing Chen, Jidong
Tian, Yitian Li, Hao He, and
Yaohui Jin. 2021a.

</span>
<span class="ltx_bibblock">De-Confounded Variational Encoder-Decoder for
Logical Table-to-Text Generation. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 59th Annual Meeting of the Association for Computational Linguistics
and the 11th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers)</em>. 5532–5542.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhiyu Chen, Wenhu Chen,
Hanwen Zha, Xiyou Zhou,
Yunkai Zhang, Sairam Sundaresan, and
William Yang Wang. 2020.

</span>
<span class="ltx_bibblock">Logic2Text: High-Fidelity Natural Language
Generation from Logical Forms. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">EMNLP
(Findings)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chisholm
et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Andrew Chisholm, Will
Radford, and Ben Hachey.
2017.

</span>
<span class="ltx_bibblock">Learning to generate one-sentence biographies from
Wikidata. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Conference of
the European Chapter of the Association for Computational Linguistics: Volume
1, Long Papers</em>. 633–642.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crawshaw (2020)</span>
<span class="ltx_bibblock">
Michael Crawshaw.
2020.

</span>
<span class="ltx_bibblock">Multi-Task Learning with Deep Neural Networks: A
Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.09796</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui
et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Leyang Cui, Yu Wu,
Shujie Liu, Yue Zhang, and
Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">MuTual: A Dataset for Multi-Turn Dialogue
Reasoning. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics</em>.
1406–1416.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai
et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Wenliang Dai, Lu Hou,
Lifeng Shang, Xin Jiang,
Qun Liu, and Pascale Fung.
2022a.

</span>
<span class="ltx_bibblock">Enabling Multimodal Generation on CLIP via
Vision-Language Knowledge Distillation. In
<em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational
Linguistics: ACL 2022</em>. Association for Computational
Linguistics, Dublin, Ireland,
2383–2395.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2022.findings-acl.187" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2022.findings-acl.187</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai
et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Wenliang Dai, Zihan Liu,
Ziwei Ji, Dan Su, and
Pascale Fung. 2022b.

</span>
<span class="ltx_bibblock">Plausible May Not Be Faithful: Probing Object
Hallucination in Vision-Language Pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2210.07688
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin
et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding. In
<em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long and Short Papers)</em>.
Association for Computational Linguistics,
Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N19-1423</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhingra et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bhuwan Dhingra, Manaal
Faruqui, Ankur Parikh, Ming-Wei Chang,
Dipanjan Das, and William Cohen.
2019.

</span>
<span class="ltx_bibblock">Handling Divergent Reference Texts when Evaluating
Table-to-Text Generation. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
57th Annual Meeting of the Association for Computational Linguistics</em>.
4884–4895.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinan
et al<span id="bib.bib32.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Emily Dinan, Varvara
Logacheva, Valentin Malykh, Alexander
Miller, Kurt Shuster, Jack Urbanek,
Douwe Kiela, Arthur Szlam,
Iulian Serban, Ryan Lowe,
et al<span id="bib.bib32.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">The Second Conversational Intelligence Challenge
(ConvAI2).

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.5.1" class="ltx_emph ltx_font_italic">The NeurIPS’18 Competition</em>.
Springer, 187–208.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinan et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Emily Dinan, Stephen
Roller, Kurt Shuster, Angela Fan,
Michael Auli, and Jason Weston.
2019.

</span>
<span class="ltx_bibblock">Wizard of Wikipedia: Knowledge-Powered
Conversational agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">ICLR</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinu
et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Georgiana Dinu, Prashant
Mathur, Marcello Federico, and Yaser
Al-Onaizan. 2019.

</span>
<span class="ltx_bibblock">Training Neural Machine Translation To Apply
Terminology Constraints.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">ACL 2019 - 57th Annual Meeting of the
Association for Computational Linguistics, Proceedings of the Conference</em>
(6 2019), 3063–3068.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/v1/p19-1294" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/p19-1294</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong
et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yue Dong, Shuohang Wang,
Zhe Gan, Yu Cheng,
Jackie Chi Kit Cheung, and Jingjing
Liu. 2020.

</span>
<span class="ltx_bibblock">Multi-Fact Correction in Abstractive Text
Summarization. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
9320–9331.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas
Beyer, Alexander Kolesnikov, Dirk
Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly,
Jakob Uszkoreit, and Neil Houlsby.
2021.

</span>
<span class="ltx_bibblock">An Image is Worth 16x16 Words: Transformers for
Image Recognition at Scale. In <em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a href="https://openreview.net/forum?id=YicbFdNTTy" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=YicbFdNTTy</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Durmus
et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Esin Durmus, He He, and
Mona Diab. 2020.

</span>
<span class="ltx_bibblock">FEQA: A Question Answering Evaluation Framework for
Faithfulness Assessment in Abstractive Summarization. In
<em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>. 5055–5070.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dušek
et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ondřej Dušek,
David M Howcroft, and Verena Rieser.
2019.

</span>
<span class="ltx_bibblock">Semantic Noise Matters for Neural Natural Language
Generation. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th
International Conference on Natural Language Generation</em>.
421–426.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dušek and Jurčíček (2016)</span>
<span class="ltx_bibblock">
Ondřej Dušek and
Filip Jurčíček.
2016.

</span>
<span class="ltx_bibblock">Sequence-to-Sequence Generation for Spoken Dialogue
via Deep Syntax Trees and Strings. In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 54th Annual Meeting of the Association for Computational Linguistics
(Volume 2: Short Papers)</em>. Association for Computational
Linguistics, Berlin, Germany, 45–51.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P16-2008" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P16-2008</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dušek and
Kasner (2020)</span>
<span class="ltx_bibblock">
Ondřej Dušek and
Zdeněk Kasner. 2020.

</span>
<span class="ltx_bibblock">Evaluating Semantic Accuracy of Data-to-Text
Generation with Natural Language Inference. In
<em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 13th International Conference on
Natural Language Generation</em>. Association for
Computational Linguistics, Dublin, Ireland,
131–137.

</span>
<span class="ltx_bibblock">
<a href="https://aclanthology.org/2020.inlg-1.19" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.inlg-1.19</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dziri
et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Nouha Dziri, Ehsan
Kamalloo, Kory Mathewson, and Osmar
Zaiane. 2019.

</span>
<span class="ltx_bibblock">Evaluating Coherence in Dialogue Systems using
Entailment. In <em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference
of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>.
Association for Computational Linguistics,
Minneapolis, Minnesota, 3806–3812.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/N19-1381" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N19-1381</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dziri
et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Nouha Dziri, Andrea
Madotto, Osmar Zaiane, and Avishek Joey
Bose. 2021a.

</span>
<span class="ltx_bibblock">Neural Path Hunter: Reducing Hallucination in
Dialogue Systems via Path Grounding.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">EMNLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dziri
et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Nouha Dziri, Hannah
Rashkin, Tal Linzen, and David
Reitter. 2021b.

</span>
<span class="ltx_bibblock">Evaluating Groundedness in Dialogue Systems: The
BEGIN Benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Findings of ACL</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eric and Manning (2017)</span>
<span class="ltx_bibblock">
Mihail Eric and
Christopher Manning. 2017.

</span>
<span class="ltx_bibblock">A Copy-Augmented Sequence-to-Sequence Architecture
Gives Good Performance on Task-Oriented Dialogue. In
<em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Conference of the
European Chapter of the Association for Computational Linguistics: Volume
2, Short Papers</em>. Association for Computational
Linguistics, Valencia, Spain, 468–473.

</span>
<span class="ltx_bibblock">
<a href="https://aclanthology.org/E17-2075" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/E17-2075</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Etzioni
et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Oren Etzioni, Michele
Banko, Stephen Soderland, and Daniel S.
Weld. 2008.

</span>
<span class="ltx_bibblock">Open Information Extraction from the Web.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 51,
12 (Dec. 2008),
68–74.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.1145/1409360.1409378" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1409360.1409378</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Falke et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tobias Falke, Leonardo FR
Ribeiro, Prasetya Ajie Utama, Ido Dagan,
and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock">Ranking Generated Summaries by Correctness: An
Interesting but Challenging Application for Natural Language Inference. In
<em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. 2214–2220.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan
et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Angela Fan, Claire
Gardent, Chloé Braud, and Antoine
Bordes. 2019a.

</span>
<span class="ltx_bibblock">Using Local Knowledge Graph Construction to Scale
Seq2Seq Models to Multi-Document Inputs. In
<em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)</em>.
4186–4196.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Angela Fan, Yacine
Jernite, Ethan Perez, David Grangier,
Jason Weston, and Michael Auli.
2019b.

</span>
<span class="ltx_bibblock">ELI5: Long Form Question Answering. In
<em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. 3558–3567.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawzi
et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Alhussein Fawzi, Horst
Samulowitz, Deepak Turaga, and Pascal
Frossard. 2016.

</span>
<span class="ltx_bibblock">Image Inpainting through Neural Networks
Hallucinations. In <em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">2016 IEEE 12th Image, Video,
and Multidimensional Signal Processing Workshop (IVMSP)</em>. Ieee,
1–5.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng
et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Feng, Wanying Xie,
Shuhao Gu, Chenze Shao,
Wen Zhang, Zhengxin Yang, and
Dong Yu. 2020.

</span>
<span class="ltx_bibblock">Modeling Fluency and Faithfulness for Diverse
Neural Machine Translation. In <em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, Vol. 34.
59–66.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Filippova (2020)</span>
<span class="ltx_bibblock">
Katja Filippova.
2020.

</span>
<span class="ltx_bibblock">Controlled Hallucinations: Learning to Generate
Faithfully from Noisy Data. In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2020 Conference on Empirical Methods in Natural Language Processing:
Findings</em>. 864–870.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fish
et al<span id="bib.bib52.3.3.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
William Fish et al<span id="bib.bib52.4.1" class="ltx_text">.</span>
2009.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.5.1" class="ltx_emph ltx_font_italic">Perception, hallucination, and illusion</em>.

</span>
<span class="ltx_bibblock">OUP USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gabriel et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Saadia Gabriel, Asli
Celikyilmaz, Rahul Jha, Yejin Choi,
and Jianfeng Gao. 2021.

</span>
<span class="ltx_bibblock">GO FIGURE: A Meta Evaluation of Factuality in
Summarization. In <em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for
Computational Linguistics: ACL-IJCNLP 2021</em>. Association
for Computational Linguistics, Online,
478–487.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.findings-acl.42" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.findings-acl.42</a>

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao
et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jianfeng Gao, Michel
Galley, and Lihong Li. 2018.

</span>
<span class="ltx_bibblock">Neural Approaches to Conversational AI. In
<em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics: Tutorial Abstracts</em>.
Association for Computational Linguistics,
Melbourne, Australia, 2–7.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P18-5002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P18-5002</a>

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gardent et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Claire Gardent, Anastasia
Shimorina, Shashi Narayan, and Laura
Perez-Beltrachini. 2017.

</span>
<span class="ltx_bibblock">Creating Training Corpora for NLG Micro-Planning.
In <em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">55th annual meeting of the Association for
Computational Linguistics (ACL)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garg
et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sarthak Garg, Stephan
Peitz, Udhyakumar Nallasamy, and
Matthias Paulik. 2019.

</span>
<span class="ltx_bibblock">Jointly Learning to Align and Translate with
Transformer Models. In <em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. 4453–4462.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gatt and Krahmer (2018)</span>
<span class="ltx_bibblock">
Albert Gatt and Emiel
Krahmer. 2018.

</span>
<span class="ltx_bibblock">Survey of the State of the Art in Natural Language
Generation: Core tasks, applications and evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Journal of Artificial Intelligence Research</em>
61 (2018), 65–170.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosal et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Deepanway Ghosal, Pengfei
Hong, Siqi Shen, Navonil Majumder,
Rada Mihalcea, and Soujanya Poria.
2021.

</span>
<span class="ltx_bibblock">CIDER: Commonsense Inference for Dialogue
Explanation and Reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">ACL</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginsca
et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Alexandru L Ginsca, Adrian
Popescu, and Mihai Lupu.
2015.

</span>
<span class="ltx_bibblock">Credibility in Information Retrieval.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Foundations and Trends in Information
Retrieval</em> 9, 5 (2015),
355–475.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gliwa
et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Bogdan Gliwa, Iwona
Mochol, Maciej Biesek, and Aleksander
Wawer. 2019.

</span>
<span class="ltx_bibblock">SAMSum Corpus: A Human-annotated Dialogue Dataset
for Abstractive Summarization. In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2nd Workshop on New Frontiers in Summarization</em>.
Association for Computational Linguistics,
Hong Kong, China, 70–79.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D19-5409" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-5409</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Göbel and
Rushworth (2004)</span>
<span class="ltx_bibblock">
Silke M Göbel and
Matthew FS Rushworth. 2004.

</span>
<span class="ltx_bibblock">Cognitive Neuroscience: Acting on Numbers.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Current Biology</em> 14,
13 (2004), R517–R519.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodrich
et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ben Goodrich, Vinay Rao,
Peter J Liu, and Mohammad Saleh.
2019.

</span>
<span class="ltx_bibblock">Assessing the Factual Accuracy of Generated Text.
In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery &amp; Data Mining</em>.
166–175.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal
et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Kartik Goyal, Chris Dyer,
and Taylor Berg-Kirkpatrick.
2017.

</span>
<span class="ltx_bibblock">Differentiable Scheduled Sampling for Credit
Assignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">ACL 2017 - 55th Annual Meeting of the
Association for Computational Linguistics, Proceedings of the Conference
(Long Papers)</em> 2 (4
2017), 366–371.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/v1/P17-2058" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P17-2058</a>

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal and Durrett (2020)</span>
<span class="ltx_bibblock">
Tanya Goyal and Greg
Durrett. 2020.

</span>
<span class="ltx_bibblock">Evaluating Factuality in Generation with
Dependency-level Entailment. In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2020 Conference on Empirical Methods in Natural Language Processing:
Findings</em>. 3592–3603.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guan and Huang (2020)</span>
<span class="ltx_bibblock">
Jian Guan and Minlie
Huang. 2020.

</span>
<span class="ltx_bibblock">UNION: An Unreferenced Metric for Evaluating
Open-ended Story Generation. In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2020 Conference on Empirical Methods in Natural Language Processing
(EMNLP)</em>. 9157–9166.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunel
et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Beliz Gunel, Chenguang
Zhu, Michael Zeng, and Xuedong Huang.
2019.

</span>
<span class="ltx_bibblock">Mind the facts: Knowledge-Boosted Coherent
Abstractive Text Summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">NeurIPS, Knowledge Representation &amp;
Reasoning Meets Machine Learning (KR2ML workshop)</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Prakhar Gupta, Chien-Sheng
Wu, Wenhao Liu, and Caiming Xiong.
2021.

</span>
<span class="ltx_bibblock">DialFact: A Benchmark for Fact-Checking in
Dialogue.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.08222</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Suchin Gururangan, Swabha
Swayamdipta, Omer Levy, Roy Schwartz,
Samuel Bowman, and Noah A Smith.
2018.

</span>
<span class="ltx_bibblock">Annotation Artifacts in Natural Language Inference
Data. In <em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the
North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, Volume 2 (Short Papers)</em>.
107–112.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hancock
et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Braden Hancock, Antoine
Bordes, Pierre-Emmanuel Mazare, and
Jason Weston. 2019.

</span>
<span class="ltx_bibblock">Learning from Dialogue after Deployment: Feed
Yourself, Chatbot!. In <em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th
Annual Meeting of the Association for Computational Linguistics</em>.
Association for Computational Linguistics,
Florence, Italy, 3667–3684.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P19-1358" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1358</a>

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianxing He, Jingzhao
Zhang, Zhiming Zhou, and James Glass.
2021.

</span>
<span class="ltx_bibblock">Exposure Bias versus Self-Recovery: Are Distortions
Really Incremental for Autoregressive Text Generation?. In
<em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing</em>. 5087–5102.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hokamp and Liu (2017)</span>
<span class="ltx_bibblock">
Chris Hokamp and Qun
Liu. 2017.

</span>
<span class="ltx_bibblock">Lexically Constrained Decoding for Sequence
Generation Using Grid Beam Search.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">ACL 2017 - 55th Annual Meeting of the
Association for Computational Linguistics, Proceedings of the Conference
(Long Papers)</em> 1 (4
2017), 1535–1546.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/v1/P17-1141" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P17-1141</a>

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holtzman
et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ari Holtzman, Jan Buys,
Li Du, Maxwell Forbes, and
Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">The Curious Case of Neural Text Degeneration. In
<em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich
et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Or Honovich, Roee
Aharoni, Jonathan Herzig, Hagai
Taitelbaum, Doron Kukliansy, Vered
Cohen, Thomas Scialom, Idan Szpektor,
Avinatan Hassidim, and Yossi Matias.
2022.

</span>
<span class="ltx_bibblock">TRUE: Re-evaluating Factual Consistency
Evaluation. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Second DialDoc
Workshop on Document-grounded Dialogue and Conversational Question
Answering</em>. 161–175.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et al<span id="bib.bib74.3.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Or Honovich, Leshem
Choshen, Roee Aharoni, Ella Neeman,
Idan Szpektor, and Omri Abend.
2021.

</span>
<span class="ltx_bibblock">Q<math id="bib.bib74.1.m1.1" class="ltx_Math" alttext="{}^{2}" display="inline"><semantics id="bib.bib74.1.m1.1a"><msup id="bib.bib74.1.m1.1.1" xref="bib.bib74.1.m1.1.1.cmml"><mi id="bib.bib74.1.m1.1.1a" xref="bib.bib74.1.m1.1.1.cmml"></mi><mn id="bib.bib74.1.m1.1.1.1" xref="bib.bib74.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="bib.bib74.1.m1.1b"><apply id="bib.bib74.1.m1.1.1.cmml" xref="bib.bib74.1.m1.1.1"><cn type="integer" id="bib.bib74.1.m1.1.1.1.cmml" xref="bib.bib74.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib74.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="bib.bib74.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>: Evaluating Factual Consistency in
Knowledge-Grounded Dialogues via Question Generation and Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.4.1" class="ltx_emph ltx_font_italic">EMNLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Luyang Huang, Lingfei Wu,
and Lu Wang. 2020a.

</span>
<span class="ltx_bibblock">Knowledge Graph-Augmented Abstractive Summarization
with Semantic-Driven Cloze Reward.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Minlie Huang, Xiaoyan
Zhu, and Jianfeng Gao.
2020b.

</span>
<span class="ltx_bibblock">Challenges in Building Intelligent Open-domain
Dialog Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Information Systems
(TOIS)</em> 38, 3 (2020),
1–32.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yichong Huang, Xiachong
Feng, Xiaocheng Feng, and Bing Qin.
2021.

</span>
<span class="ltx_bibblock">The Factual Inconsistency Problem in Abstractive
Text Summarization: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.14839</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hussein
et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ahmed Hussein,
Mohamed Medhat Gaber, Eyad Elyan, and
Chrisina Jayne. 2017.

</span>
<span class="ltx_bibblock">Imitation Learning: A Survey of Learning Methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em> 50,
2, Article 21 (apr
2017), 35 pages.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.1145/3054912" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3054912</a>

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ziwei Ji, Yan Xu,
I-Tsun Cheng, Samuel Cahyawijaya,
Rita Frieske, Etsuko Ishii,
Min Zeng, Andrea Madotto, and
Pascale Fung. 2022.

</span>
<span class="ltx_bibblock">VScript: Controllable Script Generation with Visual
Presentation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2203.00314

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Junczys-Dowmunt (2018)</span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt.
2018.

</span>
<span class="ltx_bibblock">Dual Conditional Cross-Entropy Filtering of Noisy
Parallel Corpora. In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third
Conference on Machine Translation: Shared Task Papers</em>.
Association for Computational Linguistics,
Belgium, Brussels, 888–895.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/W18-6478" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W18-6478</a>

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jurafsky and
Marin (2019)</span>
<span class="ltx_bibblock">
Daniel Jurafsky and
James H. Marin. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Speech and Language Processing</em>.

</span>
<span class="ltx_bibblock">Draft of October 16th, 2019,
Website:
<a href="https://web.stanford.edu/~jurafsky/slp3/26.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://web.stanford.edu/~jurafsky/slp3/26.pdf</a>, Chapter 26.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and
Hashimoto (2020a)</span>
<span class="ltx_bibblock">
Daniel Kang and
Tatsunori Hashimoto. 2020a.

</span>
<span class="ltx_bibblock">Improved Natural Language Generation via Loss
Truncation.

</span>
<span class="ltx_bibblock">(4 2020), 718–731.

</span>
<span class="ltx_bibblock">
<a href="https://arxiv.org/abs/2004.14589v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2004.14589v2</a>

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and
Hashimoto (2020b)</span>
<span class="ltx_bibblock">
Daniel Kang and
Tatsunori B Hashimoto. 2020b.

</span>
<span class="ltx_bibblock">Improved Natural Language Generation via Loss
Truncation. In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics</em>.
718–731.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kayhan
et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Osman Semih Kayhan, Bart
Vredebregt, and Jan C van Gemert.
2021.

</span>
<span class="ltx_bibblock">Hallucination In Object Detection—A Study In
Visual Part VERIFICATION. In <em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">2021 IEEE
International Conference on Image Processing (ICIP)</em>. IEEE,
2234–2238.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Daniel Khashabi, Amos Ng,
Tushar Khot, Ashish Sabharwal,
Hannaneh Hajishirzi, and Chris
Callison-Burch. 2021.

</span>
<span class="ltx_bibblock">GooAQ: Open Question Answering with Diverse Answer
Types. In <em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for
Computational Linguistics: EMNLP 2021</em>. Association for
Computational Linguistics, Punta Cana, Dominican
Republic, 421–433.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.findings-emnlp.38" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.findings-emnlp.38</a>

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn and Knowles (2017a)</span>
<span class="ltx_bibblock">
Philipp Koehn and
Rebecca Knowles. 2017a.

</span>
<span class="ltx_bibblock">Six Challenges for Neural Machine Translation. In
<em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">First Workshop on Neural Machine Translation</em>.
Association for Computational Linguistics, 28–39.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn and Knowles (2017b)</span>
<span class="ltx_bibblock">
Philipp Koehn and
Rebecca Knowles. 2017b.

</span>
<span class="ltx_bibblock">Six Challenges for Neural Machine Translation.

</span>
<span class="ltx_bibblock">(2017), 28–39.

</span>
<span class="ltx_bibblock">
<a href="http://www.statmt.org/wmt17/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.statmt.org/wmt17/</a>

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kong
et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Xiang Kong, Zhaopeng Tu,
Shuming Shi, Eduard Hovy, and
Tong Zhang. 2019.

</span>
<span class="ltx_bibblock">Neural Machine Translation with Adequacy-Oriented
Learning. In <em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, Vol. 33.
6618–6625.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna
et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kalpesh Krishna, Aurko
Roy, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock">Hurdles to Progress in Long-form Question
Answering. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference
of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies</em>. 4940–4957.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kryscinski et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Wojciech Kryscinski, Bryan
McCann, Caiming Xiong, and Richard
Socher. 2020.

</span>
<span class="ltx_bibblock">Evaluating the Factual Consistency of Abstractive
Text Summarization. In <em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
9332–9346.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kukich (1983)</span>
<span class="ltx_bibblock">
Karen Kukich.
1983.

</span>
<span class="ltx_bibblock">Design of a Knowledge-based Report Generator. In
<em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">21st Annual Meeting of the Association for
Computational Linguistics</em>. 145–150.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulikov
et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ilia Kulikov, Alexander H.
Miller, Kyunghyun Cho, and Jason
Weston. 2019.

</span>
<span class="ltx_bibblock">Importance of Search and Evaluation Strategies in
Neural Dialogue Modeling. In <em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
12th International Conference on Natural Language Generation, INLG 2019,
Tokyo, Japan, October 29 - November 1, 2019</em>,
Kees van Deemter,
Chenghua Lin, and Hiroya Takamura
(Eds.). Association for Computational Linguistics,
76–87.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/W19-8609" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W19-8609</a>

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski
et al<span id="bib.bib93.3.3.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski,
Jennimaria Palomaki, Olivia Redfield,
Michael Collins, Ankur Parikh,
Chris Alberti, Danielle Epstein,
Illia Polosukhin, Jacob Devlin,
Kenton Lee, et al<span id="bib.bib93.4.1" class="ltx_text">.</span>
2019.

</span>
<span class="ltx_bibblock">Natural Questions: A Benchmark for Question
Answering Research.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.5.1" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em> 7 (2019),
452–466.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laban
et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Philippe Laban, Tobias
Schnabel, Paul N Bennett, and Marti A
Hearst. 2022.

</span>
<span class="ltx_bibblock">SummaC: Re-Visiting NLI-based Models for
Inconsistency Detection in Summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em> 10 (2022),
163–177.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lebret
et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Rémi Lebret, David
Grangier, and Michael Auli.
2016.

</span>
<span class="ltx_bibblock">Neural Text Generation from Structured Data with
Application to the Biography Domain.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Processing</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Katherine Lee, Orhan
Firat, Ashish Agarwal, Clara Fannjiang,
and David Sussillo. 2019.

</span>
<span class="ltx_bibblock">Hallucinations in Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">ICLR</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Katherine Lee, Daphne
Ippolito, Andrew Nystrom, Chiyuan Zhang,
Douglas Eck, Chris Callison-Burch, and
Nicholas Carlini. 2021.

</span>
<span class="ltx_bibblock">Deduplicating Training Data Makes Language Models
Better.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06499</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nayeon Lee, Belinda Z Li,
Sinong Wang, Wen-Tau Yih,
Hao Ma, and Madian Khabsa.
2020.

</span>
<span class="ltx_bibblock">Language Models as Fact Checkers?

</span>
<span class="ltx_bibblock"><em id="bib.bib98.3.1" class="ltx_emph ltx_font_italic">ACL 2020</em> (2020),
36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nayeon Lee, Wei Ping,
Peng Xu, Mostofa Patwary,
Mohammad Shoeybi, and Bryan Catanzaro.
2022.

</span>
<span class="ltx_bibblock">Factuality Enhanced Language Models for Open-Ended
Text Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.04624</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> ([n. d.])</span>
<span class="ltx_bibblock">
Nayeon Lee, Chien-Sheng
Wu, and Pascale Fung.
[n. d.].

</span>
<span class="ltx_bibblock">Improving Large-Scale Fact-Checking using
Decomposable Attention Models and Lexical Tagging.

</span>
<span class="ltx_bibblock">([n. d.]).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu,
Naman Goyal, Marjan Ghazvininejad,
Abdelrahman Mohamed, Omer Levy,
Veselin Stoyanov, and Luke
Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock">BART: Denoising Sequence-to-Sequence Pre-training
for Natural Language Generation, Translation, and Comprehension. In
<em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>. 7871–7880.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Bohan Li, Yutai Hou,
and Wanxiang Che. 2021b.

</span>
<span class="ltx_bibblock">Data Augmentation Approaches in Natural Language
Processing: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.01852</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Chenliang Li, Bin Bi,
Ming Yan, Wei Wang, and
Songfang Huang. 2021a.

</span>
<span class="ltx_bibblock">Addressing Semantic Drift in Generative Question
Answering with Auxiliary Extraction. In
<em id="bib.bib103.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing (Volume 2: Short Papers)</em>.
942–947.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Haoran Li, Junnan Zhu,
Jiajun Zhang, and Chengqing Zong.
2018.

</span>
<span class="ltx_bibblock">Ensure the Correctness of the Summary: Incorporate
Entailment Knowledge into Abstractive Sentence Summarization. In
<em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th International Conference on
Computational Linguistics</em>. Association for
Computational Linguistics, Santa Fe, New Mexico, USA,
1430–1441.

</span>
<span class="ltx_bibblock">
<a href="https://aclanthology.org/C18-1121" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/C18-1121</a>

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jiwei Li, Michel Galley,
Chris Brockett, Georgios Spithourakis,
Jianfeng Gao, and Bill Dolan.
2016.

</span>
<span class="ltx_bibblock">A Persona-Based Neural Conversation Model. In
<em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers)</em>.
Association for Computational Linguistics,
Berlin, Germany, 994–1003.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P16-1094" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P16-1094</a>

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Junnan Li, Dongxu Li,
Caiming Xiong, and Steven Hoi.
2022.

</span>
<span class="ltx_bibblock">BLIP: Bootstrapping Language-Image Pre-training for
Unified Vision-Language Understanding and Generation. In
<em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Margaret Li, Stephen
Roller, Ilia Kulikov, Sean Welleck,
Y-Lan Boureau, Kyunghyun Cho, and
Jason Weston. 2020b.

</span>
<span class="ltx_bibblock">Don’t Say That! Making Inconsistent Dialogue
Unlikely with Unlikelihood Training. In
<em id="bib.bib107.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>. Association
for Computational Linguistics, Online,
4715–4728.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.acl-main.428" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.428</a>

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tian Li, Ahmad Beirami,
Maziar Sanjabi, and Virginia Smith.
2020a.

</span>
<span class="ltx_bibblock">Tilted Empirical Risk Minimization. In
<em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Yangming Li, Kaisheng
Yao, Libo Qin, Wanxiang Che,
Xiaolong Li, and Ting Liu.
2020c.

</span>
<span class="ltx_bibblock">Slot-consistent NLG for Task-oriented Dialogue
Systems with Iterative Rectification Network. In
<em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>. Association
for Computational Linguistics, Online,
97–106.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.acl-main.10" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.10</a>

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin.
2004.

</span>
<span class="ltx_bibblock">Rouge: A Package for Automatic Evaluation of
Summaries. In <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Text summarization branches out</em>.
74–81.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin
et al<span id="bib.bib111.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob
Hilton, and Owain Evans.
2021.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring How Models Mimic Human
Falsehoods.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.07958</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael
Maire, Serge J. Belongie, James Hays,
Pietro Perona, Deva Ramanan,
Piotr Dollár, and C. Lawrence
Zitnick. 2014.

</span>
<span class="ltx_bibblock">Microsoft COCO: Common Objects in Context.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1405.0312
(2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
Ce Liu, Heung-Yeung Shum,
and William T Freeman. 2007.

</span>
<span class="ltx_bibblock">Face Hallucination: Theory and Practice.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>
75, 1 (2007),
115–134.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Tianyu Liu, Yizhe Zhang,
Chris Brockett, Yi Mao,
Zhifang Sui, Weizhu Chen, and
Bill Dolan. 2021a.

</span>
<span class="ltx_bibblock">A Token-level Reference-free Hallucination
Detection Benchmark for Free-form Text Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08704</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Tianyu Liu, Xin Zheng,
Baobao Chang, and Zhifang Sui.
2021b.

</span>
<span class="ltx_bibblock">Towards Faithfulness in Open Domain Table-to-text
Generation from an Entity-centric View. In
<em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, Vol. 35. 13415–13423.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Shayne Longpre, Kartik
Perisetla, Anthony Chen, Nikhil Ramesh,
Chris DuBois, and Sameer Singh.
2021.

</span>
<span class="ltx_bibblock">Entity-Based Knowledge Conflicts in Question
Answering. In <em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Processing</em>.
7052–7063.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu
et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jiasen Lu, Jianwei Yang,
Dhruv Batra, and Devi Parikh.
2018.

</span>
<span class="ltx_bibblock">Neural Baby Talk. In
<em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma
et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yukun Ma, Khanh Linh
Nguyen, Frank Z Xing, and Erik
Cambria. 2020.

</span>
<span class="ltx_bibblock">A Survey on Empathetic Dialogue Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">Information Fusion</em> 64
(2020), 50–70.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macpherson and
Platchias (2013)</span>
<span class="ltx_bibblock">
Fiona Macpherson and
Dimitris Platchias. 2013.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">Hallucination: Philosophy and psychology</em>.

</span>
<span class="ltx_bibblock">MIT Press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madotto et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Andrea Madotto, Samuel
Cahyawijaya, Genta Indra Winata, Yan Xu,
Zihan Liu, Zhaojiang Lin, and
Pascale Fung. 2020a.

</span>
<span class="ltx_bibblock">Learning Knowledge Bases with Parameters for
Task-Oriented Dialogue Systems. In <em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">Findings of the
Association for Computational Linguistics: EMNLP 2020</em>.
Association for Computational Linguistics,
Online, 2372–2394.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.findings-emnlp.215" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.findings-emnlp.215</a>

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madotto
et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Andrea Madotto, Zhaojiang
Lin, Chien-Sheng Wu, and Pascale
Fung. 2019.

</span>
<span class="ltx_bibblock">Personalizing dialogue agents via meta-learning.
In <em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. 5454–5459.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madotto
et al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Andrea Madotto, Zihan
Liu, Zhaojiang Lin, and Pascale Fung.
2020b.

</span>
<span class="ltx_bibblock">Language Models as Few-Shot Learner for Task-Oriented
Dialogue Systems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2008.06239 [cs.CL]

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madotto
et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrea Madotto,
Chien-Sheng Wu, and Pascale Fung.
2018.

</span>
<span class="ltx_bibblock">Mem2Seq: Effectively Incorporating Knowledge
Bases into End-to-End Task-Oriented Dialog Systems. In
<em id="bib.bib123.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers)</em>.
Association for Computational Linguistics,
Melbourne, Australia, 1468–1478.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P18-1136" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P18-1136</a>

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Magdy and Wanas (2010)</span>
<span class="ltx_bibblock">
Amr Magdy and Nayer
Wanas. 2010.

</span>
<span class="ltx_bibblock">Web-based Statistical Fact Checking of Textual
Documents. In <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd international
workshop on Search and mining user-generated contents</em>.
103–110.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martindale et al<span id="bib.bib125.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Marianna J. Martindale,
Marine Carpuat, Kevin Duh, and
Paul McNamee. 2019.

</span>
<span class="ltx_bibblock">Identifying Fluently Inadequate Output in Neural
and Statistical Machine Translation. In
<em id="bib.bib125.3.1" class="ltx_emph ltx_font_italic">MTSummit</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maynez
et al<span id="bib.bib126.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Joshua Maynez, Shashi
Narayan, Bernd Bohnet, and Ryan
McDonald. 2020.

</span>
<span class="ltx_bibblock">On Faithfulness and Factuality in Abstractive
Summarization. In <em id="bib.bib126.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics</em>.
1906–1919.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mazaré et al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Pierre-Emmanuel Mazaré,
Samuel Humeau, Martin Raison, and
Antoine Bordes. 2018.

</span>
<span class="ltx_bibblock">Training Millions of Personalized Dialogue Agents.
In <em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing</em>. Association for
Computational Linguistics, Brussels, Belgium,
2775–2779.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D18-1298" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D18-1298</a>

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKeown (1992)</span>
<span class="ltx_bibblock">
Kathleen McKeown.
1992.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">Text Generation</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mesgar
et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mohsen Mesgar, Edwin
Simpson, and Iryna Gurevych.
2021.

</span>
<span class="ltx_bibblock">Improving Factual Consistency Between a Response
and Persona Facts. In <em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th
Conference of the European Chapter of the Association for Computational
Linguistics: Main Volume</em>. Association for Computational
Linguistics, Online, 549–562.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.eacl-main.44" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.eacl-main.44</a>

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Metzler
et al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Donald Metzler, Yi Tay,
Dara Bahri, and Marc Najork.
2021.

</span>
<span class="ltx_bibblock">Rethinking Search: Making Experts out of
Dilettantes.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.02274</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mielke
et al<span id="bib.bib131.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sabrina J Mielke, Arthur
Szlam, Y-Lan Boureau, and Emily
Dinan. 2020.

</span>
<span class="ltx_bibblock">Linguistic calibration through metacognition:
aligning dialogue agent responses with expected correctness.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.14983</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Anshuman Mishra, Dhruvesh
Patel, Aparna Vijayakumar, Xiang Lorraine
Li, Pavan Kapanipathi, and Kartik
Talamadupula. 2021.

</span>
<span class="ltx_bibblock">Looking Beyond Sentence-Level Natural Language
Inference for Question Answering and Text Summarization. In
<em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies</em>. 1322–1336.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller
et al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mathias Müller,
Annette Rios, and Rico Sennrich.
2020.

</span>
<span class="ltx_bibblock">Domain Robustness in Neural Machine Translation.
In <em id="bib.bib133.3.1" class="ltx_emph ltx_font_italic">14th Conference of the Association for Machine
Translation in the Americas</em>. Association for Machine Translation in the
Americas, AMTA, 151–164.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano et al<span id="bib.bib134.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob
Hilton, Suchir Balaji, Jeff Wu,
Long Ouyang, Christina Kim,
Christopher Hesse, Shantanu Jain,
Vineet Kosaraju, William Saunders,
et al<span id="bib.bib134.4.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">WebGPT: Browser-assisted question-answering with
human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.09332</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nan et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Feng Nan, Ramesh
Nallapati, Zhiguo Wang, Cicero dos
Santos, Henghui Zhu, Dejiao Zhang,
Kathleen McKeown, and Bing Xiang.
2021.

</span>
<span class="ltx_bibblock">Entity-level Factual Consistency of Abstractive
Text Summarization. In <em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th
Conference of the European Chapter of the Association for Computational
Linguistics: Main Volume</em>. 2727–2733.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Tri Nguyen, Mir
Rosenberg, Xia Song, Jianfeng Gao,
Saurabh Tiwary, Rangan Majumder, and
Li Deng. 2016.

</span>
<span class="ltx_bibblock">MS MARCO: A human generated machine reading
comprehension dataset. In <em id="bib.bib136.3.1" class="ltx_emph ltx_font_italic">CoCo@ NIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nie
et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Feng Nie, Jinpeng Wang,
Jin-Ge Yao, Rong Pan, and
Chin-Yew Lin. 2018.

</span>
<span class="ltx_bibblock">Operation-guided Neural Networks for High Fidelity
Data-To-Text Generation. In <em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nie
et al<span id="bib.bib138.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Feng Nie, Jin-Ge Yao,
Jinpeng Wang, Rong Pan, and
Chin-Yew Lin. 2019.

</span>
<span class="ltx_bibblock">A Simple Recipe towards Reducing Hallucination in
Neural Surface Realisation. In <em id="bib.bib138.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
57th Annual Meeting of the Association for Computational Linguistics</em>.
Association for Computational Linguistics,
Florence, Italy, 2673–2679.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P19-1256" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1256</a>

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Och (2003)</span>
<span class="ltx_bibblock">
Franz Josef Och.
2003.

</span>
<span class="ltx_bibblock">Minimum Error Rate Training in Statistical Machine
Translation. In <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 41st annual
meeting of the Association for Computational Linguistics</em>.
160–167.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pagnoni
et al<span id="bib.bib140.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Artidoro Pagnoni, Vidhisha
Balachandran, and Yulia Tsvetkov.
2021.

</span>
<span class="ltx_bibblock">Understanding Factuality in Abstractive
Summarization with FRANK: A Benchmark for Factuality Metrics. In
<em id="bib.bib140.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies</em>. 4812–4829.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parikh et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ankur Parikh, Xuezhi
Wang, Sebastian Gehrmann, Manaal
Faruqui, Bhuwan Dhingra, Diyi Yang,
and Dipanjan Das. 2020.

</span>
<span class="ltx_bibblock">ToTTo: A Controlled Table-To-Text Generation
Dataset. In <em id="bib.bib141.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP)</em>.
1173–1186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parthasarathi et al<span id="bib.bib142.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Prasanna Parthasarathi,
Koustuv Sinha, Joelle Pineau, and
Adina Williams. 2021.

</span>
<span class="ltx_bibblock">Sometimes We Want Ungrammatical Translations. In
<em id="bib.bib142.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational
Linguistics: EMNLP 2021</em>. Association for Computational
Linguistics, Punta Cana, Dominican Republic,
3205–3227.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.findings-emnlp.275" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.findings-emnlp.275</a>

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al<span id="bib.bib143.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim
Rocktäschel, Sebastian Riedel,
Patrick Lewis, Anton Bakhtin,
Yuxiang Wu, and Alexander Miller.
2019.

</span>
<span class="ltx_bibblock">Language Models as Knowledge Bases?. In
<em id="bib.bib143.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)</em>.
Association for Computational Linguistics,
Hong Kong, China, 2463–2473.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D19-1250" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1250</a>

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poliak et al<span id="bib.bib144.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Adam Poliak, Jason
Naradowsky, Aparajita Haldar, Rachel
Rudinger, and Benjamin Van Durme.
2018.

</span>
<span class="ltx_bibblock">Hypothesis Only Baselines in Natural Language
Inference. In <em id="bib.bib144.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Joint
Conference on Lexical and Computational Semantics</em>.
180–191.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popat et al<span id="bib.bib145.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Kashyap Popat, Subhabrata
Mukherjee, Jannik Strötgen, and
Gerhard Weikum. 2016.

</span>
<span class="ltx_bibblock">Credibility Assessment of Textual Claims on the
Web. In <em id="bib.bib145.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM International
on Conference on Information and Knowledge Management</em>.
2173–2178.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popat
et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Kashyap Popat, Subhabrata
Mukherjee, Andrew Yates, and Gerhard
Weikum. 2018.

</span>
<span class="ltx_bibblock">DeClarE: Debunking Fake News and False Claims using
Evidence-Aware Deep Learning. In <em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2018 Conference on Empirical Methods in Natural Language Processing</em>.
Association for Computational Linguistics,
Brussels, Belgium, 22–32.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D18-1003" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D18-1003</a>

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post and Vilar (2018)</span>
<span class="ltx_bibblock">
Matt Post and David
Vilar. 2018.

</span>
<span class="ltx_bibblock">Fast Lexically Constrained Decoding with Dynamic
Beam Allocation for Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">NAACL HLT 2018 - 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies - Proceedings of the Conference</em> 1
(4 2018), 1314–1324.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/v1/n18-1119" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/n18-1119</a>

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puduppully
et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ratish Puduppully, Li
Dong, and Mirella Lapata.
2019.

</span>
<span class="ltx_bibblock">Data-to-text generation with content selection and
planning. In <em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on
artificial intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puduppully and
Lapata (2021)</span>
<span class="ltx_bibblock">
Ratish Puduppully and
Mirella Lapata. 2021.

</span>
<span class="ltx_bibblock">Data-to-text generation with macro planning.

</span>
<span class="ltx_bibblock"><em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span id="bib.bib150.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever.
2019.

</span>
<span class="ltx_bibblock">Language Models are Unsupervised Multitask
Learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.3.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em> 1,
8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al<span id="bib.bib151.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam
Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and
Peter J. Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the Limits of Transfer Learning with a
Unified Text-to-Text Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib151.3.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>
21, 140 (2020),
1–67.

</span>
<span class="ltx_bibblock">
<a href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://jmlr.org/papers/v21/20-074.html</a>

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranzato
et al<span id="bib.bib152.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Marc’Aurelio Ranzato,
Sumit Chopra, Michael Auli, and
Wojciech Zaremba. 2016.

</span>
<span class="ltx_bibblock">Sequence Level Training with Recurrent Neural
Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib152.3.1" class="ltx_emph ltx_font_italic">ICLR</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rashkin
et al<span id="bib.bib153.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hannah Rashkin, David
Reitter, Gaurav Singh Tomar, and
Dipanjan Das. 2021.

</span>
<span class="ltx_bibblock">Increasing Faithfulness in Knowledge-Grounded
Dialogue with Controllable Features. In
<em id="bib.bib153.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing (Volume 1: Long Papers)</em>.
Association for Computational Linguistics,
Online, 704–718.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.acl-long.58" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.acl-long.58</a>

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raunak
et al<span id="bib.bib154.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Vikas Raunak, Arul
Menezes, and Marcin Junczys-Dowmunt.
2021.

</span>
<span class="ltx_bibblock">The Curious Case of Hallucinations in Neural
Machine Translation.

</span>
<span class="ltx_bibblock">(4 2021),
1172–1183.

</span>
<span class="ltx_bibblock">
<a href="https://arxiv.org/abs/2104.06683v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2104.06683v1</a>

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rebuffel et al<span id="bib.bib155.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Clément Rebuffel,
Marco Roberti, Laure Soulier,
Geoffrey Scoutheeten, Rossella
Cancelliere, and Patrick Gallinari.
2022.

</span>
<span class="ltx_bibblock">Controlling hallucinations at word level in
data-to-text generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib155.3.1" class="ltx_emph ltx_font_italic">Data Mining and Knowledge Discovery</em>
36, 1 (2022),
318–354.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rebuffel
et al<span id="bib.bib156.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Clément Rebuffel,
Thomas Scialom, Laure Soulier,
Benjamin Piwowarski, Sylvain Lamprier,
Jacopo Staiano, Geoffrey Scoutheeten,
and Patrick Gallinari. 2021.

</span>
<span class="ltx_bibblock">Data-QuestEval: A Reference-less Metric for
Data-to-Text Semantic Evaluation. In <em id="bib.bib156.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2021 Conference on Empirical Methods in Natural Language Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reiter (2018)</span>
<span class="ltx_bibblock">
Ehud Reiter.
2018.

</span>
<span class="ltx_bibblock">A Structured Review of the Validity of BLEU.

</span>
<span class="ltx_bibblock"><em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>
44, 3 (Sept.
2018), 393–401.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.1162/coli_a_00322" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1162/coli_a_00322</a>

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reiter and Dale (1997)</span>
<span class="ltx_bibblock">
Ehud Reiter and Robert
Dale. 1997.

</span>
<span class="ltx_bibblock">Building Applied Natural Language Generation
Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">Natural Language Engineering</em>
3, 1 (1997),
57–87.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts
et al<span id="bib.bib159.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Adam Roberts, Colin
Raffel, and Noam Shazeer.
2020.

</span>
<span class="ltx_bibblock">How Much Knowledge Can You Pack Into the Parameters
of a Language Model?. In <em id="bib.bib159.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
Association for Computational Linguistics,
Online, 5418–5426.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.emnlp-main.437" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.emnlp-main.437</a>

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rohrbach et al<span id="bib.bib160.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Anna Rohrbach, Lisa Anne
Hendricks, Kaylee Burns, Trevor Darrell,
and Kate Saenko. 2018.

</span>
<span class="ltx_bibblock">Object Hallucination in Image Captioning. In
<em id="bib.bib160.3.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roller et al<span id="bib.bib161.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Stephen Roller, Y-Lan
Boureau, Jason Weston, Antoine Bordes,
Emily Dinan, Angela Fan,
David Gunning, Da Ju,
Margaret Li, Spencer Poff,
et al<span id="bib.bib161.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Open-Domain Conversational Agents: Current
Progress, Open Problems, and Future Directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.5.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.12442</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roller et al<span id="bib.bib162.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Stephen Roller, Emily
Dinan, Naman Goyal, Da Ju,
Mary Williamson, Yinhan Liu,
Jing Xu, Myle Ott,
Eric Michael Smith, Y-Lan Boureau,
et al<span id="bib.bib162.4.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Recipes for Building an Open-Domain Chatbot. In
<em id="bib.bib162.5.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European
Chapter of the Association for Computational Linguistics: Main Volume</em>.
300–325.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sabet
et al<span id="bib.bib163.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Masoud Jalili Sabet,
Philipp Dufter, François Yvon,
and Hinrich Schütze.
2020.

</span>
<span class="ltx_bibblock">SimAlign: High Quality Word Alignments Without
Parallel Training Data Using Static and Contextualized Embeddings. In
<em id="bib.bib163.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational
Linguistics: EMNLP 2020</em>. 1627–1643.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Santhanam et al<span id="bib.bib164.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sashank Santhanam, Behnam
Hedayatnia, Spandana Gella, Aishwarya
Padmakumar, Seokhwan Kim, Yang Liu,
and Dilek Hakkani-Tur. 2021.

</span>
<span class="ltx_bibblock">Rome was built in 1776: A Case Study on Factual
Correctness in Knowledge-Grounded Response Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib164.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.05456</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scialom et al<span id="bib.bib165.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Thomas Scialom,
Paul-Alexis Dray, Patrick Gallinari,
Sylvain Lamprier, Benjamin Piwowarski,
Jacopo Staiano, and Alex Wang.
2021.

</span>
<span class="ltx_bibblock">Questeval: Summarization asks for fact-based
evaluation. In <em id="bib.bib165.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">See
et al<span id="bib.bib166.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Abigail See, Peter J.
Liu, and Christopher D. Manning.
2017.

</span>
<span class="ltx_bibblock">Get To The Point: Summarization with
Pointer-Generator Networks. In <em id="bib.bib166.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
55th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers)</em>. Association for Computational
Linguistics, Vancouver, Canada,
1073–1083.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P17-1099" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P17-1099</a>

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sellam
et al<span id="bib.bib167.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Thibault Sellam, Dipanjan
Das, and Ankur Parikh. 2020.

</span>
<span class="ltx_bibblock">BLEURT: Learning Robust Metrics for Text
Generation. In <em id="bib.bib167.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics</em>.
7881–7892.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen
et al<span id="bib.bib168.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Lei Shen, Haolan Zhan,
Xin Shen, Hongshen Chen,
Xiaofang Zhao, and Xiaodan Zhu.
2021.

</span>
<span class="ltx_bibblock">Identifying Untrustworthy Samples: Data Filtering
for Open-domain Dialogues with Bayesian Optimization. In
<em id="bib.bib168.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International
Conference on Information &amp; Knowledge Management</em>.
1598–1608.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et al<span id="bib.bib169.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer
Poff, Moya Chen, Douwe Kiela, and
Jason Weston. 2021.

</span>
<span class="ltx_bibblock">Retrieval Augmentation Reduces Hallucination in
Conversation.

</span>
<span class="ltx_bibblock"><em id="bib.bib169.3.1" class="ltx_emph ltx_font_italic">EMNLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song
et al<span id="bib.bib170.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Haoyu Song, Wei-Nan
Zhang, Jingwen Hu, and Ting Liu.
2020b.

</span>
<span class="ltx_bibblock">Generating Persona Consistent Dialogues by
Exploiting Natural Language Inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on
Artificial Intelligence</em> 34, 05
(Apr. 2020), 8878–8885.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.1609/aaai.v34i05.6417" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v34i05.6417</a>

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al<span id="bib.bib171.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Kaiqiang Song, Logan
Lebanoff, Qipeng Guo, Xipeng Qiu,
Xiangyang Xue, Chen Li,
Dong Yu, and Fei Liu.
2020a.

</span>
<span class="ltx_bibblock">Joint Parsing and Generation for Abstractive
Summarization. In <em id="bib.bib171.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI
Conference on Artificial Intelligence</em>, Vol. 34.
8894–8901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song
et al<span id="bib.bib172.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kai Song, Yue Zhang,
Heng Yu, Weihua Luo, Kun
Wang, and Min Zhang. 2019.

</span>
<span class="ltx_bibblock">Code-Switching for Enhancing NMT with Pre-Specified
Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib172.3.1" class="ltx_emph ltx_font_italic">NAACL HLT 2019 - 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies - Proceedings of the Conference</em> 1
(4 2019), 449–459.

</span>
<span class="ltx_bibblock">

<a href="https://arxiv.org/abs/1904.09107v4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1904.09107v4</a>

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su
et al<span id="bib.bib173.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dan Su, Xiaoguang Li,
Jindi Zhang, Lifeng Shang,
Xin Jiang, Qun Liu, and
Pascale Fung. 2022.

</span>
<span class="ltx_bibblock">Read before Generate! Faithful Long Form Question
Answering with Machine Reading.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2203.00343 [cs.CL]

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su
et al<span id="bib.bib174.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hui Su, Xiaoyu Shen,
Sanqiang Zhao, Zhou Xiao,
Pengwei Hu, Cheng Niu, and
Jie Zhou. 2020.

</span>
<span class="ltx_bibblock">Diversifying Dialogue Generation with
Non-Conversational Text. In <em id="bib.bib174.3.1" class="ltx_emph ltx_font_italic">58th Annual Meeting of
the Association for Computational Linguistics</em>. ACL,
7087–7097.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su
et al<span id="bib.bib175.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yixuan Su, David Vandyke,
Sihui Wang, Yimai Fang, and
Nigel Collier. 2021.

</span>
<span class="ltx_bibblock">Plan-then-Generate: Controlled Data-to-Text
Generation via Planning.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.3.1" class="ltx_emph ltx_font_italic">Findings of EMNLP</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suadaa et al<span id="bib.bib176.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Lya Hulliyyatus Suadaa,
Hidetaka Kamigaito, Kotaro Funakoshi,
Manabu Okumura, and Hiroya Takamura.
2021.

</span>
<span class="ltx_bibblock">Towards Table-to-text Generation with Numerical
Reasoning. In <em id="bib.bib176.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual
Meeting of the Association for Computational Linguistics and the 11th
International Joint Conference on Natural Language Processing (Volume 1: Long
Papers)</em>. 1451–1465.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun (2010)</span>
<span class="ltx_bibblock">
Yanli Sun.
2010.

</span>
<span class="ltx_bibblock">Mining the Correlation between Human and Automatic
Evaluation at Sentence Level.. In <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">LREC</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Susanto
et al<span id="bib.bib178.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Raymond Hendy Susanto,
Shamil Chollampatt, and Liling Tan.
2020.

</span>
<span class="ltx_bibblock">Lexically Constrained Neural Machine Translation
with Levenshtein Transformer.

</span>
<span class="ltx_bibblock">(7 2020),
3536–3543.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/V1/2020.ACL-MAIN.325" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2020.ACL-MAIN.325</a>

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever
et al<span id="bib.bib179.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol
Vinyals, and Quoc V Le.
2014.

</span>
<span class="ltx_bibblock">Sequence to sequence learning with neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib179.3.1" class="ltx_emph ltx_font_italic">Advances in neural information processing
systems</em> 27 (2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib180.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiangru Tang, Arjun Nair,
Borui Wang, Bingyao Wang,
Jai Desai, Aaron Wade,
Haoran Li, Asli Celikyilmaz,
Yashar Mehdad, and Dragomir Radev.
2021.

</span>
<span class="ltx_bibblock">CONFIT: Toward Faithful Dialogue Summarization with
Linguistically-Informed Contrastive Fine-tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.08713</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thawani et al<span id="bib.bib181.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Avijit Thawani, Jay
Pujara, Filip Ilievski, and Pedro
Szekely. 2021.

</span>
<span class="ltx_bibblock">Representing Numbers in NLP: a Survey and a
Vision. In <em id="bib.bib181.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of
the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies</em>. 644–656.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thomson and
Reiter (2020)</span>
<span class="ltx_bibblock">
Craig Thomson and Ehud
Reiter. 2020.

</span>
<span class="ltx_bibblock">A Gold Standard Methodology for Evaluating Accuracy
in Data-To-Text Systems. In <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
13th International Conference on Natural Language Generation</em>.
158–168.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thorne et al<span id="bib.bib183.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
James Thorne, Andreas
Vlachos, Christos Christodoulopoulos, and
Arpit Mittal. 2018.

</span>
<span class="ltx_bibblock">FEVER: a Large-scale Dataset for Fact Extraction
and VERification. In <em id="bib.bib183.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018
Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long
Papers)</em>. Association for Computational Linguistics,
New Orleans, Louisiana, 809–819.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/N18-1074" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N18-1074</a>

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thorne et al<span id="bib.bib184.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
James Thorne, Andreas
Vlachos, Christos Christodoulopoulos, and
Arpit Mittal. 2019.

</span>
<span class="ltx_bibblock">Evaluating adversarial attacks against multiple
fact verification systems. In <em id="bib.bib184.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2019 Conference on Empirical Methods in Natural Language Processing and the
9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. Association for Computational
Linguistics, 2944–2953.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D19-1292" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1292</a>

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian
et al<span id="bib.bib185.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ran Tian, Shashi Narayan,
Thibault Sellam, and Ankur P. Parikh.
2020.

</span>
<span class="ltx_bibblock">Sticking to the Facts: Confident Decoding for
Faithful Data-to-Text Generation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1910.08684 [cs.CL]

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran and Nguyen (2017)</span>
<span class="ltx_bibblock">
Van-Khanh Tran and
Le-Minh Nguyen. 2017.

</span>
<span class="ltx_bibblock">Natural Language Generation for Spoken Dialogue
System using RNN Encoder-Decoder Networks. In
<em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 21st Conference on Computational
Natural Language Learning (CoNLL 2017)</em>. Association
for Computational Linguistics, Vancouver, Canada,
442–451.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/K17-1044" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/K17-1044</a>

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu
et al<span id="bib.bib187.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Zhaopeng Tu, Yang Liu,
Lifeng Shang, Xiaohua Liu, and
Hang Li. 2017.

</span>
<span class="ltx_bibblock">Neural Machine Translation with Reconstruction. In
<em id="bib.bib187.3.1" class="ltx_emph ltx_font_italic">Thirty-First AAAI Conference on Artificial
Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu
et al<span id="bib.bib188.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Zhaopeng Tu, Zhengdong
Lu, Yang Liu, Xiaohua Liu, and
Hang Li. 2016.

</span>
<span class="ltx_bibblock">Modeling Coverage for Neural Machine Translation.
In <em id="bib.bib188.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers)</em>.
76–85.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uc-Cetina et al<span id="bib.bib189.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Victor Uc-Cetina, Nicolas
Navarro-Guerrero, Anabel Martin-Gonzalez,
Cornelius Weber, and Stefan Wermter.
2021.

</span>
<span class="ltx_bibblock">Survey on reinforcement learning for language
processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib189.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.05565</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib190.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N Gomez,
Ł ukasz Kaiser, and Illia Polosukhin.
2017.

</span>
<span class="ltx_bibblock">Attention is All you Need. In
<em id="bib.bib190.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, I. Guyon,
U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett
(Eds.), Vol. 30. 5998–6008.

</span>
<span class="ltx_bibblock">
<a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinyals and Le (2015)</span>
<span class="ltx_bibblock">
Oriol Vinyals and Quoc
Le. 2015.

</span>
<span class="ltx_bibblock">A Neural Conversational Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">ICML Deep Learning Workshop</em>
(2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib192.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Alex Wang, Kyunghyun Cho,
and Mike Lewis. 2020a.

</span>
<span class="ltx_bibblock">Asking and Answering Questions to Evaluate the
Factual Consistency of Summaries.

</span>
<span class="ltx_bibblock"><em id="bib.bib192.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and
Komatsuzaki (2021)</span>
<span class="ltx_bibblock">
Ben Wang and Aran
Komatsuzaki. 2021.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive
Language Model.

</span>
<span class="ltx_bibblock"><a href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Sennrich (2020)</span>
<span class="ltx_bibblock">
Chaojun Wang and Rico
Sennrich. 2020.

</span>
<span class="ltx_bibblock">On Exposure Bias, Hallucination and Domain Shift in
Neural Machine Translation. In <em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">2020 Annual
Conference of the Association for Computational Linguistics</em>. Association
for Computational Linguistics (ACL), 3544–3552.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2019)</span>
<span class="ltx_bibblock">
Hongmin Wang.
2019.

</span>
<span class="ltx_bibblock">Revisiting Challenges in Data-to-Text Generation
with Fact Grounding. In <em id="bib.bib195.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th
International Conference on Natural Language Generation</em>.
311–322.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib196.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Peng Wang, Junyang Lin,
An Yang, Chang Zhou,
Yichang Zhang, Jingren Zhou, and
Hongxia Yang. 2021a.

</span>
<span class="ltx_bibblock">Sketch and Refine: Towards Faithful and Informative
Table-to-Text Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib196.3.1" class="ltx_emph ltx_font_italic">ACL</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib197.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Peng Wang, An Yang,
Rui Men, Junyang Lin,
Shuai Bai, Zhikang Li,
Jianxin Ma, Chang Zhou,
Jingren Zhou, and Hongxia Yang.
2022b.

</span>
<span class="ltx_bibblock">OFA: Unifying Architectures, Tasks, and Modalities
Through a Simple Sequence-to-Sequence Learning Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib197.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2202.03052
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib198.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Wenhui Wang, Hangbo Bao,
Li Dong, Johan Bjorck,
Zhiliang Peng, Qiang Liu,
Kriti Aggarwal, Owais Mohammed,
Saksham Singhal, Subhojit Som, and
Furu Wei. 2022a.

</span>
<span class="ltx_bibblock">Image as a Foreign Language: BEiT Pretraining for
All Vision and Vision-Language Tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib198.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2208.10442
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib199.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Xu Wang, Hainan Zhang,
Shuai Zhao, Yanyan Zou,
Hongshen Chen, Zhuoye Ding,
Bo Cheng, and Yanyan Lan.
2021b.

</span>
<span class="ltx_bibblock">FCM: A Fine-grained Comparison Model for Multi-turn
Dialogue Reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.3.1" class="ltx_emph ltx_font_italic">EMNLP Findings</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib200.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Zhenyi Wang, Xiaoyang
Wang, Bang An, Dong Yu, and
Changyou Chen. 2020b.

</span>
<span class="ltx_bibblock">Towards Faithful Neural Table-to-Text Generation
with Content-Matching Constraints. In <em id="bib.bib200.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 58th Annual Meeting of the Association for Computational
Linguistics</em>. 1072–1086.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib201.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Zirui Wang, Jiahui Yu,
Adams Wei Yu, Zihang Dai,
Yulia Tsvetkov, and Yuan Cao.
2022c.

</span>
<span class="ltx_bibblock">SimVLM: Simple Visual Language Model Pretraining
with Weak Supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib201.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2108.10904
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck et al<span id="bib.bib202.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Sean Welleck, Ilia
Kulikov, Stephen Roller, Emily Dinan,
Kyunghyun Cho, and Jason Weston.
2019a.

</span>
<span class="ltx_bibblock">Neural Text Generation With Unlikelihood Training.
In <em id="bib.bib202.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck
et al<span id="bib.bib203.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Sean Welleck, Jason
Weston, Arthur Szlam, and Kyunghyun
Cho. 2019b.

</span>
<span class="ltx_bibblock">Dialogue Natural Language Inference. In
<em id="bib.bib203.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. Association
for Computational Linguistics, Florence, Italy,
3731–3741.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/P19-1363" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1363</a>

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al<span id="bib.bib204.2.2.1" class="ltx_text">.</span> (2015a)</span>
<span class="ltx_bibblock">
Tsung-Hsien Wen, Milica
Gašić, Dongho Kim, Nikola
Mrkšić, Pei-Hao Su, David
Vandyke, and Steve Young.
2015a.

</span>
<span class="ltx_bibblock">Stochastic Language Generation in Dialogue using
Recurrent Neural Networks with Convolutional Sentence Reranking. In
<em id="bib.bib204.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Annual Meeting of the
Special Interest Group on Discourse and Dialogue</em>.
Association for Computational Linguistics,
Prague, Czech Republic, 275–284.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/W15-4639" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W15-4639</a>

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al<span id="bib.bib205.2.2.1" class="ltx_text">.</span> (2015b)</span>
<span class="ltx_bibblock">
Tsung-Hsien Wen, Milica
Gasic, Nikola Mrksic, Pei-hao Su,
David Vandyke, and Steve J Young.
2015b.

</span>
<span class="ltx_bibblock">Semantically Conditioned LSTM-based Natural
Language Generation for Spoken Dialogue Systems. In
<em id="bib.bib205.3.1" class="ltx_emph ltx_font_italic">EMNLP</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weng
et al<span id="bib.bib206.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Rongxiang Weng, Heng Yu,
Xiangpeng Wei, and Weihua Luo.
2020.

</span>
<span class="ltx_bibblock">Towards Enhancing Faithfulness for Neural Machine
Translation. In <em id="bib.bib206.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Processing (EMNLP)</em>.
2675–2684.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams
et al<span id="bib.bib207.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Adina Williams, Nikita
Nangia, and Samuel Bowman.
2018.

</span>
<span class="ltx_bibblock">A Broad-Coverage Challenge Corpus for Sentence
Understanding through Inference. In <em id="bib.bib207.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2018 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long
Papers)</em>. Association for Computational Linguistics,
New Orleans, Louisiana, 1112–1122.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/N18-1101" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N18-1101</a>

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiseman
et al<span id="bib.bib208.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Sam Wiseman, Stuart
Shieber, and Alexander Rush.
2017.

</span>
<span class="ltx_bibblock">Challenges in Data-to-Document Generation. In
<em id="bib.bib208.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing</em>. Association for
Computational Linguistics, Copenhagen, Denmark,
2253–2263.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/D17-1239" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D17-1239</a>

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf
et al<span id="bib.bib209.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Thomas Wolf, Victor Sanh,
Julien Chaumond, and Clement Delangue.
2019.

</span>
<span class="ltx_bibblock">TransferTransfo: A Transfer Learning Approach for
Neural Network Based Conversational Agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib209.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/1901.08149
(2019).

</span>
<span class="ltx_bibblock">arXiv:1901.08149

<a href="http://arxiv.org/abs/1901.08149" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1901.08149</a>

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span id="bib.bib210.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chien-Sheng Wu, Richard
Socher, and Caiming Xiong.
2019.

</span>
<span class="ltx_bibblock">Global-to-local Memory Pointer Networks for
Task-Oriented Dialogue. In <em id="bib.bib210.3.1" class="ltx_emph ltx_font_italic">International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a href="https://openreview.net/forum?id=ryxnHhRqFm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=ryxnHhRqFm</a>

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span id="bib.bib211.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zeqiu Wu, Michel Galley,
Chris Brockett, Yizhe Zhang,
Xiang Gao, Chris Quirk,
Rik Koncel-Kedziorski, Jianfeng Gao,
Hannaneh Hajishirzi, Mari Ostendorf,
et al<span id="bib.bib211.4.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">A Controllable Model of Grounded Response
Generation. In <em id="bib.bib211.5.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference
on Artificial Intelligence</em>, Vol. 35.
14085–14093.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao and Wang (2021)</span>
<span class="ltx_bibblock">
Yijun Xiao and
William Yang Wang. 2021.

</span>
<span class="ltx_bibblock">On Hallucination and Predictive Uncertainty in
Conditional Language Generation. In <em id="bib.bib212.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 16th Conference of the European Chapter of the Association for
Computational Linguistics: Main Volume</em>. 2734–2744.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib213.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Jing Xu, Arthur D. Szlam,
and Jason Weston. 2021c.

</span>
<span class="ltx_bibblock">Beyond Goldfish Memory: Long-Term Open-Domain
Conversation.

</span>
<span class="ltx_bibblock"><em id="bib.bib213.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2107.07567
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Carpuat (2020)</span>
<span class="ltx_bibblock">
Weijia Xu and Marine
Carpuat. 2020.

</span>
<span class="ltx_bibblock">EDITOR: an Edit-Based Transformer with
Repositioning for Neural Machine Translation with Soft Lexical Constraints.

</span>
<span class="ltx_bibblock"><em id="bib.bib214.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em> 9 (11
2020), 311–328.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.1162/tacl_a_00368d3/2021." title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1162/tacl_a_00368d3/2021.</a>

</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Carpuat (2021)</span>
<span class="ltx_bibblock">
Weijia Xu and Marine
Carpuat. 2021.

</span>
<span class="ltx_bibblock">Rule-based Morphological Inflection Improves Neural
Terminology Translation.

</span>
<span class="ltx_bibblock">(9 2021),
5902–5914.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2021.emnlp-main.477" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2021.emnlp-main.477</a>

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib216.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Weijia Xu, Xing Niu,
and Marine Carpuat. 2019.

</span>
<span class="ltx_bibblock">Differentiable Sampling with Flexible Reference
Word Order for Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib216.3.1" class="ltx_emph ltx_font_italic">NAACL HLT 2019 - 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies - Proceedings of the Conference</em> 1
(4 2019), 2047–2053.

</span>
<span class="ltx_bibblock">

<a href="https://doi.org/10.18653/v1/n19-1207" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/n19-1207</a>

</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib217.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Xinnuo Xu, Ondřej
Dušek, Verena Rieser, and Ioannis
Konstas. 2021a.

</span>
<span class="ltx_bibblock">AGGGEN: Ordering and Aggregating while Generating.

</span>
<span class="ltx_bibblock"><em id="bib.bib217.3.1" class="ltx_emph ltx_font_italic">roceedings of the 59th Annual Meeting of the
Association for Computational Linguistics (ACL2021)</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib218.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Yan Xu, Etsuko Ishii,
Samuel Cahyawijaya, Zihan Liu,
Genta Indra Winata, Andrea Madotto,
Dan Su, and Pascale Fung.
2021b.

</span>
<span class="ltx_bibblock">Retrieval-Free Knowledge-Grounded Dialogue Response
Generation with Adapters.

</span>
<span class="ltx_bibblock"><em id="bib.bib218.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.06232</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib219.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi,
Saizheng Zhang, Yoshua Bengio,
William Cohen, Ruslan Salakhutdinov,
and Christopher D Manning.
2018.

</span>
<span class="ltx_bibblock">HotpotQA: A Dataset for Diverse, Explainable
Multi-hop Question Answering. In <em id="bib.bib219.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2018 Conference on Empirical Methods in Natural Language Processing</em>.
2369–2380.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yavuz
et al<span id="bib.bib220.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Semih Yavuz, Abhinav
Rastogi, Guan-Lin Chao, and Dilek
Hakkani-Tur. 2019.

</span>
<span class="ltx_bibblock">DEEPCOPY: Grounded Response Generation with
Hierarchical Pointer Networks. In <em id="bib.bib220.3.1" class="ltx_emph ltx_font_italic">Proceedings of
SIGdial</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin
et al<span id="bib.bib221.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jun Yin, Xin Jiang,
Zhengdong Lu, Lifeng Shang,
Hang Li, and Xiaoming Li.
2016.

</span>
<span class="ltx_bibblock">Neural generative question answering. In
<em id="bib.bib221.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Fifth International Joint
Conference on Artificial Intelligence</em>. 2972–2978.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoneda et al<span id="bib.bib222.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Takuma Yoneda, Jeff
Mitchell, Johannes Welbl, Pontus
Stenetorp, and Sebastian Riedel.
2018.

</span>
<span class="ltx_bibblock">UCL Machine Reading Group: Four Factor Framework
For Fact Finding (HexaF). In <em id="bib.bib222.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the First Workshop on Fact Extraction and VERification (FEVER)</em>.
Association for Computational Linguistics,
Brussels, Belgium, 97–102.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/W18-5515" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W18-5515</a>

</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib223.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tiezheng Yu, Zihan Liu,
and Pascale Fung. 2021.

</span>
<span class="ltx_bibblock">AdaptSum: Towards Low-Resource Domain Adaptation
for Abstractive Summarization. In <em id="bib.bib223.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2021 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies</em>.
5892–5904.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaheer et al<span id="bib.bib224.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Manzil Zaheer, Guru
Guruganesh, Kumar Avinava Dubey, Joshua
Ainslie, Chris Alberti, Santiago
Ontanon, Philip Pham, Anirudh Ravula,
Qifan Wang, Li Yang, and
Amr Ahmed. 2020.

</span>
<span class="ltx_bibblock">Big Bird: Transformers for Longer Sequences. In
<em id="bib.bib224.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, H. Larochelle,
M. Ranzato, R. Hadsell,
M. F. Balcan, and H. Lin (Eds.),
Vol. 33. Curran Associates, Inc.,
17283–17297.

</span>
<span class="ltx_bibblock">
<a href="https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf</a>

</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zemlyanskiy and
Sha (2018)</span>
<span class="ltx_bibblock">
Yury Zemlyanskiy and Fei
Sha. 2018.

</span>
<span class="ltx_bibblock">Aiming to Know You Better Perhaps Makes Me a More
Engaging Dialogue Partner. In <em id="bib.bib225.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
22nd Conference on Computational Natural Language Learning</em>.
Association for Computational Linguistics,
Brussels, Belgium, 551–561.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/K18-1053" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/K18-1053</a>

</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib226.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Chen Zhang, Grandee Lee,
Luis Fernando D’Haro, and Haizhou
Li. 2021a.

</span>
<span class="ltx_bibblock">D-score: Holistic dialogue evaluation without
reference.

</span>
<span class="ltx_bibblock"><em id="bib.bib226.3.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and
Language Processing</em> 29 (2021),
2502–2516.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib227.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Hongguang Zhang, Jing
Zhang, and Piotr Koniusz.
2019b.

</span>
<span class="ltx_bibblock">Few-Shot Learning via Saliency-Guided Hallucination
of Samples. In <em id="bib.bib227.3.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer
Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20,
2019</em>. Computer Vision Foundation / IEEE,
2770–2779.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.1109/CVPR.2019.00288" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPR.2019.00288</a>

</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib228.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jiacheng Zhang, Huanbo
Luan, Maosong Sun, Feifei Zhai,
Jingfang Xu, and Yang Liu.
2021b.

</span>
<span class="ltx_bibblock">Neural Machine Translation with Explicit Phrase
Alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib228.3.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and
Language Processing</em> 29 (2021),
1001–1010.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib229.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Saizheng Zhang, Emily
Dinan, Jack Urbanek, Arthur Szlam,
Douwe Kiela, and Jason Weston.
2018.

</span>
<span class="ltx_bibblock">Personalizing Dialogue Agents: I have a dog, do you
have pets too?. In <em id="bib.bib229.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers)</em>. 2204–2213.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib230.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha
Kishore, Felix Wu, Kilian Q Weinberger,
and Yoav Artzi. 2019a.

</span>
<span class="ltx_bibblock">BERTScore: Evaluating Text Generation with BERT.
In <em id="bib.bib230.3.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib231.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Xikun Zhang, Deepak
Ramachandran, Ian Tenney, Yanai Elazar,
and Dan Roth. 2020b.

</span>
<span class="ltx_bibblock">Do Language Embeddings capture Scales?. In
<em id="bib.bib231.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Third BlackboxNLP Workshop on
Analyzing and Interpreting Neural Networks for NLP</em>.
292–299.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib232.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yuhao Zhang, Derek Merck,
Emily Tsai, Christopher D Manning, and
Curtis Langlotz. 2020a.

</span>
<span class="ltx_bibblock">Optimizing the Factual Correctness of a Summary: A
Study of Summarizing Radiology Reports. In
<em id="bib.bib232.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>. 5108–5120.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib233.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Yizhe Zhang, Siqi Sun,
Michel Galley, Yen-Chun Chen,
Chris Brockett, Xiang Gao,
Jianfeng Gao, Jingjing Liu, and
Bill Dolan. 2020c.

</span>
<span class="ltx_bibblock">DIALOGPT : Large-Scale Generative Pre-training
for Conversational Response Generation. In
<em id="bib.bib233.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics: System Demonstrations</em>.
Association for Computational Linguistics,
Online, 270–278.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.acl-demos.30" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-demos.30</a>

</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib234.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jing Zhao, Junwei Bao,
Yifan Wang, Yongwei Zhou,
Youzheng Wu, Xiaodong He, and
Bowen Zhou. 2021.

</span>
<span class="ltx_bibblock">RoR: Read-over-Read for Long Document Machine
Reading Comprehension. In <em id="bib.bib234.3.1" class="ltx_emph ltx_font_italic">Findings of the
Association for Computational Linguistics: EMNLP 2021</em>.
Association for Computational Linguistics,
Punta Cana, Dominican Republic,
1862–1872.

</span>
<span class="ltx_bibblock">
<a href="https://aclanthology.org/2021.findings-emnlp.160" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2021.findings-emnlp.160</a>

</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib235.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zheng Zhao, Shay B.
Cohen, and Bonnie Webber.
2020.

</span>
<span class="ltx_bibblock">Reducing Quantity Hallucinations in Abstractive
Summarization. In <em id="bib.bib235.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for
Computational Linguistics: EMNLP 2020</em>. Association for
Computational Linguistics, Online,
2237–2249.

</span>
<span class="ltx_bibblock">
<a href="https://doi.org/10.18653/v1/2020.findings-emnlp.203" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.findings-emnlp.203</a>

</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al<span id="bib.bib236.3.3.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ming Zhong, Da Yin,
Tao Yu, Ahmad Zaidi,
Mutethia Mutuma, Rahul Jha,
Ahmed Hassan, Asli Celikyilmaz,
Yang Liu, Xipeng Qiu, et al<span id="bib.bib236.4.1" class="ltx_text">.</span>
2021.

</span>
<span class="ltx_bibblock">QMSum: A New Benchmark for Query-based Multi-domain
Meeting Summarization. In <em id="bib.bib236.5.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies</em>. 5905–5921.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
et al<span id="bib.bib237.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chunting Zhou, Xuezhe Ma,
Di Wang, and Graham Neubig.
2019.

</span>
<span class="ltx_bibblock">Density Matching for Bilingual Word Embedding. In
<em id="bib.bib237.3.1" class="ltx_emph ltx_font_italic">NAACL</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib238.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Chunting Zhou, Graham
Neubig, Jiatao Gu, Mona Diab,
Francisco Guzmán, Luke Zettlemoyer,
and Marjan Ghazvininejad.
2021b.

</span>
<span class="ltx_bibblock">Detecting Hallucinated Content in Conditional
Neural Sequence Generation. In <em id="bib.bib238.3.1" class="ltx_emph ltx_font_italic">Findings of the
Association for Computational Linguistics: ACL-IJCNLP 2021</em>.
1393–1404.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
et al<span id="bib.bib239.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Kangyan Zhou, Shrimai
Prabhumoye, and Alan W Black.
2018.

</span>
<span class="ltx_bibblock">A Dataset for Document Grounded Conversations. In
<em id="bib.bib239.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing</em>. 708–713.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al<span id="bib.bib240.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Pei Zhou, Karthik
Gopalakrishnan, Behnam Hedayatnia,
Seokhwan Kim, Jay Pujara,
Xiang Ren, Yang Liu, and
Dilek Hakkani-Tur. 2021a.

</span>
<span class="ltx_bibblock">Think Before You Speak: Using Self-talk to Generate
Implicit Commonsense Knowledge for Response Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib240.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.08501</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib241.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chenguang Zhu, William
Hinthorn, Ruochen Xu, Qingkai Zeng,
Michael Zeng, Xuedong Huang, and
Meng Jiang. 2021.

</span>
<span class="ltx_bibblock">Enhancing Factual Consistency of Abstractive
Summarization. In <em id="bib.bib241.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies</em>. 718–733.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul 25 02:23:58 2023 by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
